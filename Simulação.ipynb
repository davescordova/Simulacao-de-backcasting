{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7380b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† Falha ao importar bibliotecas de GPU (cuml/xgboost): No module named 'cuml'\n",
      " ¬†‚Üí Usando fallback para YDF (CPU).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 17:25:11.421705: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/mnt/c/Users/daves/OneDrive/Pessoal/Notebooks/tf_env/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando PyMC vers√£o: 5.27.0\n",
      "Modo Qiskit: Legacy\n",
      "================================================================================\n",
      "INICIANDO PIPELINE DE MODELOS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Prepara√ß√£o de dados e econometria cl√°ssica\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.structural import UnobservedComponents\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "#Modelos de Mudan√ßa de Regime (Modelo de Regress√£o com Mudan√ßa de Regime de Markov):\n",
    "    # em vez de um √∫nico modelo de regress√£o para explicar a s√©rie inteira, h√° v√°rios modelos\n",
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Modelagem Bayesiana:\n",
    "    # par√¢metros como vari√°veis aleat√≥rias: tem uma distribui√ß√£o de probabilidade, portanto com incerteza\n",
    "    #resultado √© uma distribui√ß√£o de probabilidade\n",
    "        #prior: cren√ßa sobre o par√¢metro antes de ver os dados\n",
    "        #likelihood: como os dados s√£o gerados, fun√ß√£o de verossimilhan√ßa\n",
    "        #posterior: cren√ßa atualizada sobre o par√¢metro ap√≥s ver os dados\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Visualiza√ß√£o de dados\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.colors \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy.optimize import minimize\n",
    "from pygam import LinearGAM, s, f\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "#Modelos Aditivos Generalizados (GAM)\n",
    "    # Em vez de for√ßar uma rela√ß√£o linear, o GAM substitui esse termo por uma fun√ß√£o suave e flex√≠vel\n",
    "    #spline:divide o intervalo de $x$ em se√ß√µes (definidas por \"n√≥s\" ou knots) \n",
    "        # e ajusta fun√ß√µes mais simples (como pequenos polin√¥mios c√∫bicos) em cada se√ß√£o\n",
    "from scipy.stats import norm\n",
    "\n",
    "#Computa√ß√£o qu√¢ntica: \n",
    "    #Uso de Otimiza√ß√£o Combinat√≥ria: QAOA n√£o √© puramente qu√¢ntico; ele √© um algoritmo h√≠brido. \n",
    "        #Cl√°ssico üíª: O otimizador COBYLA (cl√°ssico) \"chuta\" um conjunto inicial de par√¢metros (√¢ngulos) para o circuito qu√¢ntico.\n",
    "        # Qu√¢ntico ‚öõÔ∏è: O QAOAAnsatz (o circuito qu√¢ntico) √© montado com esses par√¢metros. \n",
    "            # Ele √© executado no processador qu√¢ntico (ou simulador), usando superposi√ß√£o\n",
    "            # e emaranhamento para explorar o vasto espa√ßo de solu√ß√µes do seu QuadraticProgram.\n",
    "        # Qu√¢ntico ‚öõÔ∏è: O circuito √© medido, \"colapsando\" para uma solu√ß√£o candidata (ex: \"rota A\") e seu respectivo \"custo\".\n",
    "        # Cl√°ssico üíª: O COBYLA recebe esse custo.\n",
    "            # Ele ent√£o usa sua l√≥gica cl√°ssica para decidir um novo conjunto de par√¢metros para o circuito qu√¢ntico, tentando obter um custo menor.\n",
    "\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit_algorithms import QAOA\n",
    "from qiskit.circuit.library import TwoLocal, QAOAAnsatz\n",
    "from qiskit_optimization import QuadraticProgram\n",
    "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
    "\n",
    "\n",
    "# Usar o Sampler correto dependendo da vers√£o\n",
    "try:\n",
    "    # Para Qiskit >= 1.0\n",
    "    from qiskit.primitives import Sampler\n",
    "    QISKIT_NEW = True\n",
    "except ImportError:\n",
    "    # Para vers√µes antigas\n",
    "    try:\n",
    "        from qiskit_aer.primitives import Sampler\n",
    "        QISKIT_NEW = False\n",
    "    except ImportError:\n",
    "        # Fallback: usar StatevectorSampler\n",
    "        from qiskit.primitives import StatevectorSampler as Sampler\n",
    "        QISKIT_NEW = True\n",
    "\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "# Machine Learning Cl√°ssico: \n",
    "    # Random Forest: Constr√≥i  √°rvores independentes em paralelo usando aleatoriedade nos dados e nas features, e tira a m√©dia das previs√µes.\n",
    "    # XGBoost: Constr√≥i √°rvores sequencialmente, onde cada √°rvore aprende com os erros das anteriores,\n",
    "        # usando otimiza√ß√µes de gradiente e regulariza√ß√£o para alta performance e controle de overfitting.\n",
    "\n",
    "# Importa√ß√µes necess√°rias para Machiene Learning com GPU\n",
    "try:\n",
    "    from cuml.ensemble import RandomForestRegressor\n",
    "    import xgboost as xgb\n",
    "    print(\" ¬†‚Üí 'cuml.RandomForestRegressor' e 'xgboost' importados.\")\n",
    "    USE_GPU_ML = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö† Falha ao importar bibliotecas de GPU (cuml/xgboost): {e}\")\n",
    "    print(\" ¬†‚Üí Usando fallback para YDF (CPU).\")\n",
    "    USE_GPU_ML = False\n",
    "\n",
    "import ydf\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#VARMAX:\n",
    "    # analisar e prever m√∫ltiplas s√©ries temporais que s√£o interdependentes e tamb√©m podem ser influenciadas por vari√°veis externas.\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"Usando PyMC vers√£o: {pm.__version__}\")\n",
    "print(f\"Modo Qiskit: {'Novo (>=1.0)' if QISKIT_NEW else 'Legacy'}\")\n",
    "print(\"=\"*80)\n",
    "print(\"INICIANDO PIPELINE DE MODELOS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cfc988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 0. SIMULA√á√ÉO DE DADOS \n",
    "# ===========================\n",
    "\n",
    "np.random.seed(1872)\n",
    "anos = np.arange(1872, 2023)\n",
    "n_anos = len(anos)\n",
    "\n",
    "# Simula PIB per capita e garante n√£o-negatividade\n",
    "pib_pc = 500 * np.exp(np.linspace(0, 1.5, n_anos)) + np.random.normal(0, 50, n_anos)\n",
    "pib_pc = np.maximum(pib_pc, 0) # Garante que pib_pc >= 0\n",
    "\n",
    "# Simula Urbanizacao (j√° clipado entre 0.05 e 0.85, ent√£o √© positivo)\n",
    "urbanizacao = 0.8 / (1 + np.exp(-0.05 * (anos - 1990))) + np.random.normal(0, 0.02, n_anos)\n",
    "urbanizacao = np.clip(urbanizacao, 0.05, 0.85)\n",
    "\n",
    "# Simula Industrializacao e garante n√£o-negatividade\n",
    "industrializacao = 0.6 / (1 + np.exp(-0.06 * (anos - 1980))) + np.random.normal(0, 0.02, n_anos)\n",
    "industrializacao = np.maximum(industrializacao, 0) # Garante que industrializacao >= 0\n",
    "\n",
    "# Simula Educacao e garante n√£o-negatividade\n",
    "educacao = 0.7 / (1 + np.exp(-0.04 * (anos - 1985))) + np.random.normal(0, 0.015, n_anos)\n",
    "educacao = np.maximum(educacao, 0) # Garante que educacao >= 0\n",
    "\n",
    "regimes_verdadeiros = np.zeros(n_anos, dtype=int)\n",
    "gini_por_regime = {0: 0.40, 1: 0.43, 2: 0.46}\n",
    "volatilidade_regime = {0: 0.025, 1: 0.015, 2: 0.020}\n",
    "regime_atual = 0\n",
    "for i in range(n_anos):\n",
    "    ano_atual = anos[i]\n",
    "    if ano_atual < 1930: regime_atual = 0\n",
    "    elif 1930 <= ano_atual < 1960: regime_atual = 1\n",
    "    elif 1960 <= ano_atual < 2000: regime_atual = 0\n",
    "    else: regime_atual = 2\n",
    "    regimes_verdadeiros[i] = regime_atual\n",
    "\n",
    "tendencia = 0.6 - 0.10 * ((anos - 1872) / 150)\n",
    "ciclica = -0.05 * np.sin(np.pi * (anos - 1872) / 40)\n",
    "estrutural = 0.03 * np.cos(np.pi * (anos - 1872) / 25)\n",
    "gini_regime = np.array([gini_por_regime[r] for r in regimes_verdadeiros])\n",
    "noise_regime = np.array([np.random.normal(0, volatilidade_regime[r]) for r in regimes_verdadeiros])\n",
    "gini_real = 0.1 * tendencia + 0.7 * gini_regime + 0.1 * ciclica + 0.1 * estrutural + noise_regime\n",
    "gini_real = np.clip(gini_real, 0.35, 0.55)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Ano': anos, 'PIB_pc': pib_pc, 'Urbanizacao': urbanizacao,\n",
    "    'Industrializacao': industrializacao, 'Educacao': educacao,\n",
    "    'Gini_Verdadeiro': gini_real, 'Regime_Verdadeiro': regimes_verdadeiros\n",
    "})\n",
    "\n",
    "ano_inicio_pnad = 1976\n",
    "# Criar Gini_Observado para sele√ß√£o de lags\n",
    "df['Gini_Observado'] = np.nan\n",
    "mask_moderno_inicial = df['Ano'] >= ano_inicio_pnad\n",
    "df.loc[mask_moderno_inicial, 'Gini_Observado'] = df.loc[mask_moderno_inicial, 'Gini_Verdadeiro'] + \\\n",
    "                                                np.random.normal(0, 0.01, mask_moderno_inicial.sum())\n",
    "n_total = len(df)\n",
    "\n",
    "print(\"\\nDADOS SIMULADOS (com garantia de positividade para PIB_pc, Industrializacao, Educacao):\")\n",
    "print(f\"Gini por Regime: {gini_por_regime}\")\n",
    "print(\"Primeiras linhas do DataFrame:\")\n",
    "print(df.head())\n",
    "# Verifica valores m√≠nimos (opcional)\n",
    "print(\"\\nValores m√≠nimos simulados:\")\n",
    "print(f\"  PIB_pc Min: {df['PIB_pc'].min():.4f}\")\n",
    "print(f\"  Industrializacao Min: {df['Industrializacao'].min():.4f}\")\n",
    "print(f\"  Educacao Min: {df['Educacao'].min():.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- VISUALIZA√á√ÉO DOS DADOS ---\n",
    "# Presume que matplotlib e seaborn foram importados no bloco principal de imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_moderno_grafico = df[df['Ano'] >= ano_inicio_pnad].copy()\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Gr√°fico 1: Gini e Regimes\n",
    "fig, ax1 = plt.subplots(figsize=(16, 6))\n",
    "sns.lineplot(data=df, x='Ano', y='Gini_Verdadeiro', label='Gini Verdadeiro (Latente)', ax=ax1, color='blue', linewidth=2.5)\n",
    "sns.scatterplot(data=df_moderno_grafico, x='Ano', y='Gini_Observado', label=f'Gini Observado (p√≥s-{ano_inicio_pnad})', ax=ax1, color='red', s=50, zorder=5)\n",
    "ax1.set_title('Simula√ß√£o do √çndice Gini e Regimes Estruturais (1872-2022)', fontsize=16, pad=20)\n",
    "ax1.set_ylabel('√çndice Gini', fontsize=12, color='blue')\n",
    "ax1.set_xlabel('Ano', fontsize=12)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.fill_between(df['Ano'], df['Regime_Verdadeiro'], step='pre', alpha=0.2, color='gray', label='Regime (Eixo Direito)')\n",
    "ax2.set_ylabel('Regime Estrutural', fontsize=12, color='gray')\n",
    "ax2.tick_params(axis='y', labelcolor='gray', labelsize=9)\n",
    "tick_locs = np.unique(regimes_verdadeiros)\n",
    "ax2.set_yticks(tick_locs)\n",
    "regime_nomes = [f\"Regime {r} (Gini ~{gini_por_regime[r]})\" for r in tick_locs]\n",
    "ax2.set_yticklabels(regime_nomes)\n",
    "ax2.grid(False)\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"gini_regimes_plot.png\")\n",
    "plt.show() # Descomente para mostrar o gr√°fico interativamente se n√£o estiver em ambiente como VS Code/Jupyter\n",
    "plt.close(fig) # Fecha a figura para n√£o aparecer inline depois\n",
    "print(\"‚úì Gr√°fico Gini vs Regimes salvo como gini_regimes_plot.png\")\n",
    "\n",
    "# Gr√°fico 2: Covari√°veis\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 12), sharex=True)\n",
    "fig.suptitle('Evolu√ß√£o das Covari√°veis Simuladas (1872-2022)', fontsize=18, y=1.02)\n",
    "sns.lineplot(data=df, x='Ano', y='PIB_pc', ax=axes[0], color='green'); axes[0].set_title('PIB per capita', fontsize=12); axes[0].set_ylabel('Valor')\n",
    "sns.lineplot(data=df, x='Ano', y='Urbanizacao', ax=axes[1], color='orange'); axes[1].set_title('Taxa de Urbaniza√ß√£o', fontsize=12); axes[1].set_ylabel('Taxa (0-1)')\n",
    "sns.lineplot(data=df, x='Ano', y='Industrializacao', ax=axes[2], color='purple'); axes[2].set_title('N√≠vel de Industrializa√ß√£o', fontsize=12); axes[2].set_ylabel('N√≠vel (0-1)')\n",
    "sns.lineplot(data=df, x='Ano', y='Educacao', ax=axes[3], color='brown'); axes[3].set_title('N√≠vel de Educa√ß√£o', fontsize=12); axes[3].set_ylabel('N√≠vel (0-1)')\n",
    "axes[3].set_xlabel('Ano', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"covariaveis_plot.png\")\n",
    "plt.show() # Descomente para mostrar o gr√°fico interativamente\n",
    "plt.close(fig) # Fecha a figura\n",
    "print(\"‚úì Gr√°fico Covari√°veis salvo como covariaveis_plot.png\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# --- SELE√á√ÉO DE LAGS PARA O GINI (BASEADO NO AIC) ---\n",
    "# Presume que AutoReg foi importado no bloco principal de imports\n",
    "\n",
    "print(\"\\n[Sele√ß√£o de Lags via AIC]\")\n",
    "print(\"‚Üí Selecionando n√∫mero de lags para Gini (max 10)...\")\n",
    "gini_moderno_observado = df.loc[mask_moderno_inicial, 'Gini_Observado'].dropna()\n",
    "\n",
    "k_lags_selecionados = 1 # Valor padr√£o caso a sele√ß√£o falhe\n",
    "\n",
    "if len(gini_moderno_observado) > 10: # Checagem m√≠nima de dados\n",
    "    try:\n",
    "        # A sintaxe moderna (statsmodels > 0.11) seleciona automaticamente \n",
    "        # o melhor lag (baseado no AIC por padr√£o) quando 'lags' √© um inteiro.\n",
    "        model_select = AutoReg(gini_moderno_observado, lags=10, trend='n', old_names=False) \n",
    "        results_select = model_select.fit(cov_type=\"nonrobust\") # Ajusta o modelo com a melhor ordem\n",
    "        \n",
    "        # ***** CORRE√á√ÉO APLICADA AQUI *****\n",
    "        # O lag selecionado est√° em 'results_select.model.k_ar'\n",
    "        k_lags_selecionados = results_select.model.k_ar \n",
    "        \n",
    "        if k_lags_selecionados == 0: \n",
    "            k_lags_selecionados = 1 # Evitar 0 lags\n",
    "            \n",
    "    except AttributeError as e:\n",
    "        # Fallback para a sintaxe antiga (select_order), caso o erro acima persista\n",
    "        print(f\"‚ö† Erro de atributo ({e}), tentando fallback 'select_order' (vers√£o antiga)...\")\n",
    "        try:\n",
    "             ar_mod_sel = AutoReg(gini_moderno_observado, lags=10, trend='n') \n",
    "             sel_res = ar_mod_sel.select_order(maxlag=10, ic='aic')\n",
    "             k_lags_selecionados = sel_res.aic if sel_res.aic > 0 else 1\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ö† Fallback 'select_order' tamb√©m falhou ({e2}), usando k=1.\")\n",
    "            k_lags_selecionados = 1\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Erro inesperado na sele√ß√£o autom√°tica de lags ({e}), usando k=1.\")\n",
    "        k_lags_selecionados = 1\n",
    "else:\n",
    "    print(\"‚ö† Dados insuficientes para sele√ß√£o autom√°tica, usando k=1.\")\n",
    "    k_lags_selecionados = 1\n",
    "\n",
    "\n",
    "print(f\"‚úì N√∫mero de lags selecionados (k): {k_lags_selecionados}\")\n",
    "\n",
    "# --- CRIA√á√ÉO DAS COLUNAS DE LAG ---\n",
    "print(\"‚Üí Criando colunas de lag no DataFrame principal...\")\n",
    "lag_cols_names = []\n",
    "for i in range(1, k_lags_selecionados + 1):\n",
    "    col_name = f'Gini_Lag_{i}'\n",
    "    df[col_name] = df['Gini_Verdadeiro'].shift(i)\n",
    "    # Preencher NaNs iniciais com o primeiro valor de Gini_Verdadeiro\n",
    "    df[col_name].fillna(df['Gini_Verdadeiro'].iloc[0], inplace=True)\n",
    "    lag_cols_names.append(col_name)\n",
    "    print(f\"  ‚úì Coluna '{col_name}' criada e preenchida.\")\n",
    "\n",
    "# --- ATUALIZAR df_moderno e df_historico ---\n",
    "print(\"‚Üí Atualizando DataFrames moderno e hist√≥rico...\")\n",
    "df_moderno = df[df['Ano'] >= ano_inicio_pnad].copy()\n",
    "df_historico = df[df['Ano'] < ano_inicio_pnad].copy()\n",
    "n_historico = len(df_historico)\n",
    "n_moderno = len(df_moderno)\n",
    "print(f\"  ‚úì df_moderno ({n_moderno} obs) e df_historico ({n_historico} obs) atualizados.\")\n",
    "\n",
    "print(\"\\nPrimeiras linhas do DataFrame com colunas de lag:\")\n",
    "print(df.head())\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- LISTA DE PREDITORES BASE E DE LAGS ---\n",
    "predictors_base = ['PIB_pc', 'Urbanizacao', 'Industrializacao', 'Educacao']\n",
    "predictors_lags = lag_cols_names\n",
    "# --- FIM DAS LISTAS ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 1. MODELO OLS BASELINE (com k lags)\n",
    "# ===========================\n",
    "print(f\"\\n[1] MODELO OLS (Baseline com k={k_lags_selecionados} Lags)\")\n",
    "predictors_ols = predictors_base + predictors_lags # Combina base + lags\n",
    "print(f\"‚Üí Preditores OLS: {predictors_ols}\")\n",
    "\n",
    "with tqdm(total=100, desc=\"OLS\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "    X_moderno_ols = df_moderno[predictors_ols]\n",
    "    X_moderno_ols = sm.add_constant(X_moderno_ols)\n",
    "    y_moderno_ols = df_moderno['Gini_Observado']\n",
    "    pbar.update(30)\n",
    "\n",
    "    modelo_ols = sm.OLS(y_moderno_ols, X_moderno_ols).fit()\n",
    "    pbar.update(40)\n",
    "\n",
    "    X_historico_ols = df_historico[predictors_ols]\n",
    "    X_historico_ols = sm.add_constant(X_historico_ols)\n",
    "    df_historico['Gini_OLS'] = modelo_ols.predict(X_historico_ols)\n",
    "    pbar.update(30)\n",
    "\n",
    "print(f\"‚úì R¬≤: {modelo_ols.rsquared:.4f} | AIC: {modelo_ols.aic:.2f}\")\n",
    "print(modelo_ols.summary())\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7396678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 2. MARKOV SWITCHING REGRESSION (com k lags)\n",
    "# ===========================\n",
    "print(f\"\\n[2] MARKOV SWITCHING REGRESSION (com k={k_lags_selecionados} Lags)\")\n",
    "predictors_markov_base_subset = ['PIB_pc', 'Urbanizacao'] # Usando subconjunto base para Markov\n",
    "predictors_markov = predictors_markov_base_subset + predictors_lags # Combina subconjunto base + lags\n",
    "print(f\"‚Üí Preditores Markov: {predictors_markov}\")\n",
    "\n",
    "X_markov = df_moderno[predictors_markov].values\n",
    "y_markov = df_moderno['Gini_Observado'].values\n",
    "X_markov_const = sm.add_constant(X_markov)\n",
    "\n",
    "# --- Atualizar n√∫mero de preditores para Markov ---\n",
    "num_predictors_markov = X_markov_const.shape[1] # Usa a forma de X_markov_const\n",
    "print(f\"  (N√∫mero total de coeficientes por regime: {num_predictors_markov})\")\n",
    "# --- Fim da atualiza√ß√£o ---\n",
    "\n",
    "try:\n",
    "    with tqdm(total=100, desc=\"Markov\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "        pbar.set_postfix_str(\"Inicializando modelo...\")\n",
    "        \n",
    "        # ***** CORRE√á√ÉO 1: Adicionado trend='n' para evitar colinearidade com sm.add_constant *****\n",
    "        modelo_markov = MarkovRegression(\n",
    "            endog=y_markov, k_regimes=2, exog=X_markov_const, trend='n', switching_variance=True\n",
    "        )\n",
    "        pbar.update(20)\n",
    "\n",
    "        pbar.set_postfix_str(\"Estimando (max 500 iter)...\")\n",
    "        resultado_markov = modelo_markov.fit(maxiter=500, disp=False)\n",
    "        pbar.update(60)\n",
    "\n",
    "        prob_regimes = resultado_markov.smoothed_marginal_probabilities\n",
    "        regime_mais_provavel = np.argmax(prob_regimes, axis=1)\n",
    "        pbar.update(10)\n",
    "\n",
    "        # Backcasting\n",
    "        X_hist_markov = df_historico[predictors_markov].values\n",
    "        X_hist_markov_const = sm.add_constant(X_hist_markov)\n",
    "        ultimo_regime = regime_mais_provavel[-1]\n",
    "\n",
    "        # --- Ajustar √≠ndices dos par√¢metros dinamicamente ---\n",
    "        params = resultado_markov.params\n",
    "        if ultimo_regime == 0:\n",
    "             coefs_pred = params[:num_predictors_markov]\n",
    "        else:\n",
    "             coefs_pred = params[num_predictors_markov:(2 * num_predictors_markov)]\n",
    "        # --- Fim do ajuste ---\n",
    "\n",
    "        df_historico['Gini_Markov'] = X_hist_markov_const @ coefs_pred\n",
    "        pbar.update(5)\n",
    "\n",
    "        # ***** CORRE√á√ÉO 2: Buscar sigma2 (vari√¢ncias) nos locais corretos *****\n",
    "        # As vari√¢ncias (sigma2) v√™m DEPOIS de todos os coeficientes de regime\n",
    "        sigma2_idx_start = modelo_markov.k_regimes * num_predictors_markov\n",
    "        sigma2_idx_end = sigma2_idx_start + modelo_markov.k_regimes\n",
    "        sigma_regime = np.sqrt(params[sigma2_idx_start:sigma2_idx_end])\n",
    "        # ***** Fim da corre√ß√£o 2 *****\n",
    "        \n",
    "        sigma_usado = sigma_regime[ultimo_regime]\n",
    "        df_historico['Gini_Markov_Low'] = df_historico['Gini_Markov'] - 1.96 * sigma_usado\n",
    "        df_historico['Gini_Markov_High'] = df_historico['Gini_Markov'] + 1.96 * sigma_usado\n",
    "        pbar.update(5)\n",
    "\n",
    "        df_moderno['Prob_Regime_0'] = prob_regimes[:, 0]\n",
    "        df_moderno['Prob_Regime_1'] = prob_regimes[:, 1]\n",
    "        df_moderno['Regime_Inferido'] = regime_mais_provavel\n",
    "\n",
    "        markov_success = True\n",
    "\n",
    "    print(f\"‚úì Converg√™ncia OK | AIC: {resultado_markov.aic:.2f}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUM√ÅRIO DO MODELO MARKOV SWITCHING (treinado nos dados modernos)\")\n",
    "    print(\"=\"*80)\n",
    "    print(resultado_markov.summary())\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Falhou: {e}\")\n",
    "    print(\"‚Üí Usando K-means como fallback...\")\n",
    "\n",
    "    # K-means e OLS por cluster\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "    kmeans_data = np.column_stack([y_markov, X_markov])\n",
    "    regime_mais_provavel = kmeans.fit_predict(kmeans_data)\n",
    "\n",
    "    coefs_regimes = []\n",
    "    for r in range(2):\n",
    "        mask = regime_mais_provavel == r\n",
    "        X_r = X_markov_const[mask]\n",
    "        y_r = y_markov[mask]\n",
    "        # Adiciona uma checagem para garantir que o cluster n√£o est√° vazio\n",
    "        if X_r.shape[0] > X_r.shape[1]: # Mais observa√ß√µes que preditores\n",
    "            coefs_r = np.linalg.lstsq(X_r, y_r, rcond=None)[0]\n",
    "            coefs_regimes.append(coefs_r)\n",
    "        else:\n",
    "            print(f\"‚ö† Cluster {r} tem dados insuficientes ({X_r.shape[0]} obs) para OLS. Usando NaNs.\")\n",
    "            coefs_regimes.append(np.full(num_predictors_markov, np.nan)) # Adiciona NaNs se falhar\n",
    "\n",
    "    # Fallback para o √∫ltimo regime (se os coeficientes forem v√°lidos)\n",
    "    ultimo_regime = regime_mais_provavel[-1]\n",
    "    if ultimo_regime < len(coefs_regimes) and not np.isnan(coefs_regimes[ultimo_regime]).any():\n",
    "        X_hist_markov_const = sm.add_constant(df_historico[predictors_markov].values)\n",
    "        df_historico['Gini_Markov'] = X_hist_markov_const @ coefs_regimes[ultimo_regime]\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUM√ÅRIO DO FALLBACK (K-Means + OLS por cluster)\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Clusters (regimes) encontrados: {len(coefs_regimes)}\")\n",
    "        print(f\"Vari√°veis usadas no OLS: ['const'] + {predictors_markov}\")\n",
    "        for r, coefs in enumerate(coefs_regimes):\n",
    "            print(f\"\\n--- Coeficientes para Regime (Cluster) {r} ---\")\n",
    "            if not np.isnan(coefs).any():\n",
    "                print(f\"  const: {coefs[0]:.6f}\")\n",
    "                for i, pred_name in enumerate(predictors_markov):\n",
    "                     if i+1 < len(coefs): print(f\"  {pred_name}: {coefs[i+1]:.6f}\")\n",
    "            else:\n",
    "                 print(\"  (Coeficientes NaN - dados insuficientes)\")\n",
    "\n",
    "        print(f\"\\n√öltimo regime observado: {ultimo_regime}\")\n",
    "        print(f\"‚Üí Coeficientes do Regime {ultimo_regime} ser√£o usados para o backcasting.\")\n",
    "    else:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SUM√ÅRIO DO FALLBACK (K-Means + OLS por cluster)\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"‚ö† Fallback K-Means tamb√©m falhou (cluster vazio ou dados insuficientes).\")\n",
    "        df_historico['Gini_Markov'] = np.nan # Define como NaN se o fallback falhar\n",
    "\n",
    "    # Intervalos de confian√ßa fixos no fallback\n",
    "    df_historico['Gini_Markov_Low'] = df_historico['Gini_Markov'] - 0.03 # Intervalo fixo\n",
    "    df_historico['Gini_Markov_High'] = df_historico['Gini_Markov'] + 0.03 # Intervalo fixo\n",
    "    df_moderno['Regime_Inferido'] = regime_mais_provavel\n",
    "    markov_success = False\n",
    "    \n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 3. GENERALIZED ADDITIVE MODELS (GAMs) (com k lags)\n",
    "# ===========================\n",
    "print(f\"\\n[3] GENERALIZED ADDITIVE MODELS (GAMs com k={k_lags_selecionados} Lags)\")\n",
    "predictors_gam = predictors_base + predictors_lags # Combina base + lags\n",
    "print(f\"‚Üí Preditores GAM: {predictors_gam}\")\n",
    "\n",
    "X_gam_treino = df_moderno[predictors_gam].values\n",
    "y_gam_treino = df_moderno['Gini_Observado'].values\n",
    "\n",
    "# --- Ajustar n_splines_list e gam_terms dinamicamente ---\n",
    "n_splines_base = [8, 6, 6, 6]\n",
    "n_splines_lags = [6] * k_lags_selecionados\n",
    "n_splines_list = n_splines_base + n_splines_lags\n",
    "print(f\"  (N√∫mero de splines por preditor: {n_splines_list})\")\n",
    "\n",
    "gam_terms = None\n",
    "num_total_predictors_gam = len(predictors_gam)\n",
    "for i in range(num_total_predictors_gam):\n",
    "    term = s(i, n_splines=n_splines_list[i])\n",
    "    if gam_terms is None:\n",
    "        gam_terms = term\n",
    "    else:\n",
    "        gam_terms += term\n",
    "# --- Fim do ajuste ---\n",
    "\n",
    "\n",
    "with tqdm(total=100, desc=\"GAM\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "    pbar.set_postfix_str(\"Grid search...\")\n",
    "    gam_model = LinearGAM(gam_terms)\n",
    "\n",
    "    gam_model.gridsearch(X_gam_treino, y_gam_treino)\n",
    "    pbar.update(70)\n",
    "\n",
    "    X_gam_historico = df_historico[predictors_gam].values\n",
    "    df_historico['Gini_GAM'] = gam_model.predict(X_gam_historico)\n",
    "    pbar.update(20)\n",
    "\n",
    "    gam_intervals = gam_model.prediction_intervals(X_gam_historico, width=0.95)\n",
    "    df_historico['Gini_GAM_Low'] = gam_intervals[:, 0]\n",
    "    df_historico['Gini_GAM_High'] = gam_intervals[:, 1]\n",
    "    pbar.update(10)\n",
    "\n",
    "print(f\"‚úì Pseudo R¬≤: {gam_model.statistics_['pseudo_r2']['explained_deviance']:.4f}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUM√ÅRIO DO MODELO GAM (treinado nos dados modernos)\")\n",
    "print(\"=\"*80)\n",
    "print(gam_model.summary())\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 4. S√âRIE TEMPORAL ESTRUTURAL (UCM )\n",
    "# ===========================\n",
    "print(\"\\n[4] MODELO DE S√âRIE TEMPORAL ESTRUTURAL (UCM)\")\n",
    "ts_data = df_moderno.set_index('Ano')['Gini_Observado']\n",
    "\n",
    "with tqdm(total=100, desc=\"TimeSeries\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "    pbar.set_postfix_str(\"Modelo forward...\")\n",
    "    modelo_uc = UnobservedComponents(\n",
    "        ts_data, level='local linear trend', cycle=True,\n",
    "        stochastic_cycle=True, damped_cycle=True, irregular=True\n",
    "    )\n",
    "    resultado_uc = modelo_uc.fit(disp=False)\n",
    "    pbar.update(40)\n",
    "\n",
    "    pbar.set_postfix_str(\"Modelo backward...\")\n",
    "    ts_invertida = ts_data[::-1]\n",
    "    modelo_uc_inv = UnobservedComponents(\n",
    "        ts_invertida, level='local linear trend', cycle=True,\n",
    "        stochastic_cycle=True, damped_cycle=True, irregular=True\n",
    "    )\n",
    "    resultado_uc_inv = modelo_uc_inv.fit(disp=False)\n",
    "    pbar.update(40)\n",
    "\n",
    "    pbar.set_postfix_str(\"Backcasting...\")\n",
    "    forecast_inv = resultado_uc_inv.forecast(steps=n_historico)\n",
    "    df_historico['Gini_TimeSeries'] = forecast_inv[::-1].values\n",
    "    forecast_summary = resultado_uc_inv.get_forecast(steps=n_historico).summary_frame(alpha=0.05)\n",
    "    df_historico['Gini_TS_Low'] = forecast_summary['mean_ci_lower'][::-1].values\n",
    "    df_historico['Gini_TS_High'] = forecast_summary['mean_ci_upper'][::-1].values\n",
    "    pbar.update(20)\n",
    "\n",
    "print(f\"‚úì AIC (modelo forward): {resultado_uc.aic:.2f}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUM√ÅRIO DO MODELO UCM (treinado nos dados modernos - forward)\")\n",
    "print(\"=\"*80)\n",
    "print(resultado_uc.summary())\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e4a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 6. MODELO BAYESIANO HIER√ÅRQUICO (com k lags)\n",
    "# ===========================\n",
    "print(f\"\\n[6] MODELO BAYESIANO HIER√ÅRQUICO (OTIMIZADO com k={k_lags_selecionados} Lags)\")\n",
    "\n",
    "if df_moderno.empty or len(df_moderno) < 10:\n",
    "    print(\"‚ö† Dados insuficientes para modelo Bayesiano. Pulando...\")\n",
    "    df_historico['Gini_Bayes_Hierarquico'] = np.nan\n",
    "    df_historico['Gini_Bayes_Low'] = np.nan\n",
    "    df_historico['Gini_Bayes_High'] = np.nan\n",
    "else:\n",
    "    # --- Atualizar colunas para normaliza√ß√£o e coords ---\n",
    "    print(f\"‚Üí Normalizando preditores (incluindo {k_lags_selecionados} lags)...\")\n",
    "    scaler_bayes = StandardScaler()\n",
    "    cols_norm_bayes = predictors_base + predictors_lags # Usa k lags\n",
    "    norm_cols_names_bayes = [col + '_norm' for col in predictors_base] + \\\n",
    "                            [col + '_norm' for col in predictors_lags] # Nomes normalizados\n",
    "    print(f\"  (Colunas normalizadas: {norm_cols_names_bayes})\")\n",
    "\n",
    "    df[norm_cols_names_bayes] = scaler_bayes.fit_transform(df[cols_norm_bayes])\n",
    "\n",
    "    mask_historico = df['Ano'] < ano_inicio_pnad\n",
    "    mask_moderno = df['Ano'] >= ano_inicio_pnad\n",
    "    historico_idx = np.where(mask_historico)[0]\n",
    "    moderno_idx = np.where(mask_moderno)[0]\n",
    "\n",
    "    coords = {\"preditores\": norm_cols_names_bayes} # Atualizado coords\n",
    "    X_data_total = df[coords[\"preditores\"]].values\n",
    "    # --- Fim da atualiza√ß√£o ---\n",
    "\n",
    "    gini_col = 'Gini_Observado'\n",
    "    if gini_col not in df_moderno.columns:\n",
    "         gini_col = 'Gini_Verdadeiro'; print(f\"‚Üí Usando coluna: '{gini_col}'\")\n",
    "\n",
    "    try:\n",
    "        y_observado = df_moderno[gini_col].dropna().values\n",
    "        print(f\"‚Üí Usando {len(y_observado)} observa√ß√µes de df_moderno['{gini_col}']\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Erro ao extrair y_observado: {e}\"); raise\n",
    "\n",
    "    n_total = len(df)\n",
    "    bayesian_run_success = False\n",
    "    trace_avancado = None\n",
    "\n",
    "    with pm.Model(coords=coords) as modelo_bayes_avancado:\n",
    "        alpha = pm.Normal('alpha', mu=0.55, sigma=0.1)\n",
    "        # --- O modelo adapta-se automaticamente aos preditores via dims ---\n",
    "        betas = pm.Normal('betas', mu=0, sigma=0.3, dims=\"preditores\")\n",
    "        # --- Fim da adapta√ß√£o ---\n",
    "\n",
    "        sigma_temporal = pm.HalfNormal('sigma_temporal', sigma=0.01)\n",
    "        tendencia_passos = pm.Normal('tendencia_passos', mu=0, sigma=sigma_temporal, shape=n_total)\n",
    "        tendencia = pm.Deterministic('tendencia', pm.math.cumsum(tendencia_passos))\n",
    "\n",
    "        sigma = pm.HalfNormal('sigma', sigma=0.02)\n",
    "        mu = alpha + pm.math.dot(X_data_total, betas) + tendencia # Usa X_data_total com k lags norm\n",
    "\n",
    "        y_obs = pm.Normal('y_obs', mu=mu[moderno_idx], sigma=sigma, observed=y_observado)\n",
    "        mu_hist = pm.Deterministic('mu_hist', mu[historico_idx])\n",
    "\n",
    "        print(\"‚Üí Amostragem MCMC: 4 chains √ó 3000 itera√ß√µes\")\n",
    "        print(\"  (target_accept=0.95)\")\n",
    "        samplers_config = [(\"blackjax\", {\"sampler\": \"blackjax\"}), (\"nuts\", {})]\n",
    "\n",
    "        for sampler_name, sampler_kwargs in samplers_config:\n",
    "            try:\n",
    "                trace_avancado = pm.sample(draws=1500, tune=1500, chains=4, target_accept=0.95, progressbar=True, return_inferencedata=True, **sampler_kwargs)\n",
    "                print(f\"‚úì {sampler_name.upper()} usado com sucesso\")\n",
    "                bayesian_run_success = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† {sampler_name.upper()} falhou: {str(e)[:100]}\")\n",
    "                if sampler_name == samplers_config[-1][0]: print(\"‚úó Todos os samplers falharam\")\n",
    "                else: print(\"‚Üí Tentando pr√≥ximo sampler...\")\n",
    "\n",
    "    if bayesian_run_success and trace_avancado is not None:\n",
    "        print(\"\\n\" + \"=\"*70); print(\"DIAGN√ìSTICOS DO MODELO\"); print(\"=\"*70)\n",
    "        try:\n",
    "            rhat = az.rhat(trace_avancado, var_names=[\"alpha\", \"betas\"])\n",
    "            ess = az.ess(trace_avancado, var_names=[\"alpha\", \"betas\"])\n",
    "            print(f\"R-hat m√°ximo: {rhat.max().values:.4f} (ideal < 1.01)\")\n",
    "            print(f\"ESS m√≠nimo: {ess.min().values:.0f} (ideal > 400)\")\n",
    "            summary_bayes = az.summary(trace_avancado, var_names=[\"alpha\", \"betas\", \"sigma_temporal\", \"sigma\"], stat_focus=\"median\")\n",
    "            print(\"\\nPAR√ÇMETROS PRINCIPAIS:\"); print(summary_bayes[['mean', 'sd', 'hdi_3%', 'hdi_97%', 'r_hat']])\n",
    "        except Exception as e: print(f\"‚ö† Erro nos diagn√≥sticos: {e}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        try:\n",
    "            print(\"\\n‚Üí Extraindo predi√ß√µes posteriores...\")\n",
    "            posterior_pred = trace_avancado.posterior['mu_hist']\n",
    "            df_historico['Gini_Bayes_Hierarquico'] = posterior_pred.mean(dim=['chain', 'draw']).values\n",
    "            hdi = az.hdi(posterior_pred, hdi_prob=0.95)\n",
    "            df_historico['Gini_Bayes_Low'] = hdi['mu_hist'].sel(hdi='lower').values\n",
    "            df_historico['Gini_Bayes_High'] = hdi['mu_hist'].sel(hdi='higher').values\n",
    "            print(f\"‚úì Predi√ß√µes extra√≠das ({len(df_historico)} anos)\")\n",
    "        except KeyError as e:\n",
    "            print(f\"‚ö† Vari√°vel n√£o encontrada no trace: {e} ‚Üí Usando fallback (NaN)\"); df_historico[['Gini_Bayes_Hierarquico', 'Gini_Bayes_Low', 'Gini_Bayes_High']] = np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Erro inesperado na extra√ß√£o: {e}\"); df_historico[['Gini_Bayes_Hierarquico', 'Gini_Bayes_Low', 'Gini_Bayes_High']] = np.nan\n",
    "    else:\n",
    "        print(\"\\n‚ö† Amostragem MCMC falhou completamente ‚Üí S√©rie Bayesiana n√£o dispon√≠vel\"); df_historico[['Gini_Bayes_Hierarquico', 'Gini_Bayes_Low', 'Gini_Bayes_High']] = np.nan\n",
    "\n",
    "print(\"\\n‚úì Etapa Bayesiana conclu√≠da\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c21bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 7. COMPUTA√á√ÉO QU√ÇNTICA (QAOA)\n",
    "# ===========================\n",
    "print(f\"\\n[7] COMPUTA√á√ÉO QU√ÇNTICA: QAOA (com k={k_lags_selecionados} Lags)\")\n",
    "\n",
    "# --- Atualizar preditores e n√∫mero de vari√°veis/qubits ---\n",
    "predictors_qaoa = predictors_base + predictors_lags\n",
    "print(f\"‚Üí Preditores QAOA: {predictors_qaoa}\")\n",
    "n_vars = len(predictors_qaoa)\n",
    "n_bits = 2\n",
    "n_qubits = n_vars * n_bits\n",
    "print(f\"‚ö† Vers√£o otimizada: {n_qubits} qubits ({n_vars} vars √ó {n_bits} bits/var), 30 itera√ß√µes\")\n",
    "\n",
    "X_quantum = df_moderno[predictors_qaoa].values\n",
    "y_quantum = df_moderno['Gini_Observado'].values\n",
    "\n",
    "# Normaliza√ß√£o\n",
    "X_min = X_quantum.min(axis=0); X_max = X_quantum.max(axis=0)\n",
    "y_min = y_quantum.min(); y_max = y_quantum.max()\n",
    "X_quantum_norm = 2 * (X_quantum - X_min) / (X_max - X_min) - 1\n",
    "y_quantum_norm = 2 * (y_quantum - y_min) / (y_max - y_min) - 1\n",
    "\n",
    "# ***** CORRE√á√ÉO: Usar n_moderno (47 obs) em vez de 5 *****\n",
    "# n_samples = 5 (REMOVIDO)\n",
    "# X_q = X_quantum_norm[:n_samples]; y_q = y_quantum_norm[:n_samples] (REMOVIDO)\n",
    "\n",
    "# Usar todos os dados modernos (47 observa√ß√µes)\n",
    "X_q = X_quantum_norm \n",
    "y_q = y_quantum_norm\n",
    "print(f\"‚Üí Usando {len(X_q)} observa√ß√µes para construir o problema QUBO.\")\n",
    "# ***** FIM DA CORRE√á√ÉO *****\n",
    "\n",
    "XtX = X_q.T @ X_q; Xty = X_q.T @ y_q\n",
    "\n",
    "qp = QuadraticProgram()\n",
    "\n",
    "with tqdm(total=100, desc=\"QAOA\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "    pbar.set_postfix_str(\"Montando problema...\")\n",
    "    \n",
    "    # Criar vari√°veis bin√°rias\n",
    "    for i in range(n_vars):\n",
    "        for j in range(n_bits):\n",
    "            qp.binary_var(f'beta_{i}_{j}')\n",
    "\n",
    "    # Criar termos linear e quadr√°tico\n",
    "    linear = {}; quadratic = {}\n",
    "    for i in range(n_vars):\n",
    "        for b in range(n_bits):\n",
    "            var_name = f'beta_{i}_{b}'; weight = 2 ** b\n",
    "            linear[var_name] = -2 * Xty[i] * weight\n",
    "            for j in range(n_vars):\n",
    "                for b2 in range(n_bits):\n",
    "                    var_name2 = f'beta_{j}_{b2}'; weight2 = 2 ** b2\n",
    "                    if var_name <= var_name2:\n",
    "                        quadratic[(var_name, var_name2)] = XtX[i, j] * weight * weight2\n",
    "\n",
    "    qp.minimize(linear=linear, quadratic=quadratic)\n",
    "    pbar.update(20)\n",
    "\n",
    "    try:\n",
    "        pbar.set_postfix_str(\"Inicializando QAOA...\")\n",
    "        \n",
    "        # ===== API Qiskit 1.0+ =====\n",
    "        from qiskit_optimization.converters import QuadraticProgramToQubo\n",
    "        converter = QuadraticProgramToQubo()\n",
    "        qubo = converter.convert(qp)\n",
    "        \n",
    "        operator, offset = qubo.to_ising()\n",
    "        \n",
    "        from qiskit.circuit.library import QAOAAnsatz\n",
    "        ansatz = QAOAAnsatz(operator, reps=2)\n",
    "        \n",
    "        from qiskit_algorithms import SamplingVQE\n",
    "        \n",
    "        try:\n",
    "            from qiskit.primitives import StatevectorSampler as Sampler\n",
    "        except ImportError:\n",
    "            try:\n",
    "                from qiskit_aer.primitives import Sampler\n",
    "            except ImportError:\n",
    "                from qiskit.primitives.backend_sampler import BackendSampler\n",
    "                from qiskit_aer import AerSimulator\n",
    "                backend = AerSimulator()\n",
    "                Sampler = lambda: BackendSampler(backend=backend)\n",
    "        \n",
    "        sampler = Sampler()\n",
    "        qaoa_solver = SamplingVQE(\n",
    "            sampler=sampler,\n",
    "            ansatz=ansatz,\n",
    "            optimizer=COBYLA(maxiter=30)\n",
    "        )\n",
    "        \n",
    "        pbar.update(10)\n",
    "        pbar.set_postfix_str(\"Otimizando (30 iter)...\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        resultado = qaoa_solver.compute_minimum_eigenvalue(operator)\n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
    "        optimizer_wrapper = MinimumEigenOptimizer(qaoa_solver)\n",
    "        resultado_qaoa = optimizer_wrapper.solve(qp)\n",
    "        \n",
    "        pbar.update(60)\n",
    "\n",
    "        # Reconstruir coeficientes\n",
    "        coefs_quanticos = np.zeros(n_vars)\n",
    "        for i in range(n_vars):\n",
    "            for b in range(n_bits):\n",
    "                var_name = f'beta_{i}_{b}'\n",
    "                if var_name in resultado_qaoa.variables_dict:\n",
    "                    coefs_quanticos[i] += resultado_qaoa.variables_dict[var_name] * (2 ** b)\n",
    "\n",
    "        coefs_quanticos_norm = coefs_quanticos / (2 ** n_bits)\n",
    "        coefs_quanticos_final = coefs_quanticos_norm * 0.2 - 0.1\n",
    "\n",
    "        # Fazer predi√ß√µes\n",
    "        X_hist_qaoa = df_historico[predictors_qaoa].values\n",
    "        X_hist_norm = 2 * (X_hist_qaoa - X_min) / (X_max - X_min) - 1\n",
    "        pred_quantum_norm = X_hist_norm @ coefs_quanticos_final\n",
    "        df_historico['Gini_Quantum'] = (pred_quantum_norm + 1) / 2 * (y_max - y_min) + y_min\n",
    "        \n",
    "        pbar.update(10)\n",
    "        quantum_success = True\n",
    "        print(f\"‚úì Conclu√≠do em {elapsed:.1f}s\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"SUM√ÅRIO DO MODELO QU√ÇNTICO (QAOA com k={k_lags_selecionados} Lags)\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"--- Resultado Bruto (Bits √ìtimos) ---\")\n",
    "        print(resultado_qaoa)\n",
    "        print(\"\\n--- Coeficientes Finais Reconstru√≠dos ---\")\n",
    "        print(f\" (Valores de {n_bits} bits antes da normaliza√ß√£o: {coefs_quanticos})\")\n",
    "        print(f\" (Valores normalizados [0,1]: {coefs_quanticos_norm})\")\n",
    "        print(\"\\nCoeficientes Finais (usados na previs√£o):\")\n",
    "        for i, name in enumerate(predictors_qaoa):\n",
    "            print(f\"  beta_{name}: {coefs_quanticos_final[i]:.6f}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Falhou: {e}\")\n",
    "        print(f\"   Tipo do erro: {type(e).__name__}\")\n",
    "        import traceback\n",
    "        print(\"   Traceback:\")\n",
    "        traceback.print_exc()\n",
    "        print(\"‚Üí Usando fallback OLS\")\n",
    "        df_historico['Gini_Quantum'] = df_historico['Gini_OLS']\n",
    "        quantum_success = False\n",
    "\n",
    "print(\"\\n================================================================================\")\n",
    "print(\"‚úì PIPELINE COMPLETO\")\n",
    "print(\"================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e73094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 8. MACHINE LEARNING (RF & GBT) - OTIMIZADO GPU (cuML & XGBoost)\n",
    "# ===========================\n",
    "\n",
    "print(f\"\\n[8] MACHINE LEARNING (RF & GBT com k={k_lags_selecionados} Lags) - GPU\")\n",
    "\n",
    "predictors_ml = predictors_base + predictors_lags\n",
    "print(f\"‚Üí Preditores ML: {predictors_ml}\")\n",
    "\n",
    "# Prepara dados (Numpy arrays s√£o aceitos por cuml e xgboost)\n",
    "ml_data_np = df_moderno[['Gini_Observado'] + predictors_ml].copy().dropna()\n",
    "target_column = 'Gini_Observado'\n",
    "X_treino_ml = ml_data_np[predictors_ml].values\n",
    "y_treino_ml = ml_data_np[target_column].values\n",
    "\n",
    "print(f\"  (Observa√ß√µes usadas para treino ML ap√≥s dropna: {len(X_treino_ml)})\")\n",
    "\n",
    "# Prepara dados hist√≥ricos para predi√ß√£o\n",
    "X_hist_ml_pd = df_historico[['Ano'] + predictors_ml].copy()\n",
    "nan_mask_hist_ml = X_hist_ml_pd[predictors_ml].isnull().any(axis=1)\n",
    "X_hist_ml_clean = X_hist_ml_pd.loc[~nan_mask_hist_ml, predictors_ml].values # Numpy array\n",
    "\n",
    "# Inicializa colunas de previs√£o\n",
    "df_historico['Gini_YDF_GBT'] = np.nan # Renomear para Gini_ML_GBT\n",
    "df_historico['Gini_YDF_RF'] = np.nan  # Renomear para Gini_ML_RF\n",
    "\n",
    "if USE_GPU_ML and len(X_treino_ml) > 0 and len(X_hist_ml_clean) > 0:\n",
    "    \n",
    "    # --- Gradient Boosted Trees (XGBoost) ---\n",
    "    with tqdm(total=100, desc=\"XGBoost GBT (GPU)\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "        pbar.set_postfix_str(\"Treinando (GPU)...\")\n",
    "        gbt_model = xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            tree_method='gpu_hist', # <--- M√ÅGICA DA GPU\n",
    "            n_estimators=100,\n",
    "            random_state=42\n",
    "        )\n",
    "        gbt_model.fit(X_treino_ml, y_treino_ml)\n",
    "        pbar.update(70)\n",
    "\n",
    "        pbar.set_postfix_str(\"Prevendo (GPU)...\")\n",
    "        predictions_gbt_clean = gbt_model.predict(X_hist_ml_clean)\n",
    "        df_historico.loc[~nan_mask_hist_ml, 'Gini_YDF_GBT'] = predictions_gbt_clean\n",
    "        print(\"\\n‚úì XGBoost GBT treinado e previs√µes geradas (GPU).\")\n",
    "        pbar.update(30)\n",
    "\n",
    "    # --- Random Forest (cuML) ---\n",
    "    with tqdm(total=100, desc=\"cuML RandForest (GPU)\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "        pbar.set_postfix_str(\"Treinando (GPU)...\")\n",
    "        rf_model = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            random_state=42\n",
    "            # Outros hiperpar√¢metros (max_depth, etc.)\n",
    "        )\n",
    "        rf_model.fit(X_treino_ml, y_treino_ml)\n",
    "        pbar.update(70)\n",
    "\n",
    "        pbar.set_postfix_str(\"Prevendo (GPU)...\")\n",
    "        predictions_rf_clean_gpu = rf_model.predict(X_hist_ml_clean)\n",
    "        \n",
    "        # Copia da GPU para a CPU\n",
    "        if hasattr(predictions_rf_clean_gpu, 'get'):\n",
    "             df_historico.loc[~nan_mask_hist_ml, 'Gini_YDF_RF'] = predictions_rf_clean_gpu.get()\n",
    "        else:\n",
    "             df_historico.loc[~nan_mask_hist_ml, 'Gini_YDF_RF'] = predictions_rf_clean_gpu\n",
    "             \n",
    "        print(\"\\n‚úì cuML Random Forest treinado e previs√µes geradas (GPU).\")\n",
    "        pbar.update(30)\n",
    "\n",
    "else:\n",
    "    # --- Fallback para YDF (CPU) ---\n",
    "    print(\"\\nExecutando fallback para YDF (CPU)...\")\n",
    "    ml_data_pd = df_moderno[['Gini_Observado'] + predictors_ml].copy().dropna()\n",
    "    X_hist_ml_clean_pd = X_hist_ml_pd.loc[~nan_mask_hist_ml, predictors_ml]\n",
    "    \n",
    "    if ydf and not ml_data_pd.empty and not X_hist_ml_clean_pd.empty:\n",
    "        try:\n",
    "            # GBT (YDF)\n",
    "            with tqdm(total=100, desc=\"YDF GBT (CPU)\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "                gbt_learner = ydf.GradientBoostedTreesLearner(label=target_column, task=ydf.Task.REGRESSION)\n",
    "                gbt_model = gbt_learner.train(ml_data_pd)\n",
    "                pbar.update(70)\n",
    "                predictions_gbt_clean = gbt_model.predict(X_hist_ml_clean_pd)\n",
    "                df_historico.loc[~nan_mask_hist_ml, 'Gini_YDF_GBT'] = predictions_gbt_clean\n",
    "                pbar.update(30)\n",
    "            \n",
    "            # RF (YDF)\n",
    "            with tqdm(total=100, desc=\"YDF RandForest (CPU)\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "                rf_learner = ydf.RandomForestLearner(label=target_column, task=ydf.Task.REGRESSION)\n",
    "                rf_model = rf_learner.train(ml_data_pd)\n",
    "                pbar.update(70)\n",
    "                predictions_rf_clean = rf_model.predict(X_hist_ml_clean_pd)\n",
    "                df_historico.loc[~nan_mask_hist_ml, 'Gini_YDF_RF'] = predictions_rf_clean\n",
    "                pbar.update(30)\n",
    "            \n",
    "            print(\"\\n‚úì YDF (CPU) treinado e previs√µes geradas.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚úó Erro durante o treinamento/previs√£o com YDF (CPU): {e}\")\n",
    "    else:\n",
    "        print(\"‚ö† YDF pulado (sem biblioteca ou dados insuficientes).\")\n",
    "\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27439f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 9. TESTE DE CAUSALIDADE DE GRANGER E MODELO VARMAX (com k lags)\n",
    "# ==========================================================\n",
    "\n",
    "print(f\"\\n[9] TESTE GRANGER E MODELO VARMAX (com k={k_lags_selecionados} Lags)\")\n",
    "\n",
    "# --- 9.a Teste de Causalidade de Granger ---\n",
    "print(\"\\n--- Iniciando Teste de Causalidade de Granger ---\")\n",
    "\n",
    "# Testar causalidade APENAS nas vari√°veis base.\n",
    "potential_vars = ['Gini_Observado'] + predictors_base \n",
    "print(f\"Vari√°veis potenciais para teste: {potential_vars}\")\n",
    "\n",
    "# Preparar dados para o teste (modernos, diferenciados para estacionariedade)\n",
    "granger_data_raw = df_moderno[potential_vars].copy().dropna()\n",
    "\n",
    "endog_cols = ['Gini_Observado'] # Gini √© sempre end√≥geno\n",
    "exog_cols = []\n",
    "\n",
    "if len(granger_data_raw) > k_lags_selecionados + 5: # Checa se h√° dados suficientes ap√≥s diferencia√ß√£o e lags\n",
    "    granger_data_diff = granger_data_raw.diff().dropna()\n",
    "    print(f\"Observa√ß√µes usadas para teste Granger (ap√≥s diff e dropna): {len(granger_data_diff)}\")\n",
    "\n",
    "    granger_results = {}\n",
    "    tested_pairs = set()\n",
    "\n",
    "    print(\"\\nResultados do Teste (p-valor < 0.05 indica causalidade):\")\n",
    "    for col1 in potential_vars:\n",
    "        for col2 in potential_vars:\n",
    "            if col1 == col2:\n",
    "                continue\n",
    "            pair = tuple(sorted((col1, col2))) \n",
    "            if pair in tested_pairs:\n",
    "                continue\n",
    "            tested_pairs.add(pair)\n",
    "\n",
    "            # Testar se col2 Granger-causa col1\n",
    "            try:\n",
    "                test_result_12 = grangercausalitytests(granger_data_diff[[col1, col2]], maxlag=k_lags_selecionados, verbose=False)\n",
    "                p_value_12 = test_result_12[k_lags_selecionados][0]['ssr_ftest'][1]\n",
    "                if p_value_12 < 0.05:\n",
    "                    print(f\"  ‚Üí {col2} Granger-causa {col1} (p={p_value_12:.4f})\")\n",
    "                    if col1 == 'Gini_Observado' and col2 not in endog_cols:\n",
    "                        endog_cols.append(col2)\n",
    "                    elif col2 == 'Gini_Observado' and col1 not in endog_cols:\n",
    "                        endog_cols.append(col1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  ! Erro ao testar {col2} -> {col1}: {e}\")\n",
    "\n",
    "            # Testar se col1 Granger-causa col2\n",
    "            try:\n",
    "                test_result_21 = grangercausalitytests(granger_data_diff[[col2, col1]], maxlag=k_lags_selecionados, verbose=False)\n",
    "                p_value_21 = test_result_21[k_lags_selecionados][0]['ssr_ftest'][1]\n",
    "                if p_value_21 < 0.05:\n",
    "                     print(f\"  ‚Üí {col1} Granger-causa {col2} (p={p_value_21:.4f})\")\n",
    "                     if col2 == 'Gini_Observado' and col1 not in endog_cols:\n",
    "                         endog_cols.append(col1)\n",
    "                     elif col1 == 'Gini_Observado' and col2 not in endog_cols:\n",
    "                          endog_cols.append(col2)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  ! Erro ao testar {col1} -> {col2}: {e}\")\n",
    "\n",
    "    # Ex√≥genos s√£o as vari√°veis BASE restantes\n",
    "    exog_cols = [col for col in predictors_base if col not in endog_cols]\n",
    "\n",
    "    print(\"\\n--- Vari√°veis Selecionadas ---\")\n",
    "    print(f\"Vari√°veis End√≥genas para VARMAX: {endog_cols}\")\n",
    "    print(f\"Vari√°veis Ex√≥genas para VARMAX: {exog_cols}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # --- 9.b Modelo VARMAX (MODIFICADO para usar dados diferenciados) ---\n",
    "    print(\"\\n--- Iniciando Modelo VARMAX (com dados diferenciados) ---\")\n",
    "    \n",
    "    # 1. Preparar dados de treino (diferenciados)\n",
    "    varmax_data_fit_raw = df_moderno[endog_cols + exog_cols].copy().dropna()\n",
    "    varmax_data_fit_diff = varmax_data_fit_raw.diff().dropna() # N=46 (1977-2022)\n",
    "\n",
    "    endog_varmax_fit = varmax_data_fit_diff[endog_cols]\n",
    "    exog_varmax_fit = varmax_data_fit_diff[exog_cols] if exog_cols else None \n",
    "    print(f\"Observa√ß√µes usadas para ajuste VARMAX (ap√≥s diff e dropna): {len(endog_varmax_fit)}\")\n",
    "\n",
    "    # Guardar o √∫ltimo valor conhecido (primeiro do per√≠odo moderno) para reintegrar\n",
    "    gini_col_name = 'Gini_Observado'\n",
    "    last_known_value_gini = df_moderno[gini_col_name].iloc[0] # Valor de 1976\n",
    "    print(f\"  (Valor base para reintegra√ß√£o Gini (Ano {ano_inicio_pnad}): {last_known_value_gini:.4f})\")\n",
    "\n",
    "    df_historico['Gini_VARMAX'] = np.nan\n",
    "    df_historico['Gini_VARMAX_Low'] = np.nan\n",
    "    df_historico['Gini_VARMAX_High'] = np.nan\n",
    "    resultado_varmax_inv = None \n",
    "\n",
    "    min_obs_needed = k_lags_selecionados * (len(endog_cols)**2) + len(endog_cols) \n",
    "    \n",
    "    # 2. Checar se temos dados suficientes AP√ìS diferenciar\n",
    "    if len(endog_varmax_fit) > min_obs_needed + 5: \n",
    "         with tqdm(total=100, desc=\"VARMAX (Diff)\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "              try:\n",
    "                   pbar.set_postfix_str(\"Preparando dados invertidos (diff)...\")\n",
    "                   endog_invertido = endog_varmax_fit[::-1]\n",
    "                   exog_invertido = exog_varmax_fit[::-1] if exog_varmax_fit is not None else None\n",
    "                   pbar.update(10)\n",
    "\n",
    "                   pbar.set_postfix_str(\"Ajustando VARMAX (ordem (1,0))...\")\n",
    "                   modelo_varmax_inv = VARMAX(endog=endog_invertido, exog=exog_invertido, order=(k_lags_selecionados, 0))\n",
    "\n",
    "                   try:\n",
    "                        # Tentar ajuste padr√£o\n",
    "                        resultado_varmax_inv = modelo_varmax_inv.fit(disp=False, maxiter=200) \n",
    "                   except (np.linalg.LinAlgError, ValueError) as fit_err:\n",
    "                        print(f\"\\n‚ö† Erro ao ajustar VARMAX inicial ({fit_err}), tentando simplificar...\")\n",
    "                        try:\n",
    "                             # Tentar fallback com otimizador powell\n",
    "                             modelo_varmax_inv = VARMAX(endog=endog_invertido, exog=exog_invertido, order=(k_lags_selecionados, 0), trend='c')\n",
    "                             resultado_varmax_inv = modelo_varmax_inv.fit(disp=False, maxiter=200, method='powell')\n",
    "                        except Exception as fit_err_2:\n",
    "                             print(f\"\\n‚ö† Falha ao ajustar VARMAX simplificado: {fit_err_2}\")\n",
    "                             resultado_varmax_inv = None\n",
    "\n",
    "                   pbar.update(60)\n",
    "\n",
    "                   if resultado_varmax_inv is not None and resultado_varmax_inv.mle_retvals['converged']:\n",
    "                        pbar.set_postfix_str(\"Backcasting (diff)...\")\n",
    "                        \n",
    "                        # 3. Preparar ex√≥genas hist√≥ricas (diferenciadas e invertidas)\n",
    "                        X_hist_varmax_exog = None\n",
    "                        if exog_cols: \n",
    "                            X_hist_varmax_exog_raw = df_historico[exog_cols].copy()\n",
    "                            X_hist_varmax_exog_raw.fillna(method='ffill', inplace=True) # Preenche NaNs (se houver)\n",
    "                            X_hist_varmax_exog_raw.fillna(method='bfill', inplace=True)\n",
    "                            \n",
    "                            X_hist_varmax_exog_diff = X_hist_varmax_exog_raw.diff()\n",
    "                            X_hist_varmax_exog_diff.fillna(method='bfill', inplace=True) # Preenche o NaN inicial\n",
    "                            \n",
    "                            X_hist_varmax_exog = X_hist_varmax_exog_diff[::-1].values # Inverte\n",
    "                        \n",
    "                        # 4. Obter previs√£o (ainda em dados diferenciados)\n",
    "                        forecast_inv = resultado_varmax_inv.get_forecast(steps=n_historico, exog=X_hist_varmax_exog)\n",
    "                        forecast_summary = forecast_inv.summary_frame(alpha=0.05)\n",
    "                        \n",
    "                        try:\n",
    "                            # ***** CORRE√á√ÉO 4: Nomes de coluna corretos para extra√ß√£o *****\n",
    "                            # O summary_frame() usa 'mean', 'mean_ci_lower', etc.\n",
    "                            # Se a vari√°vel end√≥gena for 'Gini_Observado', o NOME do index ser√° 'Gini_Observado',\n",
    "                            # mas o NOME DA COLUNA ser√° 'mean'.\n",
    "                            \n",
    "                            # O nome da coluna de m√©dia no summary_frame\n",
    "                            mean_col_name = 'mean'\n",
    "                            lower_col_name = 'mean_ci_lower'\n",
    "                            upper_col_name = 'mean_ci_upper'\n",
    "                            \n",
    "                            # O nome da coluna espec√≠fica no DataFrame multivariado (se houver mais de uma endog)\n",
    "                            gini_series_name_in_forecast = 'Gini_Observado' \n",
    "                            \n",
    "                            # Checa se o forecast √© multivariado (retorna um MultiIndex)\n",
    "                            if isinstance(forecast_summary.columns, pd.MultiIndex):\n",
    "                                print(\"  (Detectado forecast multivariado, selecionando 'Gini_Observado')\")\n",
    "                                predicted_diffs_inv = forecast_summary[gini_series_name_in_forecast][mean_col_name]\n",
    "                                lower_diffs_inv = forecast_summary[gini_series_name_in_forecast][lower_col_name]\n",
    "                                upper_diffs_inv = forecast_summary[gini_series_name_in_forecast][upper_col_name]\n",
    "                            \n",
    "                            # Se for univariado (s√≥ Gini_Observado era end√≥geno)\n",
    "                            elif mean_col_name in forecast_summary.columns:\n",
    "                                print(\"  (Detectado forecast univariado)\")\n",
    "                                predicted_diffs_inv = forecast_summary[mean_col_name]\n",
    "                                lower_diffs_inv = forecast_summary[lower_col_name]\n",
    "                                upper_diffs_inv = forecast_summary[upper_col_name]\n",
    "                            \n",
    "                            else:\n",
    "                                print(f\"‚ö† Coluna de m√©dia '{mean_col_name}' n√£o encontrada no forecast_summary. Colunas dispon√≠veis: {forecast_summary.columns}\")\n",
    "                                print(\"   Verifique a sa√≠da do VARMAX. Backcasting ser√° NaN.\")\n",
    "                                # Pula a reintegra√ß√£o\n",
    "                                raise KeyError(f\"'{mean_col_name}' not in columns\")\n",
    "\n",
    "                                \n",
    "                            # --- 5. REINTEGRA√á√ÉO (CUMSUM INVERTIDO) ---\n",
    "                            # Previs√µes est√£o invertidas (1975, 1974, ..., 1872)\n",
    "                            cumulative_diffs_inv = predicted_diffs_inv.cumsum()\n",
    "                            \n",
    "                            # Y_hist(t) = Y_moderno(t+1) - D_previsto(t+1)\n",
    "                            predicted_levels_inv = last_known_value_gini - cumulative_diffs_inv\n",
    "                            \n",
    "                            # Desinverter (colocar em ordem cronol√≥gica 1872...1975)\n",
    "                            df_historico['Gini_VARMAX'] = predicted_levels_inv[::-1].values\n",
    "                            \n",
    "                            # Reintegrar CIs (m√©todo aproximado, trocando upper/lower por causa da subtra√ß√£o)\n",
    "                            cumulative_lower_inv = lower_diffs_inv.cumsum()\n",
    "                            cumulative_upper_inv = upper_diffs_inv.cumsum()\n",
    "                            \n",
    "                            df_historico['Gini_VARMAX_Low'] = (last_known_value_gini - cumulative_upper_inv)[::-1].values\n",
    "                            df_historico['Gini_VARMAX_High'] = (last_known_value_gini - cumulative_lower_inv)[::-1].values\n",
    "                            # --- FIM DA REINTEGRA√á√ÉO ---\n",
    "                            # ***** FIM DA CORRE√á√ÉO 4 *****\n",
    "\n",
    "                        except KeyError as ke:\n",
    "                             print(f\"‚ö† Coluna n√£o encontrada ao extrair previs√µes/intervalos: {ke}. Colunas dispon√≠veis: {forecast_summary.columns}\")\n",
    "                             print(\"   Verifique a sa√≠da do VARMAX. Backcasting ser√° NaN.\")\n",
    "                        except Exception as e:\n",
    "                             print(f\"‚ö† Erro inesperado na extra√ß√£o de previs√£o VARMAX: {e}\")\n",
    "\n",
    "                        pbar.update(30)\n",
    "                        print(\"\\n‚úì Backcasting VARMAX (Diferenciado) conclu√≠do e reintegrado.\")\n",
    "                        print(f\"‚úì AIC (modelo invertido, diff): {resultado_varmax_inv.aic:.2f}\")\n",
    "                        print(\"\\n\" + \"=\"*80)\n",
    "                        print(\"SUM√ÅRIO DO MODELO VARMAX (treinado nos dados modernos invertidos e diferenciados)\")\n",
    "                        print(\"=\"*80)\n",
    "                        print(resultado_varmax_inv.summary())\n",
    "                        print(\"=\"*80)\n",
    "                   else:\n",
    "                        pbar.update(30)\n",
    "                        print(\"\\n‚ö† Modelo VARMAX (Diferenciado) n√£o convergiu ou falhou no ajuste. Backcasting ser√° NaN.\")\n",
    "\n",
    "              except Exception as e:\n",
    "                   pbar.update(100 - pbar.n)\n",
    "                   print(f\"\\n‚ö† Erro inesperado na etapa VARMAX (Diff): {e}\")\n",
    "                   import traceback\n",
    "                   traceback.print_exc() \n",
    "\n",
    "    else:\n",
    "         print(f\"‚ö† Dados insuficientes ({len(endog_varmax_fit)} obs) para VARMAX ap√≥s diferenciar. Necess√°rio > ~{min_obs_needed + 5}. Pulando...\")\n",
    "\n",
    "else:\n",
    "     print(\"‚ö† Dados insuficientes para teste Granger (ap√≥s diff e dropna). Pulando VARMAX.\")\n",
    "\n",
    "print(\"=\"*80) # Final do bloco VARMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb67bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 10. MODELO H√çBRIDO (MAXENT + BAYESIANO) OTIMIZADO PARA GPU\n",
    "# ====================================================================\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# [Etapa 10.A] MODELO MAXENT (REG. LOG√çSTICA) - ACELERADO POR GPU (cuML)\n",
    "# --------------------------------------------------------------------\n",
    "print(f\"\\n[10.A] MODELO MAXENT (REG. LOG√çSTICA) - GPU c/ cuML\")\n",
    "\n",
    "# ********************************************************************\n",
    "try:\n",
    "    from cuml.linear_model import LogisticRegression\n",
    "    print(\"  ‚Üí Biblioteca 'cuml' (GPU) importada com sucesso.\")\n",
    "except ImportError:\n",
    "    print(\"‚ö† 'cuml' (RAPIDS) n√£o encontrado. Usando fallback para 'sklearn' (CPU).\")\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "# ********************************************************************\n",
    "\n",
    "\n",
    "# Preditores para o modelo de regime. Usamos os mesmos do OLS\n",
    "if 'predictors_ols' not in locals():\n",
    "     predictors_ols = predictors_base + predictors_lags\n",
    "     print(f\"  ‚Üí Preditores OLS n√£o encontrados, recriando: {predictors_ols}\")\n",
    "else:\n",
    "     print(f\"  ‚Üí Usando Preditores OLS: {predictors_ols}\")\n",
    "\n",
    "# 1. Preparar dados de TREINO (modernos)\n",
    "df_moderno_limpo = df_moderno.dropna(subset=predictors_ols + ['Regime_Verdadeiro'])\n",
    "X_treino_maxent = df_moderno_limpo[predictors_ols]\n",
    "y_treino_maxent = df_moderno_limpo['Regime_Verdadeiro']\n",
    "print(f\"  ‚Üí Treinando MaxEnt com {len(y_treino_maxent)} observa√ß√µes modernas.\")\n",
    "\n",
    "# NOTA: O cuML espera que os dados de entrada (X, y) possam ser\n",
    "# convertidos para seus formatos (ex: cuDF ou arrays numpy/cupy).\n",
    "# O Pandas (Numpy) funciona bem.\n",
    "\n",
    "# 2. Treinar o modelo MaxEnt (Regress√£o Log√≠stica Multinomial)\n",
    "# A API do cuML √© quase id√™ntica √† do sklearn\n",
    "maxent_model = LogisticRegression(\n",
    "    multi_class='multinomial', \n",
    "    solver='lbfgs', # O solver 'lbfgs' √© suportado pelo cuML\n",
    "    random_state=42,\n",
    "    max_iter=500 \n",
    ")\n",
    "maxent_model.fit(X_treino_maxent, y_treino_maxent)\n",
    "\n",
    "# 3. Preparar dados TOTAIS para previs√£o\n",
    "X_total_maxent = df[predictors_ols]\n",
    "\n",
    "# 4. Prever probabilidades para TODO o dataset (Rodar√° na GPU)\n",
    "probabilidades_regime = maxent_model.predict_proba(X_total_maxent)\n",
    "\n",
    "# 5. Adicionar probabilidades ao DataFrame 'df' principal\n",
    "#    'probabilidades_regime' pode ser um array CuPy; \n",
    "#    ao atribuir ao Pandas, ele √© copiado da VRAM (GPU) para a RAM (CPU).\n",
    "predictors_regime = [] \n",
    "print(\"  ‚Üí Gerando colunas de probabilidade de regime:\")\n",
    "for i, regime_classe in enumerate(maxent_model.classes_):\n",
    "    col_name = f'Prob_Regime_{regime_classe}'\n",
    "    # Se 'probabilidades_regime' for CuPy, .get() o move para numpy (CPU)\n",
    "    if hasattr(probabilidades_regime, 'get'):\n",
    "         df[col_name] = probabilidades_regime[:, i].get()\n",
    "    else:\n",
    "         df[col_name] = probabilidades_regime[:, i] # Se j√° for numpy (fallback)\n",
    "    predictors_regime.append(col_name)\n",
    "    print(f\"    ‚úì Coluna '{col_name}' criada.\")\n",
    "\n",
    "print(f\"‚úì Preditores de regime para o Bayesiano: {predictors_regime}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# [10.B] MODELO BAYESIANO (COM FEATURES MAXENT) - GPU c/ BlackJAX\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "print(f\"\\n[10.B] MODELO BAYESIANO (OTIMIZADO com k={k_lags_selecionados} Lags + Regimes MaxEnt)\")\n",
    "\n",
    "if 'df_moderno' not in locals() or df_moderno.empty or len(df_moderno) < 10:\n",
    "    print(\"‚ö† Dados insuficientes para modelo Bayesiano. Pulando...\")\n",
    "    df_historico['Gini_Bayes_Hierarquico'] = np.nan\n",
    "    df_historico['Gini_Bayes_Low'] = np.nan\n",
    "    df_historico['Gini_Bayes_High'] = np.nan\n",
    "else:\n",
    "    # --- 1. Normalizar Preditores Originais ---\n",
    "    print(f\"‚Üí Normalizando {k_lags_selecionados} lags e preditores base...\")\n",
    "    scaler_bayes = StandardScaler()\n",
    "    cols_norm_bayes = predictors_base + predictors_lags \n",
    "    norm_cols_names_bayes = [col + '_norm' for col in cols_norm_bayes]\n",
    "    \n",
    "    df[norm_cols_names_bayes] = scaler_bayes.fit_transform(df[cols_norm_bayes])\n",
    "    \n",
    "    # --- 2. Definir Preditores Finais (Normalizados + Probabilidades) ---\n",
    "    if 'predictors_regime' not in locals():\n",
    "         print(\"‚ö† 'predictors_regime' n√£o encontrado. Rodando sem features MaxEnt.\")\n",
    "         predictors_regime = []\n",
    "         \n",
    "    cols_bayes_finais = norm_cols_names_bayes + predictors_regime \n",
    "    print(f\"  (Total de Preditores Finais para Bayes: {len(cols_bayes_finais)})\")\n",
    "\n",
    "    mask_historico = df['Ano'] < ano_inicio_pnad\n",
    "    mask_moderno = df['Ano'] >= ano_inicio_pnad\n",
    "    historico_idx = np.where(mask_historico)[0]\n",
    "    moderno_idx = np.where(mask_moderno)[0]\n",
    "\n",
    "    coords = {\"preditores\": cols_bayes_finais} \n",
    "    X_data_total = df[coords[\"preditores\"]].values\n",
    "\n",
    "    gini_col = 'Gini_Observado'\n",
    "    if gini_col not in df_moderno.columns:\n",
    "         gini_col = 'Gini_Verdadeiro'; print(f\"‚Üí Usando coluna: '{gini_col}'\")\n",
    "\n",
    "    try:\n",
    "         y_observado = df_moderno[gini_col].dropna().values\n",
    "         print(f\"‚Üí Usando {len(y_observado)} observa√ß√µes de df_moderno['{gini_col}']\")\n",
    "    except Exception as e:\n",
    "         print(f\"‚úó Erro ao extrair y_observado: {e}\"); raise\n",
    "\n",
    "    n_total = len(df)\n",
    "    bayesian_run_success = False\n",
    "    trace_avancado = None\n",
    "\n",
    "    with pm.Model(coords=coords) as modelo_bayes_avancado:\n",
    "         alpha = pm.Normal('alpha', mu=0.55, sigma=0.1)\n",
    "         betas = pm.Normal('betas', mu=0, sigma=0.3, dims=\"preditores\") \n",
    "\n",
    "         # ***** CORRE√á√ÉO 1: Remover o GaussianRandomWalk (tendencia) *****\n",
    "         # O modelo agora estima a tend√™ncia usando os betas das Prob_Regime_*\n",
    "         # sigma_temporal = pm.HalfNormal('sigma_temporal', sigma=0.01) # REMOVIDO\n",
    "         # tendencia_passos = pm.Normal('tendencia_passos', mu=0, sigma=sigma_temporal, shape=n_total) # REMOVIDO\n",
    "         # tendencia = pm.Deterministic('tendencia', pm.math.cumsum(tendencia_passos)) # REMOVIDO\n",
    "         # ***** FIM DA CORRE√á√ÉO 1 *****\n",
    "         \n",
    "         sigma = pm.HalfNormal('sigma', sigma=0.05) # Prior mais flex√≠vel (era 0.02)\n",
    "         \n",
    "         # mu agora √© determinado apenas pelos betas (incluindo os betas das probs. de regime)\n",
    "         mu = alpha + pm.math.dot(X_data_total, betas) \n",
    "\n",
    "         y_obs = pm.Normal('y_obs', mu=mu[moderno_idx], sigma=sigma, observed=y_observado)\n",
    "         mu_hist = pm.Deterministic('mu_hist', mu[historico_idx])\n",
    "\n",
    "         print(\"‚Üí Amostragem MCMC: 4 chains √ó 3000 itera√ß√µes\")\n",
    "         print(\"  (target_accept=0.99)\") # Aumentado de 0.95\n",
    "         \n",
    "         samplers_config = [(\"blackjax (GPU)\", {\"sampler\": \"blackjax\"}), (\"nuts (CPU)\", {})]\n",
    "\n",
    "         for sampler_name, sampler_kwargs in samplers_config:\n",
    "             try:\n",
    "                 print(f\"--- Tentando sampler: {sampler_name} ---\")\n",
    "                 trace_avancado = pm.sample(draws=1500, tune=1500, chains=4, target_accept=0.99, progressbar=True, return_inferencedata=True, **sampler_kwargs)\n",
    "                 print(f\"‚úì {sampler_name.upper()} usado com sucesso\")\n",
    "                 bayesian_run_success = True\n",
    "                 break\n",
    "             except Exception as e:\n",
    "                 print(f\"‚ö† {sampler_name.upper()} falhou: {str(e)[:100]}\")\n",
    "                 if sampler_name == samplers_config[-1][0]: print(\"‚úó Todos os samplers falharam\")\n",
    "                 else: print(\"‚Üí Tentando pr√≥ximo sampler (fallback)...\")\n",
    "\n",
    "    if bayesian_run_success and trace_avancado is not None:\n",
    "         print(\"\\n\" + \"=\"*70); print(\"DIAGN√ìSTICOS DO MODELO\"); print(\"=\"*70)\n",
    "         try:\n",
    "             # ***** CORRE√á√ÉO 2: Adicionar kind='stats' para corrigir o erro de impress√£o *****\n",
    "             vars_para_sumario = [\"alpha\", \"betas\", \"sigma\"] # sigma_temporal foi removido\n",
    "             summary_bayes = az.summary(trace_avancado, var_names=vars_para_sumario, kind='stats', stat_focus=\"median\")\n",
    "             # ***** FIM DA CORRE√á√ÉO 2 *****\n",
    "             \n",
    "             # CORRE√á√ÉO DO ERRO DE DIAGN√ìSTICO: Selecionar colunas por nome\n",
    "             cols_to_print = ['mean', 'sd', 'hdi_3%', 'hdi_97%', 'r_hat']\n",
    "             \n",
    "             print(\"\\nPAR√ÇMETROS PRINCIPAIS (incluindo betas de regime):\")\n",
    "             # Garante que s√≥ as colunas v√°lidas sejam impressas\n",
    "             valid_cols_summary = [col for col in cols_to_print if col in summary_bayes.columns]\n",
    "             print(summary_bayes[valid_cols_summary])\n",
    "             \n",
    "             if predictors_regime:\n",
    "                  print(\"\\n--- Betas Espec√≠ficos do Regime MaxEnt ---\")\n",
    "                  betas_summary = summary_bayes.filter(like='betas', axis=0)\n",
    "                  betas_regime_summary = betas_summary[betas_summary.index.str.contains('Prob_Regime')]\n",
    "                  # Garante que s√≥ as colunas v√°lidas sejam impressas\n",
    "                  valid_cols_regime = [col for col in cols_to_print if col in betas_regime_summary.columns]\n",
    "                  print(betas_regime_summary[valid_cols_regime])\n",
    "                  \n",
    "         except Exception as e: print(f\"‚ö† Erro nos diagn√≥sticos: {e}\")\n",
    "         print(\"=\"*70)\n",
    "\n",
    "         try:\n",
    "             print(\"\\n‚Üí Extraindo predi√ß√µes posteriores...\")\n",
    "             posterior_pred = trace_avancado.posterior['mu_hist']\n",
    "             df_historico['Gini_Bayes_Hierarquico'] = posterior_pred.mean(dim=['chain', 'draw']).values\n",
    "             hdi = az.hdi(posterior_pred, hdi_prob=0.95)\n",
    "             df_historico['Gini_Bayes_Low'] = hdi['mu_hist'].sel(hdi='lower').values\n",
    "             df_historico['Gini_Bayes_High'] = hdi['mu_hist'].sel(hdi='higher').values\n",
    "             print(f\"‚úì Predi√ß√µes extra√≠das ({len(df_historico)} anos)\")\n",
    "         except KeyError as e:\n",
    "             print(f\"‚ö† Vari√°vel n√£o encontrada no trace: {e} ‚Üí Usando fallback (NaN)\"); df_historico[['Gini_Bayes_Hierarquico', 'Gini_Bayes_Low', 'Gini_Bayes_High']] = np.nan\n",
    "         except Exception as e:\n",
    "             print(f\"‚ö† Erro inesperado na extra√ß√£o: {e}\"); df_historico[['Gini_Bayes_Hierarquico', 'Gini_Bayes_Low', 'Gini_Bayes_High']] = np.nan\n",
    "    else:\n",
    "         print(\"\\n‚ö† Amostragem MCMC falhou completamente ‚Üí S√©rie Bayesiana n√£o dispon√≠vel\"); df_historico[['Gini_Bayes_Hierarquico', 'Gini_Bayes_Low', 'Gini_Bayes_High']] = np.nan\n",
    "\n",
    "print(\"\\n‚úì BLOCO 10 (MAXENT + BAYES) OTIMIZADO PARA GPU CONCLU√çDO\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd94d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "# 11. M√âTRICAS DE AVALIA√á√ÉO (Atualizado Labels e Modelos)\n",
    "# ===========================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"M√âTRICAS DE AVALIA√á√ÉO (vs Gini_Verdadeiro no per√≠odo hist√≥rico, k={k_lags_selecionados} lags)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "ols_label = f'OLS (k={k_lags_selecionados} Lags)'\n",
    "markov_label = f'Markov (k={k_lags_selecionados} Lags)'\n",
    "gam_label = f'GAM (k={k_lags_selecionados} Lags)'\n",
    "ts_label = 'S√©rie Temporal (UCM)'\n",
    "\n",
    "# ***** CORRE√á√ÉO: Renomear e adicionar os dois modelos Bayes *****\n",
    "bayes_simples_label = f'Bayes (k={k_lags_selecionados} Lags Simples)' \n",
    "bayes_hibrido_label = f'Bayes (k={k_lags_selecionados} Lags + MaxEnt)' \n",
    "# ***** FIM DA CORRE√á√ÉO *****\n",
    "\n",
    "quantum_base_label = f'Quantum (k={k_lags_selecionados} Lags)' \n",
    "\n",
    "# Verifica√ß√£o da flag de uso de GPU\n",
    "if 'USE_GPU_ML' not in locals():\n",
    "    print(\"AVISO: Flag 'USE_GPU_ML' (do Bloco 8) n√£o encontrada. Assumindo fallback YDF (CPU) para labels.\")\n",
    "    USE_GPU_ML = False \n",
    "\n",
    "if USE_GPU_ML:\n",
    "    gbt_label = f'XGBoost GBT (k={k_lags_selecionados} Lags, GPU)'\n",
    "    rf_label = f'cuML RF (k={k_lags_selecionados} Lags, GPU)'\n",
    "    print(\"‚úì Labels de ML atualizados para: GPU (XGBoost / cuML)\")\n",
    "else:\n",
    "    gbt_label = f'YDF GBT (k={k_lags_selecionados} Lags, CPU)'\n",
    "    rf_label = f'YDF RF (k={k_lags_selecionados} Lags, CPU)'\n",
    "    print(\"‚úì Labels de ML definidos para: CPU (YDF)\")\n",
    "\n",
    "varmax_label = f'VARMAX (k={k_lags_selecionados} Lags)'\n",
    "\n",
    "# Dicion√°rio dos modelos avaliados\n",
    "modelos_avaliados = {\n",
    "    ols_label: 'Gini_OLS',\n",
    "    markov_label: 'Gini_Markov',\n",
    "    gam_label: 'Gini_GAM',\n",
    "    ts_label: 'Gini_TimeSeries',\n",
    "\n",
    "    # ***** CORRE√á√ÉO: Adicionar ambos os modelos Bayes *****\n",
    "    bayes_simples_label: 'Gini_Bayes_Simples',\n",
    "    bayes_hibrido_label: 'Gini_Bayes_Hierarquico',\n",
    "    # ***** FIM DA CORRE√á√ÉO *****\n",
    "\n",
    "    quantum_base_label: 'Gini_Quantum',\n",
    "    gbt_label: 'Gini_YDF_GBT',\n",
    "    rf_label: 'Gini_YDF_RF',\n",
    "    varmax_label: 'Gini_VARMAX'\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "# S√©rie verdadeira\n",
    "y_verdadeiro_hist = df_historico['Gini_Verdadeiro'].copy().dropna()\n",
    "max_label_len = max(len(nome) for nome in modelos_avaliados.keys()) + 2\n",
    "\n",
    "# Loop de avalia√ß√£o\n",
    "for nome, coluna in modelos_avaliados.items():\n",
    "    if coluna in df_historico.columns and not df_historico[coluna].isnull().all():\n",
    "        y_pred_hist = df_historico[coluna].copy()\n",
    "        aligned_data = pd.concat([y_verdadeiro_hist, y_pred_hist], axis=1, join='inner').dropna()\n",
    "\n",
    "        if len(aligned_data) > 0:\n",
    "            y_true_aligned = aligned_data['Gini_Verdadeiro']\n",
    "            y_pred_aligned = aligned_data[coluna]\n",
    "\n",
    "            try:\n",
    "                mae = mean_absolute_error(y_true_aligned, y_pred_aligned)\n",
    "                rmse = np.sqrt(mean_squared_error(y_true_aligned, y_pred_aligned))\n",
    "                r2 = r2_score(y_true_aligned, y_pred_aligned)\n",
    "                resultados.append({'Modelo': nome, 'MAE': mae, 'RMSE': rmse, 'R¬≤': r2})\n",
    "                print(f\"{nome:<{max_label_len}s} | MAE: {mae:.4f} | RMSE: {rmse:.4f} | R¬≤: {r2:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{nome:<{max_label_len}s} | Erro no c√°lculo das m√©tricas: {e}\")\n",
    "                resultados.append({'Modelo': nome, 'MAE': np.nan, 'RMSE': np.nan, 'R¬≤': np.nan})\n",
    "        else:\n",
    "            print(f\"{nome:<{max_label_len}s} | Sem dados alinhados ap√≥s dropna. Pulando m√©tricas.\")\n",
    "            resultados.append({'Modelo': nome, 'MAE': np.nan, 'RMSE': np.nan, 'R¬≤': np.nan})\n",
    "    else:\n",
    "        print(f\"{nome:<{max_label_len}s} | Coluna '{coluna}' n√£o encontrada ou vazia. Pulando m√©tricas.\")\n",
    "        resultados.append({'Modelo': nome, 'MAE': np.nan, 'RMSE': np.nan, 'R¬≤': np.nan})\n",
    "\n",
    "# DataFrame final de resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 12 - VISUALIZA√á√ÉO ATUALIZADA (com Modelo MaxEnt+Bayes e ML GPU)\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFIGURANDO DIRET√ìRIO DE SA√çDA (WSL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    output_dir_str = '/mnt/c/Users/daves/OneDrive/Pessoal/Acad√™mico/Doutorado/Codes'\n",
    "    output_dir = Path(output_dir_str)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if output_dir.is_dir() and os.access(str(output_dir), os.W_OK):\n",
    "        print(f\"Diret√≥rio de sa√≠da (WSL): {output_dir}\")\n",
    "        print(f\"Existe: True\")\n",
    "        print(f\"‚úì Diret√≥rio √© grav√°vel\")\n",
    "        test_file = output_dir / \"test_write.tmp\"\n",
    "        test_file.touch()\n",
    "        test_file.unlink()\n",
    "    else:\n",
    "        if not output_dir.is_dir():\n",
    "            print(f\"‚ö† Diret√≥rio n√£o existe: {output_dir}\")\n",
    "        else:\n",
    "            print(f\"‚ö† Sem permiss√£o de escrita no diret√≥rio: {output_dir}\")\n",
    "        output_dir = Path.cwd() \n",
    "        print(f\"‚Üí Usando diret√≥rio atual como fallback: {output_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Erro ao configurar ou verificar diret√≥rio de sa√≠da: {e}\")\n",
    "    output_dir = Path.cwd()\n",
    "    print(f\"‚Üí Usando diret√≥rio atual como fallback: {output_dir}\")\n",
    "\n",
    "# --- Labels Atualizados ---\n",
    "if 'k_lags_selecionados' not in locals():\n",
    "    try:\n",
    "        lag_cols = [col for col in df.columns if 'Gini_Lag_' in col]\n",
    "        k_lags_selecionados = len(lag_cols) if lag_cols else 1\n",
    "        if k_lags_selecionados == 0:\n",
    "            k_lags_selecionados = 1\n",
    "        print(f\"AVISO: k_lags_selecionados inferido como {k_lags_selecionados} a partir das colunas do DataFrame.\")\n",
    "    except NameError:\n",
    "        k_lags_selecionados = 1 \n",
    "        print(\"AVISO: k_lags_selecionados n√£o definido, usando padr√£o 1.\")\n",
    "\n",
    "ols_label = f'OLS (k={k_lags_selecionados} Lags)'\n",
    "markov_label = f'Markov (k={k_lags_selecionados} Lags)'\n",
    "gam_label = f'GAM (k={k_lags_selecionados} Lags)'\n",
    "ts_label = 'S√©rie Temporal (UCM)'\n",
    "bayes_simples_label = f'Bayes (k={k_lags_selecionados} Lags Simples)'\n",
    "bayes_hibrido_label = f'Bayes (k={k_lags_selecionados} Lags + MaxEnt)'\n",
    "quantum_base_label = f'Quantum (k={k_lags_selecionados} Lags)'\n",
    "\n",
    "if 'USE_GPU_ML' not in locals():\n",
    "    print(\"AVISO: Flag 'USE_GPU_ML' n√£o encontrada. Assumindo CPU (YDF).\")\n",
    "    USE_GPU_ML = False\n",
    "\n",
    "if USE_GPU_ML:\n",
    "    gbt_label = f'XGBoost GBT (k={k_lags_selecionados} Lags, GPU)'\n",
    "    rf_label = f'cuML RF (k={k_lags_selecionados} Lags, GPU)'\n",
    "    print(\"‚úì Labels de ML definidos para GPU\")\n",
    "else:\n",
    "    gbt_label = f'YDF GBT (k={k_lags_selecionados} Lags, CPU)'\n",
    "    rf_label = f'YDF RF (k={k_lags_selecionados} Lags, CPU)'\n",
    "    print(\"‚úì Labels de ML definidos para CPU\")\n",
    "\n",
    "varmax_label = f'VARMAX (k={k_lags_selecionados} Lags)'\n",
    "\n",
    "cores = {\n",
    "    ols_label: '#FF6B6B', markov_label: '#F4A261', gam_label: '#4ECDC4',\n",
    "    ts_label: '#FFE66D',\n",
    "    bayes_simples_label: '#8A2BE2',\n",
    "    bayes_hibrido_label: '#95E1D3',\n",
    "    quantum_base_label: '#9D4EDD',\n",
    "    gbt_label: '#1E90FF',\n",
    "    rf_label: '#32CD32',\n",
    "    varmax_label: '#FF1493'\n",
    "}\n",
    "print(\"‚úì Dicion√°rio 'cores' definido com labels atualizados.\")\n",
    "\n",
    "# ====================================================================\n",
    "# 12.a GR√ÅFICO INTERATIVO PLOTLY (Atualizado)\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GERANDO GR√ÅFICO INTERATIVO PLOTLY (Atualizado)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig_plotly = go.Figure()\n",
    "\n",
    "if 'df' not in locals() or 'df_moderno' not in locals():\n",
    "    print(\"ERRO: DataFrames 'df' ou 'df_moderno' n√£o encontrados.\")\n",
    "    fig_plotly = None\n",
    "else:\n",
    "    fig_plotly.add_trace(go.Scatter(\n",
    "        x=df['Ano'], y=df['Gini_Verdadeiro'], mode='lines', name='Gini Verdadeiro',\n",
    "        line=dict(color='black', width=2.5, dash='dash'), hoverinfo='name+x+y', legendgroup='Gini'\n",
    "    ))\n",
    "    if 'ano_inicio_pnad' not in locals(): ano_inicio_pnad = 1976\n",
    "    fig_plotly.add_trace(go.Scatter(\n",
    "        x=df_moderno['Ano'], y=df_moderno['Gini_Observado'], mode='markers', name=f'Observado ({ano_inicio_pnad}+)',\n",
    "        marker=dict(color='dimgray', size=8, opacity=0.7), hoverinfo='name+x+y', legendgroup='Gini'\n",
    "    ))\n",
    "    fig_plotly.add_vline(\n",
    "        x=ano_inicio_pnad, line_dash=\"dot\", line_color=\"gray\", line_width=2,\n",
    "        annotation_text=\"In√≠cio dados modernos\", annotation_position=\"top left\"\n",
    "    )\n",
    "\n",
    "    def add_model_trace(fig, df_hist, col_name, color, line_style, label, legend_group, show_legend=True):\n",
    "        if df_hist is not None and col_name in df_hist.columns and not df_hist[col_name].isnull().all():\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_hist['Ano'], y=df_hist[col_name], mode='lines', name=label,\n",
    "                line=dict(color=color, width=2.5, dash=line_style),\n",
    "                hoverinfo='name+x+y', legendgroup=legend_group, showlegend=show_legend\n",
    "            ))\n",
    "\n",
    "    def add_fill_trace(fig, df_hist, low_col, high_col, color, model_name, legend_group):\n",
    "        if df_hist is not None and low_col in df_hist.columns and high_col in df_hist.columns:\n",
    "            rgb = plotly.colors.hex_to_rgb(color)\n",
    "            rgba_color = f'rgba({rgb[0]}, {rgb[1]}, {rgb[2]}, 0.15)'\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_hist['Ano'], y=df_hist[high_col], mode='lines', line=dict(width=0),\n",
    "                showlegend=False, hoverinfo='skip', legendgroup=legend_group\n",
    "            ))\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_hist['Ano'], y=df_hist[low_col], mode='lines', line=dict(width=0),\n",
    "                fill='tonexty', fillcolor=rgba_color, name=f'{model_name} (Int. 95%)',\n",
    "                hoverinfo='name+x', legendgroup=legend_group\n",
    "            ))\n",
    "\n",
    "    if 'df_historico' in locals() and df_historico is not None:\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_OLS', cores[ols_label], 'solid', ols_label, 'OLS')\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_Markov', cores[markov_label], 'solid', markov_label, 'Markov')\n",
    "        add_fill_trace(fig_plotly, df_historico, 'Gini_Markov_Low', 'Gini_Markov_High', cores[markov_label], markov_label, 'Markov')\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_GAM', cores[gam_label], 'solid', gam_label, 'GAM')\n",
    "        add_fill_trace(fig_plotly, df_historico, 'Gini_GAM_Low', 'Gini_GAM_High', cores[gam_label], gam_label, 'GAM')\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_TimeSeries', cores[ts_label], 'solid', ts_label, 'TS')\n",
    "        add_fill_trace(fig_plotly, df_historico, 'Gini_TS_Low', 'Gini_TS_High', cores[ts_label], ts_label, 'TS')\n",
    "\n",
    "        # Bayes\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_Bayes_Simples', cores[bayes_simples_label], 'dot', bayes_simples_label, 'Bayes_S')\n",
    "        add_fill_trace(fig_plotly, df_historico, 'Gini_Bayes_Simples_Low', 'Gini_Bayes_Simples_High', cores[bayes_simples_label], bayes_simples_label, 'Bayes_S')\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_Bayes_Hierarquico', cores[bayes_hibrido_label], 'solid', bayes_hibrido_label, 'Bayes_H')\n",
    "        add_fill_trace(fig_plotly, df_historico, 'Gini_Bayes_Low', 'Gini_Bayes_High', cores[bayes_hibrido_label], bayes_hibrido_label, 'Bayes_H')\n",
    "\n",
    "        # Quantum + ML + VARMAX\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_Quantum', cores[quantum_base_label], 'dot', quantum_base_label, 'Quantum')\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_YDF_GBT', cores[gbt_label], 'dash', gbt_label, 'GBT')\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_YDF_RF', cores[rf_label], 'dash', rf_label, 'RF')\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_VARMAX', cores[varmax_label], 'solid', varmax_label, 'VARMAX')\n",
    "        add_fill_trace(fig_plotly, df_historico, 'Gini_VARMAX_Low', 'Gini_VARMAX_High', cores[varmax_label], varmax_label, 'VARMAX')\n",
    "\n",
    "    fig_plotly.update_layout(\n",
    "        title=dict(\n",
    "            text=f'<b>An√°lise Backcasting Gini (1872-{ano_inicio_pnad-1}) com k={k_lags_selecionados} Lags (Incl. MaxEnt+Bayes)</b>',\n",
    "            x=0.5, xanchor='center', font=dict(size=16, color='black')\n",
    "        ),\n",
    "        hovermode='x unified',\n",
    "        legend=dict(\n",
    "            orientation=\"h\", yanchor=\"top\", y=-0.2, xanchor=\"center\", x=0.5, font=dict(size=9),\n",
    "            bgcolor=\"rgba(255,255,255,0.7)\", bordercolor=\"lightgray\", borderwidth=1\n",
    "        ),\n",
    "        height=750,\n",
    "        template=\"plotly_white\",\n",
    "        xaxis=dict(range=[df['Ano'].min(), df['Ano'].max()], title='Ano'),\n",
    "        yaxis=dict(range=[0, 1], title='√çndice de Gini')  # ‚úÖ Eixo Y ajustado\n",
    "    )\n",
    "\n",
    "# Salvar Plotly\n",
    "if fig_plotly:\n",
    "    output_filename_plotly = f\"grafico_backcasting_interativo_k{k_lags_selecionados}lags_full.html\"\n",
    "    output_path_plotly = output_dir / output_filename_plotly\n",
    "    fig_plotly.write_html(str(output_path_plotly))\n",
    "    print(f\"‚úì Gr√°fico Plotly salvo em: {output_path_plotly}\")\n",
    "\n",
    "# ====================================================================\n",
    "# 12.b GR√ÅFICO EST√ÅTICO MATPLOTLIB (Atualizado)\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GERANDO GR√ÅFICO EST√ÅTICO MATPLOTLIB (Atualizado)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'df' not in locals() or 'df_moderno' not in locals():\n",
    "    print(\"ERRO: DataFrames n√£o encontrados.\")\n",
    "else:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['figure.dpi'] = 100\n",
    "    fig_mpl, ax_mpl = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "    line_styles_mpl = {'solid': '-', 'dash': '--', 'dot': ':', 'dashdot': '-.'}\n",
    "\n",
    "    def add_model_trace_mpl(ax, df_hist, col_name, color, line_style_key, label):\n",
    "        if df_hist is not None and col_name in df_hist.columns and not df_hist[col_name].isnull().all():\n",
    "            ax.plot(df_hist['Ano'], df_hist[col_name], color=color,\n",
    "                    linestyle=line_styles_mpl.get(line_style_key, '-'),\n",
    "                    linewidth=2.0, label=label, zorder=2)\n",
    "\n",
    "    def add_fill_trace_mpl(ax, df_hist, low_col, high_col, color, model_name):\n",
    "        if df_hist is not None and low_col in df_hist.columns and high_col in df_hist.columns:\n",
    "            ax.fill_between(df_hist['Ano'], df_hist[low_col], df_hist[high_col],\n",
    "                            color=color, alpha=0.15, label=f'{model_name} (Int. 95%)', zorder=1)\n",
    "\n",
    "    ax_mpl.plot(df['Ano'], df['Gini_Verdadeiro'], color='black', linestyle='--', linewidth=2.0, label='Gini Verdadeiro', zorder=3)\n",
    "    ax_mpl.plot(df_moderno['Ano'], df_moderno['Gini_Observado'], marker='o', markersize=6, color='dimgray',\n",
    "                linestyle='None', label=f'Observado ({ano_inicio_pnad}+)', alpha=0.7, zorder=4)\n",
    "    ax_mpl.axvline(x=ano_inicio_pnad, color=\"gray\", linestyle=':', linewidth=2, zorder=2)\n",
    "\n",
    "    if 'df_historico' in locals() and df_historico is not None:\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_OLS', cores[ols_label], 'solid', ols_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_Markov', cores[markov_label], 'solid', markov_label)\n",
    "        add_fill_trace_mpl(ax_mpl, df_historico, 'Gini_Markov_Low', 'Gini_Markov_High', cores[markov_label], markov_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_GAM', cores[gam_label], 'solid', gam_label)\n",
    "        add_fill_trace_mpl(ax_mpl, df_historico, 'Gini_GAM_Low', 'Gini_GAM_High', cores[gam_label], gam_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_TimeSeries', cores[ts_label], 'solid', ts_label)\n",
    "        add_fill_trace_mpl(ax_mpl, df_historico, 'Gini_TS_Low', 'Gini_TS_High', cores[ts_label], ts_label)\n",
    "\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_Bayes_Simples', cores[bayes_simples_label], 'dot', bayes_simples_label)\n",
    "        add_fill_trace_mpl(ax_mpl, df_historico, 'Gini_Bayes_Simples_Low', 'Gini_Bayes_Simples_High', cores[bayes_simples_label], bayes_simples_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_Bayes_Hierarquico', cores[bayes_hibrido_label], 'solid', bayes_hibrido_label)\n",
    "        add_fill_trace_mpl(ax_mpl, df_historico, 'Gini_Bayes_Low', 'Gini_Bayes_High', cores[bayes_hibrido_label], bayes_hibrido_label)\n",
    "\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_Quantum', cores[quantum_base_label], 'dot', quantum_base_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_YDF_GBT', cores[gbt_label], 'dash', gbt_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_YDF_RF', cores[rf_label], 'dash', rf_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_VARMAX', cores[varmax_label], 'solid', varmax_label)\n",
    "        add_fill_trace_mpl(ax_mpl, df_historico, 'Gini_VARMAX_Low', 'Gini_VARMAX_High', cores[varmax_label], varmax_label)\n",
    "\n",
    "    ax_mpl.set_xlabel('Ano', fontsize=12)\n",
    "    ax_mpl.set_ylabel('√çndice de Gini', fontsize=12)\n",
    "    ax_mpl.set_xlim(df['Ano'].min(), df['Ano'].max())\n",
    "    ax_mpl.set_ylim(0, 1)  # ‚úÖ Eixo Y ajustado\n",
    "    ax_mpl.xaxis.set_major_locator(mtick.MultipleLocator(20))\n",
    "    ax_mpl.yaxis.set_major_locator(mtick.MultipleLocator(0.05))\n",
    "    ax_mpl.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=4, fontsize=8, frameon=True)\n",
    "\n",
    "    output_filename_mpl = f\"grafico_backcasting_estatico_k{k_lags_selecionados}lags_full.jpg\"\n",
    "    output_path_mpl = output_dir / output_filename_mpl\n",
    "    fig_mpl.savefig(str(output_path_mpl), format='jpg', dpi=1200, bbox_inches='tight')  # ‚úÖ 1200 dpi\n",
    "    plt.close(fig_mpl)\n",
    "    print(f\"‚úì Gr√°fico Matplotlib salvo em: {output_path_mpl}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ VISUALIZA√á√ÉO FINALIZADA COM SUCESSO!\")\n",
    "print(\"=\"*70)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
