{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7380b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 15:00:16.551148: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761505216.682957   20033 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761505216.722266   20033 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1761505217.033409   20033 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761505217.033442   20033 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761505217.033444   20033 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1761505217.033446   20033 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-26 15:00:17.076610: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando PyMC vers√£o: 5.26.1\n",
      "Modo Qiskit: Novo (>=1.0)\n",
      "================================================================================\n",
      "INICIANDO PIPELINE DE MODELOS\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Prepara√ß√£o de dados e econometria cl√°ssica\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.statespace.structural import UnobservedComponents\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "#Modelos de Mudan√ßa de Regime (Modelo de Regress√£o com Mudan√ßa de Regime de Markov):\n",
    "    # em vez de um √∫nico modelo de regress√£o para explicar a s√©rie inteira, h√° v√°rios modelos\n",
    "from statsmodels.tsa.regime_switching.markov_regression import MarkovRegression\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Modelagem Bayesiana:\n",
    "    # par√¢metros como vari√°veis aleat√≥rias: tem uma distribui√ß√£o de probabilidade, portanto com incerteza\n",
    "    #resultado √© uma distribui√ß√£o de probabilidade\n",
    "        #prior: cren√ßa sobre o par√¢metro antes de ver os dados\n",
    "        #likelihood: como os dados s√£o gerados, fun√ß√£o de verossimilhan√ßa\n",
    "        #posterior: cren√ßa atualizada sobre o par√¢metro ap√≥s ver os dados\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Visualiza√ß√£o de dados\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.colors \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy.optimize import minimize\n",
    "from pygam import LinearGAM, s, f\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "#Modelos Aditivos Generalizados (GAM)\n",
    "    # Em vez de for√ßar uma rela√ß√£o linear, o GAM substitui esse termo por uma fun√ß√£o suave e flex√≠vel\n",
    "    #spline:divide o intervalo de $x$ em se√ß√µes (definidas por \"n√≥s\" ou knots) \n",
    "        # e ajusta fun√ß√µes mais simples (como pequenos polin√¥mios c√∫bicos) em cada se√ß√£o\n",
    "from scipy.stats import norm\n",
    "\n",
    "#Computa√ß√£o qu√¢ntica: \n",
    "    #Uso de Otimiza√ß√£o Combinat√≥ria: QAOA n√£o √© puramente qu√¢ntico; ele √© um algoritmo h√≠brido. \n",
    "        #Cl√°ssico üíª: O otimizador COBYLA (cl√°ssico) \"chuta\" um conjunto inicial de par√¢metros (√¢ngulos) para o circuito qu√¢ntico.\n",
    "        # Qu√¢ntico ‚öõÔ∏è: O QAOAAnsatz (o circuito qu√¢ntico) √© montado com esses par√¢metros. \n",
    "            # Ele √© executado no processador qu√¢ntico (ou simulador), usando superposi√ß√£o\n",
    "            # e emaranhamento para explorar o vasto espa√ßo de solu√ß√µes do seu QuadraticProgram.\n",
    "        # Qu√¢ntico ‚öõÔ∏è: O circuito √© medido, \"colapsando\" para uma solu√ß√£o candidata (ex: \"rota A\") e seu respectivo \"custo\".\n",
    "        # Cl√°ssico üíª: O COBYLA recebe esse custo.\n",
    "            # Ele ent√£o usa sua l√≥gica cl√°ssica para decidir um novo conjunto de par√¢metros para o circuito qu√¢ntico, tentando obter um custo menor.\n",
    "\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_algorithms.optimizers import COBYLA\n",
    "from qiskit_algorithms import QAOA\n",
    "from qiskit.circuit.library import TwoLocal, QAOAAnsatz\n",
    "from qiskit_optimization import QuadraticProgram\n",
    "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
    "\n",
    "\n",
    "# Usar o Sampler correto dependendo da vers√£o\n",
    "try:\n",
    "    # Para Qiskit >= 1.0\n",
    "    from qiskit.primitives import Sampler\n",
    "    QISKIT_NEW = True\n",
    "except ImportError:\n",
    "    # Para vers√µes antigas\n",
    "    try:\n",
    "        from qiskit_aer.primitives import Sampler\n",
    "        QISKIT_NEW = False\n",
    "    except ImportError:\n",
    "        # Fallback: usar StatevectorSampler\n",
    "        from qiskit.primitives import StatevectorSampler as Sampler\n",
    "        QISKIT_NEW = True\n",
    "\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "\n",
    "# Machine Learning Cl√°ssico: \n",
    "    # Random Forest: Constr√≥i  √°rvores independentes em paralelo usando aleatoriedade nos dados e nas features, e tira a m√©dia das previs√µes.\n",
    "    # XGBoost: Constr√≥i √°rvores sequencialmente, onde cada √°rvore aprende com os erros das anteriores,\n",
    "        # usando otimiza√ß√µes de gradiente e regulariza√ß√£o para alta performance e controle de overfitting.\n",
    "\n",
    "import ydf\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#VARMAX:\n",
    "    # analisar e prever m√∫ltiplas s√©ries temporais que s√£o interdependentes e tamb√©m podem ser influenciadas por vari√°veis externas.\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"Usando PyMC vers√£o: {pm.__version__}\")\n",
    "print(f\"Modo Qiskit: {'Novo (>=1.0)' if QISKIT_NEW else 'Legacy'}\")\n",
    "print(\"=\"*80)\n",
    "print(\"INICIANDO PIPELINE DE MODELOS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88cfc988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DADOS SIMULADOS (com garantia de positividade para PIB_pc, Industrializacao, Educacao):\n",
      "Gini por Regime: {0: 0.4, 1: 0.43, 2: 0.46}\n",
      "Primeiras linhas do DataFrame:\n",
      "    Ano      PIB_pc  Urbanizacao  Industrializacao  Educacao  Gini_Verdadeiro  \\\n",
      "0  1872  417.208801         0.05          0.000000  0.013242         0.350000   \n",
      "1  1873  395.155205         0.05          0.000000  0.000000         0.350000   \n",
      "2  1874  467.381449         0.05          0.036170  0.000000         0.376359   \n",
      "3  1875  519.945747         0.05          0.016229  0.011559         0.350000   \n",
      "4  1876  559.001227         0.05          0.035544  0.002394         0.350000   \n",
      "\n",
      "   Regime_Verdadeiro  Gini_Observado  \n",
      "0                  0             NaN  \n",
      "1                  0             NaN  \n",
      "2                  0             NaN  \n",
      "3                  0             NaN  \n",
      "4                  0             NaN  \n",
      "\n",
      "Valores m√≠nimos simulados:\n",
      "  PIB_pc Min: 395.1552\n",
      "  Industrializacao Min: 0.0000\n",
      "  Educacao Min: 0.0000\n",
      "================================================================================\n",
      "‚úì Gr√°fico Gini vs Regimes salvo como gini_regimes_plot.png\n",
      "‚úì Gr√°fico Covari√°veis salvo como covariaveis_plot.png\n",
      "================================================================================\n",
      "\n",
      "[Sele√ß√£o de Lags via AIC]\n",
      "‚Üí Selecionando n√∫mero de lags para Gini (max 10)...\n",
      "‚ö† Erro inesperado na sele√ß√£o autom√°tica de lags ('AutoRegResults' object has no attribute 'k_ar'), usando k=1.\n",
      "‚úì N√∫mero de lags selecionados (k): 1\n",
      "‚Üí Criando colunas de lag no DataFrame principal...\n",
      "  ‚úì Coluna 'Gini_Lag_1' criada e preenchida.\n",
      "‚Üí Atualizando DataFrames moderno e hist√≥rico...\n",
      "  ‚úì df_moderno (47 obs) e df_historico (104 obs) atualizados.\n",
      "\n",
      "Primeiras linhas do DataFrame com colunas de lag:\n",
      "    Ano      PIB_pc  Urbanizacao  Industrializacao  Educacao  Gini_Verdadeiro  \\\n",
      "0  1872  417.208801         0.05          0.000000  0.013242         0.350000   \n",
      "1  1873  395.155205         0.05          0.000000  0.000000         0.350000   \n",
      "2  1874  467.381449         0.05          0.036170  0.000000         0.376359   \n",
      "3  1875  519.945747         0.05          0.016229  0.011559         0.350000   \n",
      "4  1876  559.001227         0.05          0.035544  0.002394         0.350000   \n",
      "\n",
      "   Regime_Verdadeiro  Gini_Observado  Gini_Lag_1  \n",
      "0                  0             NaN    0.350000  \n",
      "1                  0             NaN    0.350000  \n",
      "2                  0             NaN    0.350000  \n",
      "3                  0             NaN    0.376359  \n",
      "4                  0             NaN    0.350000  \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 1. SIMULA√á√ÉO DE DADOS \n",
    "# ===========================\n",
    "\n",
    "np.random.seed(1872)\n",
    "anos = np.arange(1872, 2023)\n",
    "n_anos = len(anos)\n",
    "\n",
    "# Simula PIB per capita e garante n√£o-negatividade\n",
    "pib_pc = 500 * np.exp(np.linspace(0, 1.5, n_anos)) + np.random.normal(0, 50, n_anos)\n",
    "pib_pc = np.maximum(pib_pc, 0) # Garante que pib_pc >= 0\n",
    "\n",
    "# Simula Urbanizacao (j√° clipado entre 0.05 e 0.85, ent√£o √© positivo)\n",
    "urbanizacao = 0.8 / (1 + np.exp(-0.05 * (anos - 1990))) + np.random.normal(0, 0.02, n_anos)\n",
    "urbanizacao = np.clip(urbanizacao, 0.05, 0.85)\n",
    "\n",
    "# Simula Industrializacao e garante n√£o-negatividade\n",
    "industrializacao = 0.6 / (1 + np.exp(-0.06 * (anos - 1980))) + np.random.normal(0, 0.02, n_anos)\n",
    "industrializacao = np.maximum(industrializacao, 0) # Garante que industrializacao >= 0\n",
    "\n",
    "# Simula Educacao e garante n√£o-negatividade\n",
    "educacao = 0.7 / (1 + np.exp(-0.04 * (anos - 1985))) + np.random.normal(0, 0.015, n_anos)\n",
    "educacao = np.maximum(educacao, 0) # Garante que educacao >= 0\n",
    "\n",
    "regimes_verdadeiros = np.zeros(n_anos, dtype=int)\n",
    "gini_por_regime = {0: 0.40, 1: 0.43, 2: 0.46}\n",
    "volatilidade_regime = {0: 0.025, 1: 0.015, 2: 0.020}\n",
    "regime_atual = 0\n",
    "for i in range(n_anos):\n",
    "    ano_atual = anos[i]\n",
    "    if ano_atual < 1930: regime_atual = 0\n",
    "    elif 1930 <= ano_atual < 1960: regime_atual = 1\n",
    "    elif 1960 <= ano_atual < 2000: regime_atual = 0\n",
    "    else: regime_atual = 2\n",
    "    regimes_verdadeiros[i] = regime_atual\n",
    "\n",
    "tendencia = 0.6 - 0.10 * ((anos - 1872) / 150)\n",
    "ciclica = -0.05 * np.sin(np.pi * (anos - 1872) / 40)\n",
    "estrutural = 0.03 * np.cos(np.pi * (anos - 1872) / 25)\n",
    "gini_regime = np.array([gini_por_regime[r] for r in regimes_verdadeiros])\n",
    "noise_regime = np.array([np.random.normal(0, volatilidade_regime[r]) for r in regimes_verdadeiros])\n",
    "gini_real = 0.1 * tendencia + 0.7 * gini_regime + 0.1 * ciclica + 0.1 * estrutural + noise_regime\n",
    "gini_real = np.clip(gini_real, 0.35, 0.55)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Ano': anos, 'PIB_pc': pib_pc, 'Urbanizacao': urbanizacao,\n",
    "    'Industrializacao': industrializacao, 'Educacao': educacao,\n",
    "    'Gini_Verdadeiro': gini_real, 'Regime_Verdadeiro': regimes_verdadeiros\n",
    "})\n",
    "\n",
    "ano_inicio_pnad = 1976\n",
    "# Criar Gini_Observado para sele√ß√£o de lags\n",
    "df['Gini_Observado'] = np.nan\n",
    "mask_moderno_inicial = df['Ano'] >= ano_inicio_pnad\n",
    "df.loc[mask_moderno_inicial, 'Gini_Observado'] = df.loc[mask_moderno_inicial, 'Gini_Verdadeiro'] + \\\n",
    "                                                np.random.normal(0, 0.01, mask_moderno_inicial.sum())\n",
    "n_total = len(df)\n",
    "\n",
    "print(\"\\nDADOS SIMULADOS (com garantia de positividade para PIB_pc, Industrializacao, Educacao):\")\n",
    "print(f\"Gini por Regime: {gini_por_regime}\")\n",
    "print(\"Primeiras linhas do DataFrame:\")\n",
    "print(df.head())\n",
    "# Verifica valores m√≠nimos (opcional)\n",
    "print(\"\\nValores m√≠nimos simulados:\")\n",
    "print(f\"  PIB_pc Min: {df['PIB_pc'].min():.4f}\")\n",
    "print(f\"  Industrializacao Min: {df['Industrializacao'].min():.4f}\")\n",
    "print(f\"  Educacao Min: {df['Educacao'].min():.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- VISUALIZA√á√ÉO DOS DADOS ---\n",
    "# Presume que matplotlib e seaborn foram importados no bloco principal de imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_moderno_grafico = df[df['Ano'] >= ano_inicio_pnad].copy()\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Gr√°fico 1: Gini e Regimes\n",
    "fig, ax1 = plt.subplots(figsize=(16, 6))\n",
    "sns.lineplot(data=df, x='Ano', y='Gini_Verdadeiro', label='Gini Verdadeiro (Latente)', ax=ax1, color='blue', linewidth=2.5)\n",
    "sns.scatterplot(data=df_moderno_grafico, x='Ano', y='Gini_Observado', label=f'Gini Observado (p√≥s-{ano_inicio_pnad})', ax=ax1, color='red', s=50, zorder=5)\n",
    "ax1.set_title('Simula√ß√£o do √çndice Gini e Regimes Estruturais (1872-2022)', fontsize=16, pad=20)\n",
    "ax1.set_ylabel('√çndice Gini', fontsize=12, color='blue')\n",
    "ax1.set_xlabel('Ano', fontsize=12)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax2 = ax1.twinx()\n",
    "ax2.fill_between(df['Ano'], df['Regime_Verdadeiro'], step='pre', alpha=0.2, color='gray', label='Regime (Eixo Direito)')\n",
    "ax2.set_ylabel('Regime Estrutural', fontsize=12, color='gray')\n",
    "ax2.tick_params(axis='y', labelcolor='gray', labelsize=9)\n",
    "tick_locs = np.unique(regimes_verdadeiros)\n",
    "ax2.set_yticks(tick_locs)\n",
    "regime_nomes = [f\"Regime {r} (Gini ~{gini_por_regime[r]})\" for r in tick_locs]\n",
    "ax2.set_yticklabels(regime_nomes)\n",
    "ax2.grid(False)\n",
    "lines, labels = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"gini_regimes_plot.png\")\n",
    "# plt.show() # Descomente para mostrar o gr√°fico interativamente se n√£o estiver em ambiente como VS Code/Jupyter\n",
    "plt.close(fig) # Fecha a figura para n√£o aparecer inline depois\n",
    "print(\"‚úì Gr√°fico Gini vs Regimes salvo como gini_regimes_plot.png\")\n",
    "\n",
    "# Gr√°fico 2: Covari√°veis\n",
    "fig, axes = plt.subplots(4, 1, figsize=(16, 12), sharex=True)\n",
    "fig.suptitle('Evolu√ß√£o das Covari√°veis Simuladas (1872-2022)', fontsize=18, y=1.02)\n",
    "sns.lineplot(data=df, x='Ano', y='PIB_pc', ax=axes[0], color='green'); axes[0].set_title('PIB per capita', fontsize=12); axes[0].set_ylabel('Valor')\n",
    "sns.lineplot(data=df, x='Ano', y='Urbanizacao', ax=axes[1], color='orange'); axes[1].set_title('Taxa de Urbaniza√ß√£o', fontsize=12); axes[1].set_ylabel('Taxa (0-1)')\n",
    "sns.lineplot(data=df, x='Ano', y='Industrializacao', ax=axes[2], color='purple'); axes[2].set_title('N√≠vel de Industrializa√ß√£o', fontsize=12); axes[2].set_ylabel('N√≠vel (0-1)')\n",
    "sns.lineplot(data=df, x='Ano', y='Educacao', ax=axes[3], color='brown'); axes[3].set_title('N√≠vel de Educa√ß√£o', fontsize=12); axes[3].set_ylabel('N√≠vel (0-1)')\n",
    "axes[3].set_xlabel('Ano', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"covariaveis_plot.png\")\n",
    "# plt.show() # Descomente para mostrar o gr√°fico interativamente\n",
    "plt.close(fig) # Fecha a figura\n",
    "print(\"‚úì Gr√°fico Covari√°veis salvo como covariaveis_plot.png\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# --- SELE√á√ÉO DE LAGS PARA O GINI (BASEADO NO AIC) ---\n",
    "# Presume que AutoReg foi importado no bloco principal de imports\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "print(\"\\n[Sele√ß√£o de Lags via AIC]\")\n",
    "print(\"‚Üí Selecionando n√∫mero de lags para Gini (max 10)...\")\n",
    "gini_moderno_observado = df.loc[mask_moderno_inicial, 'Gini_Observado'].dropna()\n",
    "\n",
    "k_lags_selecionados = 1 # Valor padr√£o caso a sele√ß√£o falhe\n",
    "\n",
    "if len(gini_moderno_observado) > 10: # Checagem m√≠nima de dados\n",
    "    try:\n",
    "        # Tentar com a sintaxe atualizada que seleciona automaticamente por AIC\n",
    "        model_select = AutoReg(gini_moderno_observado, lags=10, trend='n', old_names=False) # Especifica max lags\n",
    "        results_select = model_select.fit(cov_type=\"nonrobust\") # Ajusta o modelo\n",
    "        k_lags_selecionados = results_select.k_ar # k_ar cont√©m a ordem selecionada pelo crit√©rio padr√£o (AIC)\n",
    "        if k_lags_selecionados == 0: k_lags_selecionados = 1 # Evitar 0 lags\n",
    "    except TypeError:\n",
    "        # Fallback para sintaxe antiga que usa select_order (pode n√£o estar dispon√≠vel em vers√µes mais novas)\n",
    "        try:\n",
    "             ar_mod_sel = AutoReg(gini_moderno_observado, lags=10, trend='n') # Instancia com max lags\n",
    "             sel_res = ar_mod_sel.select_order(maxlag=10, ic='aic') # Chama m√©todo de sele√ß√£o\n",
    "             k_lags_selecionados = sel_res.aic if sel_res.aic > 0 else 1\n",
    "        except AttributeError: # Se select_order n√£o existe mais\n",
    "             print(f\"‚ö† M√©todo select_order n√£o encontrado (vers√£o antiga do statsmodels?), usando k=1.\")\n",
    "             k_lags_selecionados = 1\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Erro na sele√ß√£o autom√°tica de lags (select_order falhou: {e}), usando k=1.\")\n",
    "            k_lags_selecionados = 1\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Erro inesperado na sele√ß√£o autom√°tica de lags ({e}), usando k=1.\")\n",
    "        k_lags_selecionados = 1\n",
    "else:\n",
    "    print(\"‚ö† Dados insuficientes para sele√ß√£o autom√°tica, usando k=1.\")\n",
    "    k_lags_selecionados = 1\n",
    "\n",
    "\n",
    "print(f\"‚úì N√∫mero de lags selecionados (k): {k_lags_selecionados}\")\n",
    "\n",
    "# --- CRIA√á√ÉO DAS COLUNAS DE LAG  ---\n",
    "print(\"‚Üí Criando colunas de lag no DataFrame principal...\")\n",
    "lag_cols_names = []\n",
    "for i in range(1, k_lags_selecionados + 1):\n",
    "    col_name = f'Gini_Lag_{i}'\n",
    "    df[col_name] = df['Gini_Verdadeiro'].shift(i)\n",
    "    # Preencher NaNs iniciais com o primeiro valor de Gini_Verdadeiro\n",
    "    df[col_name].fillna(df['Gini_Verdadeiro'].iloc[0], inplace=True)\n",
    "    lag_cols_names.append(col_name)\n",
    "    print(f\"  ‚úì Coluna '{col_name}' criada e preenchida.\")\n",
    "\n",
    "# --- ATUALIZAR df_moderno e df_historico ---\n",
    "print(\"‚Üí Atualizando DataFrames moderno e hist√≥rico...\")\n",
    "df_moderno = df[df['Ano'] >= ano_inicio_pnad].copy()\n",
    "df_historico = df[df['Ano'] < ano_inicio_pnad].copy()\n",
    "n_historico = len(df_historico)\n",
    "n_moderno = len(df_moderno)\n",
    "print(f\"  ‚úì df_moderno ({n_moderno} obs) e df_historico ({n_historico} obs) atualizados.\")\n",
    "\n",
    "print(\"\\nPrimeiras linhas do DataFrame com colunas de lag:\")\n",
    "print(df.head())\n",
    "print(\"=\"*80)\n",
    "\n",
    "# --- LISTA DE PREDITORES BASE E DE LAGS ---\n",
    "predictors_base = ['PIB_pc', 'Urbanizacao', 'Industrializacao', 'Educacao']\n",
    "predictors_lags = lag_cols_names\n",
    "# --- FIM DAS LISTAS ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0654709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/6] MODELO OLS (Baseline com k=1 Lags)\n",
      "‚Üí Preditores OLS: ['PIB_pc', 'Urbanizacao', 'Industrializacao', 'Educacao', 'Gini_Lag_1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OLS: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì R¬≤: 0.2597 | AIC: -226.71\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         Gini_Observado   R-squared:                       0.260\n",
      "Model:                            OLS   Adj. R-squared:                  0.169\n",
      "Method:                 Least Squares   F-statistic:                     2.876\n",
      "Date:                Sun, 26 Oct 2025   Prob (F-statistic):             0.0257\n",
      "Time:                        15:00:48   Log-Likelihood:                 119.36\n",
      "No. Observations:                  47   AIC:                            -226.7\n",
      "Df Residuals:                      41   BIC:                            -215.6\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const                0.3294      0.087      3.801      0.000       0.154       0.504\n",
      "PIB_pc            -5.26e-05    5.3e-05     -0.992      0.327      -0.000    5.45e-05\n",
      "Urbanizacao          0.0045      0.122      0.037      0.971      -0.241       0.250\n",
      "Industrializacao     0.1948      0.143      1.361      0.181      -0.094       0.484\n",
      "Educacao             0.0473      0.185      0.255      0.800      -0.327       0.422\n",
      "Gini_Lag_1           0.0615      0.216      0.284      0.778      -0.375       0.498\n",
      "==============================================================================\n",
      "Omnibus:                        4.933   Durbin-Watson:                   2.058\n",
      "Prob(Omnibus):                  0.085   Jarque-Bera (JB):                3.750\n",
      "Skew:                           0.624   Prob(JB):                        0.153\n",
      "Kurtosis:                       3.597   Cond. No.                     1.44e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.44e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 2. MODELO OLS BASELINE (com k lags)\n",
    "# ===========================\n",
    "print(f\"\\n[1/6] MODELO OLS (Baseline com k={k_lags_selecionados} Lags)\")\n",
    "predictors_ols = predictors_base + predictors_lags # Combina base + lags\n",
    "print(f\"‚Üí Preditores OLS: {predictors_ols}\")\n",
    "\n",
    "with tqdm(total=100, desc=\"OLS\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "    X_moderno_ols = df_moderno[predictors_ols]\n",
    "    X_moderno_ols = sm.add_constant(X_moderno_ols)\n",
    "    y_moderno_ols = df_moderno['Gini_Observado']\n",
    "    pbar.update(30)\n",
    "\n",
    "    modelo_ols = sm.OLS(y_moderno_ols, X_moderno_ols).fit()\n",
    "    pbar.update(40)\n",
    "\n",
    "    X_historico_ols = df_historico[predictors_ols]\n",
    "    X_historico_ols = sm.add_constant(X_historico_ols)\n",
    "    df_historico['Gini_OLS'] = modelo_ols.predict(X_historico_ols)\n",
    "    pbar.update(30)\n",
    "\n",
    "print(f\"‚úì R¬≤: {modelo_ols.rsquared:.4f} | AIC: {modelo_ols.aic:.2f}\")\n",
    "print(modelo_ols.summary())\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7396678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/6] MARKOV SWITCHING REGRESSION (com k=1 Lags)\n",
      "‚Üí Preditores Markov: ['PIB_pc', 'Urbanizacao', 'Gini_Lag_1']\n",
      "  (N√∫mero total de coeficientes por regime: 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Markov:  20%|‚ñà‚ñà        | 20/100"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† Falhou: Steady-state probabilities could not be constructed.\n",
      "‚Üí Usando K-means como fallback...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUM√ÅRIO DO FALLBACK (K-Means + OLS por cluster)\n",
      "================================================================================\n",
      "Clusters (regimes) encontrados: 2\n",
      "Vari√°veis usadas no OLS: ['const'] + ['PIB_pc', 'Urbanizacao', 'Gini_Lag_1']\n",
      "\n",
      "--- Coeficientes para Regime (Cluster) 0 ---\n",
      "  const: 0.382153\n",
      "  PIB_pc: -0.000148\n",
      "  Urbanizacao: 0.335148\n",
      "  Gini_Lag_1: 0.238504\n",
      "\n",
      "--- Coeficientes para Regime (Cluster) 1 ---\n",
      "  const: 0.176603\n",
      "  PIB_pc: 0.000103\n",
      "  Urbanizacao: -0.207605\n",
      "  Gini_Lag_1: 0.297377\n",
      "\n",
      "√öltimo regime observado: 1\n",
      "‚Üí Coeficientes do Regime 1 ser√£o usados para o backcasting.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===========================\n",
    "# 3. MARKOV SWITCHING REGRESSION (com k lags)\n",
    "# ===========================\n",
    "print(f\"\\n[2/6] MARKOV SWITCHING REGRESSION (com k={k_lags_selecionados} Lags)\")\n",
    "predictors_markov_base_subset = ['PIB_pc', 'Urbanizacao'] # Usando subconjunto base para Markov\n",
    "predictors_markov = predictors_markov_base_subset + predictors_lags # Combina subconjunto base + lags\n",
    "print(f\"‚Üí Preditores Markov: {predictors_markov}\")\n",
    "\n",
    "X_markov = df_moderno[predictors_markov].values\n",
    "y_markov = df_moderno['Gini_Observado'].values\n",
    "X_markov_const = sm.add_constant(X_markov)\n",
    "\n",
    "# --- Atualizar n√∫mero de preditores para Markov ---\n",
    "num_predictors_markov = len(predictors_markov) + 1 # +1 para constante\n",
    "print(f\"  (N√∫mero total de coeficientes por regime: {num_predictors_markov})\")\n",
    "# --- Fim da atualiza√ß√£o ---\n",
    "\n",
    "try:\n",
    "    with tqdm(total=100, desc=\"Markov\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "        pbar.set_postfix_str(\"Inicializando modelo...\")\n",
    "        modelo_markov = MarkovRegression(\n",
    "            endog=y_markov, k_regimes=2, exog=X_markov_const, switching_variance=True\n",
    "        )\n",
    "        pbar.update(20)\n",
    "\n",
    "        pbar.set_postfix_str(\"Estimando (max 500 iter)...\")\n",
    "        resultado_markov = modelo_markov.fit(maxiter=500, disp=False)\n",
    "        pbar.update(60)\n",
    "\n",
    "        prob_regimes = resultado_markov.smoothed_marginal_probabilities\n",
    "        regime_mais_provavel = np.argmax(prob_regimes, axis=1)\n",
    "        pbar.update(10)\n",
    "\n",
    "        # Backcasting\n",
    "        X_hist_markov = df_historico[predictors_markov].values\n",
    "        X_hist_markov_const = sm.add_constant(X_hist_markov)\n",
    "        ultimo_regime = regime_mais_provavel[-1]\n",
    "\n",
    "        # --- Ajustar √≠ndices dos par√¢metros dinamicamente ---\n",
    "        params = resultado_markov.params\n",
    "        if ultimo_regime == 0:\n",
    "             coefs_pred = params[:num_predictors_markov]\n",
    "        else:\n",
    "             coefs_pred = params[num_predictors_markov:(2 * num_predictors_markov)]\n",
    "        # --- Fim do ajuste ---\n",
    "\n",
    "        df_historico['Gini_Markov'] = X_hist_markov_const @ coefs_pred\n",
    "        pbar.update(5)\n",
    "\n",
    "        sigma_regime = np.sqrt(params[-(modelo_markov.k_regimes):])\n",
    "        sigma_usado = sigma_regime[ultimo_regime]\n",
    "        df_historico['Gini_Markov_Low'] = df_historico['Gini_Markov'] - 1.96 * sigma_usado\n",
    "        df_historico['Gini_Markov_High'] = df_historico['Gini_Markov'] + 1.96 * sigma_usado\n",
    "        pbar.update(5)\n",
    "\n",
    "        df_moderno['Prob_Regime_0'] = prob_regimes[:, 0]\n",
    "        df_moderno['Prob_Regime_1'] = prob_regimes[:, 1]\n",
    "        df_moderno['Regime_Inferido'] = regime_mais_provavel\n",
    "\n",
    "        markov_success = True\n",
    "\n",
    "    print(f\"‚úì Converg√™ncia OK | AIC: {resultado_markov.aic:.2f}\")\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUM√ÅRIO DO MODELO MARKOV SWITCHING (treinado nos dados modernos)\")\n",
    "    print(\"=\"*80)\n",
    "    print(resultado_markov.summary())\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Falhou: {e}\")\n",
    "    print(\"‚Üí Usando K-means como fallback...\")\n",
    "\n",
    "    # K-means e OLS por cluster\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "    kmeans_data = np.column_stack([y_markov, X_markov])\n",
    "    regime_mais_provavel = kmeans.fit_predict(kmeans_data)\n",
    "\n",
    "    coefs_regimes = []\n",
    "    for r in range(2):\n",
    "        mask = regime_mais_provavel == r\n",
    "        X_r = X_markov_const[mask]\n",
    "        y_r = y_markov[mask]\n",
    "        coefs_r = np.linalg.lstsq(X_r, y_r, rcond=None)[0]\n",
    "        coefs_regimes.append(coefs_r)\n",
    "\n",
    "    ultimo_regime = regime_mais_provavel[-1]\n",
    "    X_hist_markov_const = sm.add_constant(df_historico[predictors_markov].values)\n",
    "    df_historico['Gini_Markov'] = X_hist_markov_const @ coefs_regimes[ultimo_regime]\n",
    "    df_historico['Gini_Markov_Low'] = df_historico['Gini_Markov'] - 0.03 # Intervalo fixo\n",
    "    df_historico['Gini_Markov_High'] = df_historico['Gini_Markov'] + 0.03 # Intervalo fixo\n",
    "    df_moderno['Regime_Inferido'] = regime_mais_provavel\n",
    "    markov_success = False\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUM√ÅRIO DO FALLBACK (K-Means + OLS por cluster)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Clusters (regimes) encontrados: {len(coefs_regimes)}\")\n",
    "    print(f\"Vari√°veis usadas no OLS: ['const'] + {predictors_markov}\")\n",
    "    for r, coefs in enumerate(coefs_regimes):\n",
    "        print(f\"\\n--- Coeficientes para Regime (Cluster) {r} ---\")\n",
    "        print(f\"  const: {coefs[0]:.6f}\")\n",
    "        for i, pred_name in enumerate(predictors_markov):\n",
    "             print(f\"  {pred_name}: {coefs[i+1]:.6f}\")\n",
    "\n",
    "    print(f\"\\n√öltimo regime observado: {ultimo_regime}\")\n",
    "    print(f\"‚Üí Coeficientes do Regime {ultimo_regime} ser√£o usados para o backcasting.\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7248e493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/6] GENERALIZED ADDITIVE MODELS (GAMs com k=1 Lags)\n",
      "‚Üí Preditores GAM: ['PIB_pc', 'Urbanizacao', 'Industrializacao', 'Educacao', 'Gini_Lag_1']\n",
      "  (N√∫mero de splines por preditor: [8, 6, 6, 6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GAM:   0%|          | 0/100  0% (0 of 11) |                         | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      " 27% (3 of 11) |######                   | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      " 72% (8 of 11) |##################       | Elapsed Time: 0:00:00 ETA:   0:00:00\n",
      "100% (11 of 11) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "GAM: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Pseudo R¬≤: 0.5812\n",
      "\n",
      "================================================================================\n",
      "SUM√ÅRIO DO MODELO GAM (treinado nos dados modernos)\n",
      "================================================================================\n",
      "LinearGAM                                                                                                 \n",
      "=============================================== ==========================================================\n",
      "Distribution:                        NormalDist Effective DoF:                                     11.9334\n",
      "Link Function:                     IdentityLink Log Likelihood:                                -63094.0804\n",
      "Number of Samples:                           47 AIC:                                           126214.0277\n",
      "                                                AICc:                                          126224.9273\n",
      "                                                GCV:                                                0.0005\n",
      "                                                Scale:                                              0.0003\n",
      "                                                Pseudo R-Squared:                                   0.5812\n",
      "==========================================================================================================\n",
      "Feature Function                  Lambda               Rank         EDoF         P > x        Sig. Code   \n",
      "================================= ==================== ============ ============ ============ ============\n",
      "s(0)                              [0.2512]             8            5.1          6.06e-01                 \n",
      "s(1)                              [0.2512]             6            2.4          3.71e-02     *           \n",
      "s(2)                              [0.2512]             6            1.7          1.78e-01                 \n",
      "s(3)                              [0.2512]             6            1.3          6.52e-02     .           \n",
      "s(4)                              [0.2512]             6            1.4          4.83e-02     *           \n",
      "intercept                                              1            0.0          1.11e-16     ***         \n",
      "==========================================================================================================\n",
      "Significance codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
      "\n",
      "WARNING: Fitting splines and a linear function to a feature introduces a model identifiability problem\n",
      "         which can cause p-values to appear significant when they are not.\n",
      "\n",
      "WARNING: p-values calculated in this manner behave correctly for un-penalized models or models with\n",
      "         known smoothing parameters, but when smoothing parameters have been estimated, the p-values\n",
      "         are typically lower than they should be, meaning that the tests reject the null too readily.\n",
      "None\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 4. GENERALIZED ADDITIVE MODELS (GAMs) (com k lags)\n",
    "# ===========================\n",
    "print(f\"\\n[3/6] GENERALIZED ADDITIVE MODELS (GAMs com k={k_lags_selecionados} Lags)\")\n",
    "predictors_gam = predictors_base + predictors_lags # Combina base + lags\n",
    "print(f\"‚Üí Preditores GAM: {predictors_gam}\")\n",
    "\n",
    "X_gam_treino = df_moderno[predictors_gam].values\n",
    "y_gam_treino = df_moderno['Gini_Observado'].values\n",
    "\n",
    "# --- Ajustar n_splines_list e gam_terms dinamicamente ---\n",
    "n_splines_base = [8, 6, 6, 6]\n",
    "n_splines_lags = [6] * k_lags_selecionados\n",
    "n_splines_list = n_splines_base + n_splines_lags\n",
    "print(f\"  (N√∫mero de splines por preditor: {n_splines_list})\")\n",
    "\n",
    "gam_terms = None\n",
    "num_total_predictors_gam = len(predictors_gam)\n",
    "for i in range(num_total_predictors_gam):\n",
    "    term = s(i, n_splines=n_splines_list[i])\n",
    "    if gam_terms is None:\n",
    "        gam_terms = term\n",
    "    else:\n",
    "        gam_terms += term\n",
    "# --- Fim do ajuste ---\n",
    "\n",
    "\n",
    "with tqdm(total=100, desc=\"GAM\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "    pbar.set_postfix_str(\"Grid search...\")\n",
    "    gam_model = LinearGAM(gam_terms)\n",
    "\n",
    "    gam_model.gridsearch(X_gam_treino, y_gam_treino)\n",
    "    pbar.update(70)\n",
    "\n",
    "    X_gam_historico = df_historico[predictors_gam].values\n",
    "    df_historico['Gini_GAM'] = gam_model.predict(X_gam_historico)\n",
    "    pbar.update(20)\n",
    "\n",
    "    gam_intervals = gam_model.prediction_intervals(X_gam_historico, width=0.95)\n",
    "    df_historico['Gini_GAM_Low'] = gam_intervals[:, 0]\n",
    "    df_historico['Gini_GAM_High'] = gam_intervals[:, 1]\n",
    "    pbar.update(10)\n",
    "\n",
    "print(f\"‚úì Pseudo R¬≤: {gam_model.statistics_['pseudo_r2']['explained_deviance']:.4f}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUM√ÅRIO DO MODELO GAM (treinado nos dados modernos)\")\n",
    "print(\"=\"*80)\n",
    "print(gam_model.summary())\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6628dc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/6] MODELO DE S√âRIE TEMPORAL ESTRUTURAL (UCM)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TimeSeries: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì AIC (modelo forward): -165.66\n",
      "\n",
      "================================================================================\n",
      "SUM√ÅRIO DO MODELO UCM (treinado nos dados modernos - forward)\n",
      "================================================================================\n",
      "                            Unobserved Components Results                            \n",
      "=====================================================================================\n",
      "Dep. Variable:                Gini_Observado   No. Observations:                   47\n",
      "Model:                    local linear trend   Log Likelihood                  88.832\n",
      "                   + damped stochastic cycle   AIC                           -165.663\n",
      "Date:                       Sun, 26 Oct 2025   BIC                           -155.096\n",
      "Time:                               15:00:49   HQIC                          -161.766\n",
      "Sample:                                    0                                         \n",
      "                                        - 47                                         \n",
      "Covariance Type:                         opg                                         \n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "sigma2.irregular     0.0003      0.000      0.846      0.398      -0.000       0.001\n",
      "sigma2.level      5.119e-06      0.002      0.003      0.998      -0.004       0.004\n",
      "sigma2.trend      9.747e-05      0.000      0.276      0.783      -0.001       0.001\n",
      "sigma2.cycle         0.0003      0.000      0.846      0.398      -0.000       0.001\n",
      "frequency.cycle      1.5708         -0       -inf      0.000       1.571       1.571\n",
      "damping.cycle             0   1.46e-22          0      1.000   -2.87e-22    2.87e-22\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   4.93   Jarque-Bera (JB):                 0.94\n",
      "Prob(Q):                              0.03   Prob(JB):                         0.63\n",
      "Heteroskedasticity (H):               1.03   Skew:                            -0.22\n",
      "Prob(H) (two-sided):                  0.95   Kurtosis:                         2.43\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "[2] Covariance matrix is singular or near-singular, with condition number    inf. Standard errors may be unstable.\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 5. S√âRIE TEMPORAL ESTRUTURAL (UCM - Sem altera√ß√µes)\n",
    "# ===========================\n",
    "print(\"\\n[4/6] MODELO DE S√âRIE TEMPORAL ESTRUTURAL (UCM)\")\n",
    "ts_data = df_moderno.set_index('Ano')['Gini_Observado']\n",
    "\n",
    "with tqdm(total=100, desc=\"TimeSeries\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "    pbar.set_postfix_str(\"Modelo forward...\")\n",
    "    modelo_uc = UnobservedComponents(\n",
    "        ts_data, level='local linear trend', cycle=True,\n",
    "        stochastic_cycle=True, damped_cycle=True, irregular=True\n",
    "    )\n",
    "    resultado_uc = modelo_uc.fit(disp=False)\n",
    "    pbar.update(40)\n",
    "\n",
    "    pbar.set_postfix_str(\"Modelo backward...\")\n",
    "    ts_invertida = ts_data[::-1]\n",
    "    modelo_uc_inv = UnobservedComponents(\n",
    "        ts_invertida, level='local linear trend', cycle=True,\n",
    "        stochastic_cycle=True, damped_cycle=True, irregular=True\n",
    "    )\n",
    "    resultado_uc_inv = modelo_uc_inv.fit(disp=False)\n",
    "    pbar.update(40)\n",
    "\n",
    "    pbar.set_postfix_str(\"Backcasting...\")\n",
    "    forecast_inv = resultado_uc_inv.forecast(steps=n_historico)\n",
    "    df_historico['Gini_TimeSeries'] = forecast_inv[::-1].values\n",
    "    forecast_summary = resultado_uc_inv.get_forecast(steps=n_historico).summary_frame(alpha=0.05)\n",
    "    df_historico['Gini_TS_Low'] = forecast_summary['mean_ci_lower'][::-1].values\n",
    "    df_historico['Gini_TS_High'] = forecast_summary['mean_ci_upper'][::-1].values\n",
    "    pbar.update(20)\n",
    "\n",
    "print(f\"‚úì AIC (modelo forward): {resultado_uc.aic:.2f}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUM√ÅRIO DO MODELO UCM (treinado nos dados modernos - forward)\")\n",
    "print(\"=\"*80)\n",
    "print(resultado_uc.summary())\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e4a7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/6] MODELO BAYESIANO HIER√ÅRQUICO (OTIMIZADO com k=1 Lags)\n",
      "‚Üí Normalizando preditores (incluindo 1 lags)...\n",
      "  (Colunas normalizadas: ['PIB_pc_norm', 'Urbanizacao_norm', 'Industrializacao_norm', 'Educacao_norm', 'Gini_Lag_1_norm'])\n",
      "‚Üí Usando 47 observa√ß√µes de df_moderno['Gini_Observado']\n",
      "‚Üí Amostragem MCMC: 4 chains √ó 3000 itera√ß√µes\n",
      "  (target_accept=0.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "INFO:pymc.sampling.mcmc:Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "INFO:pymc.sampling.mcmc:Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha, betas, sigma_temporal, tendencia_passos, sigma]\n",
      "INFO:pymc.sampling.mcmc:NUTS: [alpha, betas, sigma_temporal, tendencia_passos, sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_500 tune and 1_500 draw iterations (6_000 + 6_000 draws total) took 61 seconds.\n",
      "INFO:pymc.sampling.mcmc:Sampling 4 chains for 1_500 tune and 1_500 draw iterations (6_000 + 6_000 draws total) took 61 seconds.\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc.stats.convergence:There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "INFO:pymc.stats.convergence:The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n",
      "ERROR:pymc.stats.convergence:The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì BLACKJAX usado com sucesso\n",
      "\n",
      "======================================================================\n",
      "DIAGN√ìSTICOS DO MODELO\n",
      "======================================================================\n",
      "‚ö† Erro nos diagn√≥sticos: unsupported format string passed to method.__format__\n",
      "======================================================================\n",
      "\n",
      "‚Üí Extraindo predi√ß√µes posteriores...\n",
      "‚úì Predi√ß√µes extra√≠das (104 anos)\n",
      "\n",
      "‚úì Etapa Bayesiana conclu√≠da\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 6. MODELO BAYESIANO HIER√ÅRQUICO (com k lags)\n",
    "# ===========================\n",
    "print(f\"\\n[5/6] MODELO BAYESIANO HIER√ÅRQUICO (OTIMIZADO com k={k_lags_selecionados} Lags)\")\n",
    "\n",
    "if df_moderno.empty or len(df_moderno) < 10:\n",
    "    print(\"‚ö† Dados insuficientes para modelo Bayesiano. Pulando...\")\n",
    "    df_historico['Gini_Bayes_Hierarquico'] = np.nan\n",
    "    df_historico['Gini_Bayes_Low'] = np.nan\n",
    "    df_historico['Gini_Bayes_High'] = np.nan\n",
    "else:\n",
    "    # --- Atualizar colunas para normaliza√ß√£o e coords ---\n",
    "    print(f\"‚Üí Normalizando preditores (incluindo {k_lags_selecionados} lags)...\")\n",
    "    scaler_bayes = StandardScaler()\n",
    "    cols_norm_bayes = predictors_base + predictors_lags # Usa k lags\n",
    "    norm_cols_names_bayes = [col + '_norm' for col in predictors_base] + \\\n",
    "                            [col + '_norm' for col in predictors_lags] # Nomes normalizados\n",
    "    print(f\"  (Colunas normalizadas: {norm_cols_names_bayes})\")\n",
    "\n",
    "    df[norm_cols_names_bayes] = scaler_bayes.fit_transform(df[cols_norm_bayes])\n",
    "\n",
    "    mask_historico = df['Ano'] < ano_inicio_pnad\n",
    "    mask_moderno = df['Ano'] >= ano_inicio_pnad\n",
    "    historico_idx = np.where(mask_historico)[0]\n",
    "    moderno_idx = np.where(mask_moderno)[0]\n",
    "\n",
    "    coords = {\"preditores\": norm_cols_names_bayes} # Atualizado coords\n",
    "    X_data_total = df[coords[\"preditores\"]].values\n",
    "    # --- Fim da atualiza√ß√£o ---\n",
    "\n",
    "    gini_col = 'Gini_Observado'\n",
    "    if gini_col not in df_moderno.columns:\n",
    "         gini_col = 'Gini_Verdadeiro'; print(f\"‚Üí Usando coluna: '{gini_col}'\")\n",
    "\n",
    "    try:\n",
    "        y_observado = df_moderno[gini_col].dropna().values\n",
    "        print(f\"‚Üí Usando {len(y_observado)} observa√ß√µes de df_moderno['{gini_col}']\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Erro ao extrair y_observado: {e}\"); raise\n",
    "\n",
    "    n_total = len(df)\n",
    "    bayesian_run_success = False\n",
    "    trace_avancado = None\n",
    "\n",
    "    with pm.Model(coords=coords) as modelo_bayes_avancado:\n",
    "        alpha = pm.Normal('alpha', mu=0.55, sigma=0.1)\n",
    "        # --- O modelo adapta-se automaticamente aos preditores via dims ---\n",
    "        betas = pm.Normal('betas', mu=0, sigma=0.3, dims=\"preditores\")\n",
    "        # --- Fim da adapta√ß√£o ---\n",
    "\n",
    "        sigma_temporal = pm.HalfNormal('sigma_temporal', sigma=0.01)\n",
    "        tendencia_passos = pm.Normal('tendencia_passos', mu=0, sigma=sigma_temporal, shape=n_total)\n",
    "        tendencia = pm.Deterministic('tendencia', pm.math.cumsum(tendencia_passos))\n",
    "\n",
    "        sigma = pm.HalfNormal('sigma', sigma=0.02)\n",
    "        mu = alpha + pm.math.dot(X_data_total, betas) + tendencia # Usa X_data_total com k lags norm\n",
    "\n",
    "        y_obs = pm.Normal('y_obs', mu=mu[moderno_idx], sigma=sigma, observed=y_observado)\n",
    "        mu_hist = pm.Deterministic('mu_hist', mu[historico_idx])\n",
    "\n",
    "        print(\"‚Üí Amostragem MCMC: 4 chains √ó 3000 itera√ß√µes\")\n",
    "        print(\"  (target_accept=0.95)\")\n",
    "        samplers_config = [(\"blackjax\", {\"sampler\": \"blackjax\"}), (\"nuts\", {})]\n",
    "\n",
    "        for sampler_name, sampler_kwargs in samplers_config:\n",
    "            try:\n",
    "                trace_avancado = pm.sample(draws=1500, tune=1500, chains=4, target_accept=0.95, progressbar=True, return_inferencedata=True, **sampler_kwargs)\n",
    "                print(f\"‚úì {sampler_name.upper()} usado com sucesso\")\n",
    "                bayesian_run_success = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† {sampler_name.upper()} falhou: {str(e)[:100]}\")\n",
    "                if sampler_name == samplers_config[-1][0]: print(\"‚úó Todos os samplers falharam\")\n",
    "                else: print(\"‚Üí Tentando pr√≥ximo sampler...\")\n",
    "\n",
    "    if bayesian_run_success and trace_avancado is not None:\n",
    "        print(\"\\n\" + \"=\"*70); print(\"DIAGN√ìSTICOS DO MODELO\"); print(\"=\"*70)\n",
    "        try:\n",
    "            rhat = az.rhat(trace_avancado, var_names=[\"alpha\", \"betas\"])\n",
    "            ess = az.ess(trace_avancado, var_names=[\"alpha\", \"betas\"])\n",
    "            print(f\"R-hat m√°ximo: {rhat.max().values:.4f} (ideal < 1.01)\")\n",
    "            print(f\"ESS m√≠nimo: {ess.min().values:.0f} (ideal > 400)\")\n",
    "            summary_bayes = az.summary(trace_avancado, var_names=[\"alpha\", \"betas\", \"sigma_temporal\", \"sigma\"], stat_focus=\"median\")\n",
    "            print(\"\\nPAR√ÇMETROS PRINCIPAIS:\"); print(summary_bayes[['mean', 'sd', 'hdi_3%', 'hdi_97%', 'r_hat']])\n",
    "        except Exception as e: print(f\"‚ö† Erro nos diagn√≥sticos: {e}\")\n",
    "        print(\"=\"*70)\n",
    "\n",
    "        try:\n",
    "            print(\"\\n‚Üí Extraindo predi√ß√µes posteriores...\")\n",
    "            posterior_pred = trace_avancado.posterior['mu_hist']\n",
    "            df_historico['Gini_Bayes_Hierarquico'] = posterior_pred.mean(dim=['chain', 'draw']).values\n",
    "            hdi = az.hdi(posterior_pred, hdi_prob=0.95)\n",
    "            df_historico['Gini_Bayes_Low'] = hdi['mu_hist'].sel(hdi='lower').values\n",
    "            df_historico['Gini_Bayes_High'] = hdi['mu_hist'].sel(hdi='higher').values\n",
    "            print(f\"‚úì Predi√ß√µes extra√≠das ({len(df_historico)} anos)\")\n",
    "        except KeyError as e:\n",
    "            print(f\"‚ö† Vari√°vel n√£o encontrada no trace: {e} ‚Üí Usando fallback (NaN)\"); df_historico[['Gini_Bayes_Hierarquico', 'Gini_Bayes_Low', 'Gini_Bayes_High']] = np.nan\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Erro inesperado na extra√ß√£o: {e}\"); df_historico[['Gini_Bayes_Hierarquico', 'Gini_Bayes_Low', 'Gini_Bayes_High']] = np.nan\n",
    "    else:\n",
    "        print(\"\\n‚ö† Amostragem MCMC falhou completamente ‚Üí S√©rie Bayesiana n√£o dispon√≠vel\"); df_historico[['Gini_Bayes_Hierarquico', 'Gini_Bayes_Low', 'Gini_Bayes_High']] = np.nan\n",
    "\n",
    "print(\"\\n‚úì Etapa Bayesiana conclu√≠da\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c21bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6/6] COMPUTA√á√ÉO QU√ÇNTICA: QAOA (com k=1 Lags)\n",
      "‚Üí Preditores QAOA: ['PIB_pc', 'Urbanizacao', 'Industrializacao', 'Educacao', 'Gini_Lag_1']\n",
      "‚ö† Vers√£o otimizada: 10 qubits (5 vars √ó 2 bits/var), 30 itera√ß√µes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QAOA: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Conclu√≠do em 704.8s\n",
      "\n",
      "================================================================================\n",
      "SUM√ÅRIO DO MODELO QU√ÇNTICO (QAOA com k=1 Lags)\n",
      "================================================================================\n",
      "--- Resultado Bruto (Bits √ìtimos) ---\n",
      "fval=5.531738291342572, beta_0_0=1.0, beta_0_1=0.0, beta_1_0=0.0, beta_1_1=0.0, beta_2_0=1.0, beta_2_1=0.0, beta_3_0=0.0, beta_3_1=0.0, beta_4_0=0.0, beta_4_1=0.0, status=SUCCESS\n",
      "\n",
      "--- Coeficientes Finais Reconstru√≠dos ---\n",
      " (Valores de 2 bits antes da normaliza√ß√£o: [1. 0. 1. 0. 0.])\n",
      " (Valores normalizados [0,1]: [0.25 0.   0.25 0.   0.  ])\n",
      "\n",
      "Coeficientes Finais (usados na previs√£o):\n",
      "  beta_PIB_pc: -0.050000\n",
      "  beta_Urbanizacao: -0.100000\n",
      "  beta_Industrializacao: -0.050000\n",
      "  beta_Educacao: -0.100000\n",
      "  beta_Gini_Lag_1: -0.100000\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "‚úì PIPELINE COMPLETO\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 7. COMPUTA√á√ÉO QU√ÇNTICA (QAOA) - VERS√ÉO R√ÅPIDA (com k lags)\n",
    "# ===========================\n",
    "print(f\"\\n[6/6] COMPUTA√á√ÉO QU√ÇNTICA: QAOA (com k={k_lags_selecionados} Lags)\")\n",
    "\n",
    "# --- Atualizar preditores e n√∫mero de vari√°veis/qubits ---\n",
    "predictors_qaoa = predictors_base + predictors_lags # Combina base + k lags\n",
    "print(f\"‚Üí Preditores QAOA: {predictors_qaoa}\")\n",
    "n_vars = len(predictors_qaoa) # N√∫mero de vari√°veis (4 base + k lags)\n",
    "n_bits = 2 # Mantido 2 bits por vari√°vel\n",
    "n_qubits = n_vars * n_bits\n",
    "print(f\"‚ö† Vers√£o otimizada: {n_qubits} qubits ({n_vars} vars √ó {n_bits} bits/var), 30 itera√ß√µes\")\n",
    "# --- Fim da atualiza√ß√£o ---\n",
    "\n",
    "\n",
    "X_quantum = df_moderno[predictors_qaoa].values\n",
    "y_quantum = df_moderno['Gini_Observado'].values\n",
    "\n",
    "# Normaliza√ß√£o\n",
    "X_min = X_quantum.min(axis=0); X_max = X_quantum.max(axis=0)\n",
    "y_min = y_quantum.min(); y_max = y_quantum.max()\n",
    "X_quantum_norm = 2 * (X_quantum - X_min) / (X_max - X_min) - 1\n",
    "y_quantum_norm = 2 * (y_quantum - y_min) / (y_max - y_min) - 1\n",
    "\n",
    "n_samples = 5 # Mantido baixo\n",
    "X_q = X_quantum_norm[:n_samples]; y_q = y_quantum_norm[:n_samples]\n",
    "XtX = X_q.T @ X_q; Xty = X_q.T @ y_q\n",
    "\n",
    "qp = QuadraticProgram()\n",
    "\n",
    "with tqdm(total=100, desc=\"QAOA\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "    pbar.set_postfix_str(\"Montando problema...\")\n",
    "    # --- Loops atualizados para n_vars ---\n",
    "    for i in range(n_vars):\n",
    "        for j in range(n_bits):\n",
    "            qp.binary_var(f'beta_{i}_{j}')\n",
    "\n",
    "    linear = {}; quadratic = {}\n",
    "    for i in range(n_vars):\n",
    "        for b in range(n_bits):\n",
    "            var_name = f'beta_{i}_{b}'; weight = 2 ** b\n",
    "            linear[var_name] = -2 * Xty[i] * weight\n",
    "            for j in range(n_vars):\n",
    "                for b2 in range(n_bits):\n",
    "                    var_name2 = f'beta_{j}_{b2}'; weight2 = 2 ** b2\n",
    "                    if var_name <= var_name2:\n",
    "                        quadratic[(var_name, var_name2)] = XtX[i, j] * weight * weight2\n",
    "    # --- Fim da atualiza√ß√£o ---\n",
    "\n",
    "    qp.minimize(linear=linear, quadratic=quadratic)\n",
    "    pbar.update(20)\n",
    "\n",
    "    try:\n",
    "        pbar.set_postfix_str(\"Inicializando sampler...\")\n",
    "        sampler = Sampler()\n",
    "        qaoa = QAOA(sampler=sampler, optimizer=COBYLA(maxiter=30), reps=2)\n",
    "        optimizer = MinimumEigenOptimizer(qaoa)\n",
    "        pbar.update(10)\n",
    "\n",
    "        pbar.set_postfix_str(\"Otimizando (30 iter)...\")\n",
    "        start_time = time.time()\n",
    "        resultado_qaoa = optimizer.solve(qp)\n",
    "        elapsed = time.time() - start_time\n",
    "        pbar.update(60)\n",
    "\n",
    "        # --- Reconstru√ß√£o e Previs√£o atualizadas para n_vars ---\n",
    "        coefs_quanticos = np.zeros(n_vars)\n",
    "        for i in range(n_vars):\n",
    "            for b in range(n_bits):\n",
    "                var_name = f'beta_{i}_{b}'\n",
    "                if var_name in resultado_qaoa.variables_dict:\n",
    "                    coefs_quanticos[i] += resultado_qaoa.variables_dict[var_name] * (2 ** b)\n",
    "\n",
    "        coefs_quanticos_norm = coefs_quanticos / (2 ** n_bits)\n",
    "        coefs_quanticos_final = coefs_quanticos_norm * 0.2 - 0.1 # Heur√≠stica\n",
    "\n",
    "        X_hist_qaoa = df_historico[predictors_qaoa].values # Usa df_historico com k lags\n",
    "        X_hist_norm = 2 * (X_hist_qaoa - X_min) / (X_max - X_min) - 1\n",
    "        pred_quantum_norm = X_hist_norm @ coefs_quanticos_final\n",
    "        df_historico['Gini_Quantum'] = (pred_quantum_norm + 1) / 2 * (y_max - y_min) + y_min\n",
    "        # --- Fim da atualiza√ß√£o ---\n",
    "        pbar.update(10)\n",
    "\n",
    "        quantum_success = True\n",
    "        print(f\"‚úì Conclu√≠do em {elapsed:.1f}s\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"SUM√ÅRIO DO MODELO QU√ÇNTICO (QAOA com k={k_lags_selecionados} Lags)\")\n",
    "        print(\"=\"*80)\n",
    "        print(\"--- Resultado Bruto (Bits √ìtimos) ---\")\n",
    "        print(resultado_qaoa)\n",
    "        print(\"\\n--- Coeficientes Finais Reconstru√≠dos ---\")\n",
    "        print(f\" (Valores de {n_bits} bits antes da normaliza√ß√£o: {coefs_quanticos})\")\n",
    "        print(f\" (Valores normalizados [0,1]: {coefs_quanticos_norm})\")\n",
    "        print(\"\\nCoeficientes Finais (usados na previs√£o):\")\n",
    "        for i, name in enumerate(predictors_qaoa): # Usa predictors_qaoa atualizado\n",
    "            print(f\"  beta_{name}: {coefs_quanticos_final[i]:.6f}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Falhou: {e}\")\n",
    "        print(\"‚Üí Usando fallback OLS\")\n",
    "        df_historico['Gini_Quantum'] = df_historico['Gini_OLS']\n",
    "        quantum_success = False\n",
    "\n",
    "\n",
    "print(\"\\n================================================================================\")\n",
    "print(\"‚úì PIPELINE COMPLETO\")\n",
    "print(\"================================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6e73094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7/8] YGGDRASIL DECISION FORESTS (YDF) (GBT & RF com k=1 Lags)\n",
      "‚Üí Preditores YDF: ['PIB_pc', 'Urbanizacao', 'Industrializacao', 'Educacao', 'Gini_Lag_1']\n",
      "  (Observa√ß√µes usadas para treino YDF ap√≥s dropna: 47)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YDF GBT:   0%|          | 0/100"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 47 examples\n",
      "Model trained in 0:00:00.084011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YDF GBT: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì YDF GBT treinado e previs√µes geradas (CPU).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YDF RandForest:   0%|          | 0/100"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 47 examples\n",
      "Model trained in 0:00:00.009817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YDF RandForest: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì YDF Random Forest treinado e previs√µes geradas (CPU).\n",
      "(GPU usado para treino YDF: False - YDF treina na CPU)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 8. YGGDRASIL DECISION FORESTS (YDF) (GBT & RF) (com k lags)\n",
    "# ===========================\n",
    "\n",
    "\n",
    "print(f\"\\n[7/8] YGGDRASIL DECISION FORESTS (YDF) (GBT & RF com k={k_lags_selecionados} Lags)\")\n",
    "\n",
    "predictors_ml = predictors_base + predictors_lags\n",
    "print(f\"‚Üí Preditores YDF: {predictors_ml}\")\n",
    "\n",
    "# Prepara dados para YDF (usa DataFrames Pandas diretamente)\n",
    "ml_data_pd = df_moderno[['Gini_Observado'] + predictors_ml].copy().dropna()\n",
    "target_column = 'Gini_Observado' # Nome da coluna alvo\n",
    "\n",
    "print(f\"  (Observa√ß√µes usadas para treino YDF ap√≥s dropna: {len(ml_data_pd)})\")\n",
    "\n",
    "\n",
    "# Prepara dados hist√≥ricos para predi√ß√£o (como DataFrame)\n",
    "X_hist_ml_pd = df_historico[['Ano'] + predictors_ml].copy() # Mant√©m Ano se precisar indexar\n",
    "# Lida com NaNs nos preditores hist√≥ricos\n",
    "nan_mask_hist_ml = X_hist_ml_pd[predictors_ml].isnull().any(axis=1)\n",
    "X_hist_ml_clean_pd = X_hist_ml_pd.loc[~nan_mask_hist_ml, predictors_ml] # DataFrame limpo para predi√ß√£o\n",
    "\n",
    "# Inicializa colunas de previs√£o no DataFrame hist√≥rico\n",
    "df_historico['Gini_YDF_GBT'] = np.nan # Gradient Boosted Trees YDF\n",
    "df_historico['Gini_YDF_RF'] = np.nan  # Random Forest YDF\n",
    "\n",
    "ydf_models_trained = False\n",
    "# S√≥ prossegue se ydf foi importado e h√° dados suficientes\n",
    "if ydf and not ml_data_pd.empty and not X_hist_ml_clean_pd.empty:\n",
    "    try:\n",
    "        # --- Gradient Boosted Trees (YDF) ---\n",
    "        with tqdm(total=100, desc=\"YDF GBT\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "            pbar.set_postfix_str(\"Treinando (CPU)...\")\n",
    "            # Define o learner (aprendiz)\n",
    "            gbt_learner = ydf.GradientBoostedTreesLearner(\n",
    "                label=target_column, # Especifica a coluna alvo\n",
    "                task=ydf.Task.REGRESSION, # Especifica tarefa de regress√£o\n",
    "                # num_trees=100, # n√∫mero de √°rvores\n",
    "                # Outros hiperpar√¢metros podem ser ajustados aqui\n",
    "            )\n",
    "            # Treina o modelo usando o DataFrame pandas\n",
    "            gbt_model = gbt_learner.train(ml_data_pd)\n",
    "            pbar.update(70)\n",
    "\n",
    "            pbar.set_postfix_str(\"Prevendo...\")\n",
    "            # Prev√™ usando o DataFrame hist√≥rico limpo\n",
    "            predictions_gbt_clean = gbt_model.predict(X_hist_ml_clean_pd)\n",
    "            # A sa√≠da j√° √© um array numpy 1D para regress√£o\n",
    "            df_historico.loc[~nan_mask_hist_ml, 'Gini_YDF_GBT'] = predictions_gbt_clean\n",
    "            print(\"\\n‚úì YDF GBT treinado e previs√µes geradas (CPU).\")\n",
    "            pbar.update(30)\n",
    "\n",
    "        # --- Random Forest (YDF) ---\n",
    "        with tqdm(total=100, desc=\"YDF RandForest\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "            pbar.set_postfix_str(\"Treinando (CPU)...\")\n",
    "            rf_learner = ydf.RandomForestLearner(\n",
    "                label=target_column,\n",
    "                task=ydf.Task.REGRESSION,\n",
    "                # num_trees=100,\n",
    "            )\n",
    "            # Treina o modelo\n",
    "            rf_model = rf_learner.train(ml_data_pd)\n",
    "            pbar.update(70)\n",
    "\n",
    "            pbar.set_postfix_str(\"Prevendo...\")\n",
    "            # Prev√™ usando o DataFrame hist√≥rico limpo\n",
    "            predictions_rf_clean = rf_model.predict(X_hist_ml_clean_pd)\n",
    "            df_historico.loc[~nan_mask_hist_ml, 'Gini_YDF_RF'] = predictions_rf_clean\n",
    "            print(\"\\n‚úì YDF Random Forest treinado e previs√µes geradas (CPU).\")\n",
    "            pbar.update(30)\n",
    "        ydf_models_trained = True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚úó Erro durante o treinamento/previs√£o com YDF: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        # Garante que as colunas existam mesmo se o treino falhar\n",
    "        if 'Gini_YDF_GBT' not in df_historico: df_historico['Gini_YDF_GBT'] = np.nan\n",
    "        if 'Gini_YDF_RF' not in df_historico: df_historico['Gini_YDF_RF'] = np.nan\n",
    "\n",
    "else:\n",
    "     if not ydf:\n",
    "         print(\"‚ö† YDF n√£o est√° instalado. Pulando esta etapa.\")\n",
    "     else:\n",
    "         print(\"‚ö† Dados insuficientes para YDF ap√≥s remover NaNs. Pulando...\")\n",
    "     # Garante que as colunas existam mesmo se pulado\n",
    "     if 'Gini_YDF_GBT' not in df_historico: df_historico['Gini_YDF_GBT'] = np.nan\n",
    "     if 'Gini_YDF_RF' not in df_historico: df_historico['Gini_YDF_RF'] = np.nan\n",
    "\n",
    "print(f\"(GPU usado para treino YDF: False - YDF treina na CPU)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27439f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[8/8] TESTE GRANGER E MODELO VARMAX (com k=1 Lags)\n",
      "\n",
      "--- Iniciando Teste de Causalidade de Granger ---\n",
      "Vari√°veis potenciais para teste: ['Gini_Observado', 'PIB_pc', 'Urbanizacao', 'Industrializacao', 'Educacao', 'Gini_Lag_1']\n",
      "Observa√ß√µes usadas para teste Granger (ap√≥s diff e dropna): 46\n",
      "\n",
      "Resultados do Teste (p-valor < 0.05 indica causalidade):\n",
      "  ‚Üí Industrializacao Granger-causa Gini_Observado (p=0.0467)\n",
      "  ‚Üí Gini_Observado Granger-causa Industrializacao (p=0.0409)\n",
      "  ‚Üí Gini_Observado Granger-causa Gini_Lag_1 (p=0.0000)\n",
      "  ‚Üí Industrializacao Granger-causa Urbanizacao (p=0.0292)\n",
      "\n",
      "--- Vari√°veis Selecionadas ---\n",
      "Vari√°veis End√≥genas para VARMAX: ['Gini_Observado', 'Industrializacao', 'Gini_Lag_1']\n",
      "Vari√°veis Ex√≥genas para VARMAX: ['PIB_pc', 'Urbanizacao', 'Educacao']\n",
      "------------------------------\n",
      "\n",
      "--- Iniciando Modelo VARMAX ---\n",
      "Observa√ß√µes usadas para ajuste VARMAX (ap√≥s dropna): 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VARMAX: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö† Modelo VARMAX invertido n√£o convergiu ou falhou no ajuste. Backcasting ser√° NaN.\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# 8. TESTE DE CAUSALIDADE DE GRANGER E MODELO VARMAX (com k lags)\n",
    "# ==========================================================\n",
    "\n",
    "print(f\"\\n[8/8] TESTE GRANGER E MODELO VARMAX (com k={k_lags_selecionados} Lags)\")\n",
    "\n",
    "# --- 8.a Teste de Causalidade de Granger ---\n",
    "print(\"\\n--- Iniciando Teste de Causalidade de Granger ---\")\n",
    "potential_vars = ['Gini_Observado'] + predictors_base + predictors_lags\n",
    "print(f\"Vari√°veis potenciais para teste: {potential_vars}\")\n",
    "\n",
    "# Preparar dados para o teste (modernos, diferenciados para estacionariedade)\n",
    "granger_data_raw = df_moderno[potential_vars].copy().dropna()\n",
    "\n",
    "if len(granger_data_raw) > k_lags_selecionados + 5: # Checa se h√° dados suficientes ap√≥s diferencia√ß√£o e lags\n",
    "    granger_data_diff = granger_data_raw.diff().dropna()\n",
    "    print(f\"Observa√ß√µes usadas para teste Granger (ap√≥s diff e dropna): {len(granger_data_diff)}\")\n",
    "\n",
    "    granger_results = {}\n",
    "    endog_cols = ['Gini_Observado'] # Gini √© sempre end√≥geno\n",
    "    exog_cols = []\n",
    "\n",
    "    tested_pairs = set()\n",
    "\n",
    "    print(\"\\nResultados do Teste (p-valor < 0.05 indica causalidade):\")\n",
    "    for col1 in potential_vars:\n",
    "        for col2 in potential_vars:\n",
    "            if col1 == col2:\n",
    "                continue\n",
    "            pair = tuple(sorted((col1, col2))) # Evita testar A->B e B->A separadamente no output\n",
    "            if pair in tested_pairs:\n",
    "                continue\n",
    "            tested_pairs.add(pair)\n",
    "\n",
    "            # Testar se col2 Granger-causa col1\n",
    "            try:\n",
    "                test_result_12 = grangercausalitytests(granger_data_diff[[col1, col2]], maxlag=k_lags_selecionados, verbose=False)\n",
    "                # Checa se o p-valor do F-test no lag selecionado √© significativo\n",
    "                p_value_12 = test_result_12[k_lags_selecionados][0]['ssr_ftest'][1]\n",
    "                if p_value_12 < 0.05:\n",
    "                    print(f\"  ‚Üí {col2} Granger-causa {col1} (p={p_value_12:.4f})\")\n",
    "                    # Se causa ou √© causado pelo Gini, adiciona aos end√≥genos (se n√£o for o pr√≥prio Gini)\n",
    "                    if col1 == 'Gini_Observado' and col2 not in endog_cols:\n",
    "                        endog_cols.append(col2)\n",
    "                    elif col2 == 'Gini_Observado' and col1 not in endog_cols:\n",
    "                        endog_cols.append(col1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  ! Erro ao testar {col2} -> {col1}: {e}\")\n",
    "\n",
    "            # Testar se col1 Granger-causa col2 (s√≥ para registro e decis√£o endog/exog)\n",
    "            try:\n",
    "                test_result_21 = grangercausalitytests(granger_data_diff[[col2, col1]], maxlag=k_lags_selecionados, verbose=False)\n",
    "                p_value_21 = test_result_21[k_lags_selecionados][0]['ssr_ftest'][1]\n",
    "                if p_value_21 < 0.05:\n",
    "                     print(f\"  ‚Üí {col1} Granger-causa {col2} (p={p_value_21:.4f})\")\n",
    "                     # Se causa ou √© causado pelo Gini, adiciona aos end√≥genos (se n√£o for o pr√≥prio Gini)\n",
    "                     if col2 == 'Gini_Observado' and col1 not in endog_cols:\n",
    "                         endog_cols.append(col1)\n",
    "                     elif col1 == 'Gini_Observado' and col2 not in endog_cols:\n",
    "                          endog_cols.append(col2)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  ! Erro ao testar {col1} -> {col2}: {e}\")\n",
    "\n",
    "    # Definir ex√≥genos como aqueles n√£o selecionados como end√≥genos (exceto Gini)\n",
    "    exog_cols = [col for col in potential_vars if col not in endog_cols]\n",
    "\n",
    "    print(\"\\n--- Vari√°veis Selecionadas ---\")\n",
    "    print(f\"Vari√°veis End√≥genas para VARMAX: {endog_cols}\")\n",
    "    print(f\"Vari√°veis Ex√≥genas para VARMAX: {exog_cols}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # --- 8.b Modelo VARMAX ---\n",
    "    print(\"\\n--- Iniciando Modelo VARMAX ---\")\n",
    "    # Preparar dados para VARMAX (sem diferenciar, mas dropna e inverter)\n",
    "    varmax_data_fit_raw = df_moderno[endog_cols + exog_cols].copy()\n",
    "    # Drop rows where ANY of the selected endog/exog variables are NaN\n",
    "    varmax_data_fit = varmax_data_fit_raw.dropna()\n",
    "\n",
    "    endog_varmax_fit = varmax_data_fit[endog_cols]\n",
    "    exog_varmax_fit = varmax_data_fit[exog_cols] if exog_cols else None # Exog pode ser None\n",
    "    print(f\"Observa√ß√µes usadas para ajuste VARMAX (ap√≥s dropna): {len(endog_varmax_fit)}\")\n",
    "\n",
    "    df_historico['Gini_VARMAX'] = np.nan\n",
    "    df_historico['Gini_VARMAX_Low'] = np.nan\n",
    "    df_historico['Gini_VARMAX_High'] = np.nan\n",
    "    resultado_varmax_inv = None # Initialize\n",
    "\n",
    "    # Precisa de observa√ß√µes suficientes para o n√∫mero de par√¢metros\n",
    "    min_obs_needed = k_lags_selecionados * (len(endog_cols)**2) + len(endog_cols) # Aproxima√ß√£o m√≠nima\n",
    "    if len(endog_varmax_fit) > min_obs_needed + 5: # Checa se h√° dados suficientes\n",
    "         with tqdm(total=100, desc=\"VARMAX\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt}') as pbar:\n",
    "              try:\n",
    "                   pbar.set_postfix_str(\"Preparando dados invertidos...\")\n",
    "                   endog_invertido = endog_varmax_fit[::-1]\n",
    "                   exog_invertido = exog_varmax_fit[::-1] if exog_varmax_fit is not None else None\n",
    "                   pbar.update(10)\n",
    "\n",
    "                   pbar.set_postfix_str(\"Ajustando VARMAX (ordem (1,0))...\")\n",
    "                   # Modelo VARMAX(p,q) onde p=k_lags_selecionados, q=0\n",
    "                   # Nota: A ordem AR (p) se aplica √†s vari√°veis end√≥genas\n",
    "                   modelo_varmax_inv = VARMAX(endog=endog_invertido, exog=exog_invertido, order=(k_lags_selecionados, 0))\n",
    "\n",
    "                   try:\n",
    "                        resultado_varmax_inv = modelo_varmax_inv.fit(disp=False, maxiter=200) # Aumentar maxiter se necess√°rio\n",
    "                   except (np.linalg.LinAlgError, ValueError) as fit_err:\n",
    "                        print(f\"\\n‚ö† Erro ao ajustar VARMAX inicial ({fit_err}), tentando simplificar...\")\n",
    "                        try:\n",
    "                             modelo_varmax_inv = VARMAX(endog=endog_invertido, exog=exog_invertido, order=(k_lags_selecionados, 0), trend='c')\n",
    "                             resultado_varmax_inv = modelo_varmax_inv.fit(disp=False, maxiter=200, method='powell')\n",
    "                        except Exception as fit_err_2:\n",
    "                             print(f\"\\n‚ö† Falha ao ajustar VARMAX simplificado: {fit_err_2}\")\n",
    "                             resultado_varmax_inv = None\n",
    "\n",
    "                   pbar.update(60)\n",
    "\n",
    "                   if resultado_varmax_inv is not None and resultado_varmax_inv.mle_retvals['converged']:\n",
    "                        pbar.set_postfix_str(\"Backcasting...\")\n",
    "                        # Preparar ex√≥genos hist√≥ricos para previs√£o\n",
    "                        X_hist_varmax_exog = None\n",
    "                        if exog_cols: # S√≥ prepara se houver ex√≥genos\n",
    "                            X_hist_varmax_exog_raw = df_historico[exog_cols].copy()\n",
    "                            X_hist_varmax_exog_raw.fillna(method='ffill', inplace=True)\n",
    "                            X_hist_varmax_exog_raw.fillna(method='bfill', inplace=True)\n",
    "                            X_hist_varmax_exog = X_hist_varmax_exog_raw[::-1].values # Inverter\n",
    "\n",
    "                        # Fazer backcasting\n",
    "                        forecast_inv = resultado_varmax_inv.get_forecast(steps=n_historico, exog=X_hist_varmax_exog)\n",
    "                        forecast_summary = forecast_inv.summary_frame(alpha=0.05)\n",
    "\n",
    "                        # Encontrar o √≠ndice de 'Gini_Observado' nas colunas end√≥genas\n",
    "                        try:\n",
    "                            gini_idx = endog_cols.index('Gini_Observado')\n",
    "                            # Extrair a previs√£o e os intervalos corretos para Gini\n",
    "                            # Os nomes das colunas no summary_frame podem ser 'mean', 'mean_ci_lower', etc. se endog for univariado\n",
    "                            # ou podem incluir o nome da vari√°vel endog se for multivariado (ex: 'mean_Gini_Observado')\n",
    "                            mean_col_name = f'mean_{endog_cols[gini_idx]}' if len(endog_cols) > 1 else 'mean'\n",
    "                            lower_col_name = f'mean_ci_lower_{endog_cols[gini_idx]}' if len(endog_cols) > 1 else 'mean_ci_lower'\n",
    "                            upper_col_name = f'mean_ci_upper_{endog_cols[gini_idx]}' if len(endog_cols) > 1 else 'mean_ci_upper'\n",
    "\n",
    "                            # Verificar se as colunas esperadas existem\n",
    "                            if mean_col_name in forecast_summary.columns:\n",
    "                                df_historico['Gini_VARMAX'] = forecast_summary[mean_col_name][::-1].values\n",
    "                                df_historico['Gini_VARMAX_Low'] = forecast_summary[lower_col_name][::-1].values\n",
    "                                df_historico['Gini_VARMAX_High'] = forecast_summary[upper_col_name][::-1].values\n",
    "                            else:\n",
    "                                print(f\"‚ö† Coluna de m√©dia '{mean_col_name}' n√£o encontrada no forecast_summary. Colunas dispon√≠veis: {forecast_summary.columns}\")\n",
    "                                print(\"   Verifique a sa√≠da do VARMAX. Backcasting ser√° NaN.\")\n",
    "                                # Deixa como NaN se n√£o encontrar a coluna\n",
    "\n",
    "                        except ValueError:\n",
    "                             print(\"‚ö† 'Gini_Observado' n√£o encontrado nas colunas end√≥genas (erro inesperado). Backcasting ser√° NaN.\")\n",
    "                        except KeyError as ke:\n",
    "                             print(f\"‚ö† Coluna n√£o encontrada ao extrair previs√µes/intervalos: {ke}. Colunas dispon√≠veis: {forecast_summary.columns}\")\n",
    "                             print(\"   Verifique a sa√≠da do VARMAX. Backcasting ser√° NaN.\")\n",
    "\n",
    "                        pbar.update(30)\n",
    "                        print(\"\\n‚úì Backcasting VARMAX conclu√≠do (ou definido como NaN se colunas n√£o encontradas).\")\n",
    "                        print(f\"‚úì AIC (modelo invertido): {resultado_varmax_inv.aic:.2f}\")\n",
    "                        print(\"\\n\" + \"=\"*80)\n",
    "                        print(\"SUM√ÅRIO DO MODELO VARMAX (treinado nos dados modernos invertidos)\")\n",
    "                        print(\"=\"*80)\n",
    "                        print(resultado_varmax_inv.summary())\n",
    "                        print(\"=\"*80)\n",
    "                   else:\n",
    "                        pbar.update(30)\n",
    "                        print(\"\\n‚ö† Modelo VARMAX invertido n√£o convergiu ou falhou no ajuste. Backcasting ser√° NaN.\")\n",
    "\n",
    "              except Exception as e:\n",
    "                   pbar.update(100 - pbar.n)\n",
    "                   print(f\"\\n‚ö† Erro inesperado na etapa VARMAX: {e}\")\n",
    "                   import traceback\n",
    "                   traceback.print_exc() # Imprime o traceback completo para depura√ß√£o\n",
    "\n",
    "    else:\n",
    "         print(f\"‚ö† Dados insuficientes ({len(endog_varmax_fit)} obs) para VARMAX ap√≥s remover NaNs. Necess√°rio > ~{min_obs_needed + 5}. Pulando...\")\n",
    "\n",
    "else:\n",
    "     print(\"‚ö† Dados insuficientes para teste Granger (ap√≥s diff e dropna). Pulando VARMAX.\")\n",
    "\n",
    "print(\"=\"*80) # Final do bloco VARMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7ff88b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "M√âTRICAS DE AVALIA√á√ÉO (vs Gini_Verdadeiro no per√≠odo hist√≥rico, k=1 lags)\n",
      "================================================================================\n",
      "OLS (k=1 Lags)         | MAE: 0.0342 | RMSE: 0.0366 | R¬≤: -12.7699\n",
      "Markov (k=1 Lags)      | MAE: 0.0169 | RMSE: 0.0205 | R¬≤: -3.3292\n",
      "GAM (k=1 Lags)         | MAE: 0.0318 | RMSE: 0.0361 | R¬≤: -12.4381\n",
      "S√©rie Temporal (UCM)   | MAE: 0.2947 | RMSE: 0.3374 | R¬≤: -1171.3369\n",
      "Bayesiano (k=1 Lags)   | MAE: 0.0230 | RMSE: 0.0287 | R¬≤: -7.4664\n",
      "Quantum (k=1 Lags)     | MAE: 0.0570 | RMSE: 0.0583 | R¬≤: -33.9936\n",
      "YDF GBT (k=1 Lags)     | MAE: 0.0095 | RMSE: 0.0107 | R¬≤: -0.1836\n",
      "YDF RF (k=1 Lags)      | MAE: 0.0096 | RMSE: 0.0107 | R¬≤: -0.1862\n",
      "VARMAX (k=1 Lags)      | Coluna 'Gini_VARMAX' n√£o encontrada ou vazia. Pulando m√©tricas.\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 10. M√âTRICAS DE AVALIA√á√ÉO (Atualizado Labels e Modelos)\n",
    "# ===========================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"M√âTRICAS DE AVALIA√á√ÉO (vs Gini_Verdadeiro no per√≠odo hist√≥rico, k={k_lags_selecionados} lags)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "ols_label = f'OLS (k={k_lags_selecionados} Lags)'\n",
    "markov_label = f'Markov (k={k_lags_selecionados} Lags)'\n",
    "gam_label = f'GAM (k={k_lags_selecionados} Lags)'\n",
    "ts_label = 'S√©rie Temporal (UCM)' # Label without k_lags\n",
    "bayes_label = f'Bayesiano (k={k_lags_selecionados} Lags)'\n",
    "quantum_base_label = f'Quantum (k={k_lags_selecionados} Lags)' # Base label for color/dict key consistency\n",
    "gbt_label = f'YDF GBT (k={k_lags_selecionados} Lags)' # Or 'TF GBT' or 'XGBoost'\n",
    "rf_label = f'YDF RF (k={k_lags_selecionados} Lags)' # Or 'TF RF' or 'Random Forest'\n",
    "varmax_label = f'VARMAX (k={k_lags_selecionados} Lags)'\n",
    "\n",
    "\n",
    "modelos_avaliados = {\n",
    "    ols_label: 'Gini_OLS',\n",
    "    markov_label: 'Gini_Markov',\n",
    "    gam_label: 'Gini_GAM',\n",
    "    ts_label: 'Gini_TimeSeries',\n",
    "    bayes_label: 'Gini_Bayes_Hierarquico',\n",
    "    quantum_base_label: 'Gini_Quantum', # Key uses base label\n",
    "    # Adjust column names based on which ML models actually ran (YDF or TF-DF)\n",
    "    gbt_label: 'Gini_YDF_GBT', # Or 'Gini_GBT' or 'Gini_XGB'\n",
    "    rf_label: 'Gini_YDF_RF', # Or 'Gini_TF_RF' or 'Gini_RF'\n",
    "    varmax_label: 'Gini_VARMAX'\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "# Ensure target has no NaNs before alignment in the loop\n",
    "y_verdadeiro_hist = df_historico['Gini_Verdadeiro'].copy().dropna()\n",
    "\n",
    "max_label_len = max(len(nome) for nome in modelos_avaliados.keys()) + 2 # For alignment\n",
    "\n",
    "for nome, coluna in modelos_avaliados.items():\n",
    "    if coluna in df_historico.columns and not df_historico[coluna].isnull().all():\n",
    "        y_pred_hist = df_historico[coluna].copy()\n",
    "\n",
    "        # Align prediction and true values by index, drop missing in either\n",
    "        # Use inner join to only keep indices present in both series after dropping NaNs\n",
    "        aligned_data = pd.concat([y_verdadeiro_hist, y_pred_hist], axis=1, join='inner').dropna()\n",
    "\n",
    "        if len(aligned_data) > 0:\n",
    "            y_true_aligned = aligned_data['Gini_Verdadeiro']\n",
    "            y_pred_aligned = aligned_data[coluna]\n",
    "\n",
    "            try:\n",
    "                mae = mean_absolute_error(y_true_aligned, y_pred_aligned)\n",
    "                rmse = np.sqrt(mean_squared_error(y_true_aligned, y_pred_aligned))\n",
    "                r2 = r2_score(y_true_aligned, y_pred_aligned)\n",
    "                resultados.append({'Modelo': nome, 'MAE': mae, 'RMSE': rmse, 'R¬≤': r2})\n",
    "                # Use max_label_len for consistent alignment in printing\n",
    "                print(f\"{nome:<{max_label_len}s} | MAE: {mae:.4f} | RMSE: {rmse:.4f} | R¬≤: {r2:.4f}\")\n",
    "            except Exception as e:\n",
    "                 # Use max_label_len here too\n",
    "                 print(f\"{nome:<{max_label_len}s} | Erro no c√°lculo das m√©tricas: {e}\")\n",
    "                 resultados.append({'Modelo': nome, 'MAE': np.nan, 'RMSE': np.nan, 'R¬≤': np.nan})\n",
    "        else:\n",
    "            # Use max_label_len here too\n",
    "            print(f\"{nome:<{max_label_len}s} | Sem dados alinhados ap√≥s dropna. Pulando m√©tricas.\")\n",
    "            resultados.append({'Modelo': nome, 'MAE': np.nan, 'RMSE': np.nan, 'R¬≤': np.nan})\n",
    "    else:\n",
    "        # Use max_label_len here too\n",
    "        print(f\"{nome:<{max_label_len}s} | Coluna '{coluna}' n√£o encontrada ou vazia. Pulando m√©tricas.\")\n",
    "        resultados.append({'Modelo': nome, 'MAE': np.nan, 'RMSE': np.nan, 'R¬≤': np.nan})\n",
    "\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f44d7ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CONFIGURANDO DIRET√ìRIO DE SA√çDA (WSL)\n",
      "======================================================================\n",
      "Diret√≥rio de sa√≠da (WSL): /mnt/c/Users/daves/OneDrive/Pessoal/Acad√™mico/Doutorado/Codes\n",
      "Existe: True\n",
      "‚úì Diret√≥rio √© grav√°vel\n",
      "‚úì Dicion√°rio 'cores' definido.\n",
      "\n",
      "======================================================================\n",
      "GERANDO GR√ÅFICO INTERATIVO PLOTLY (Atualizado)\n",
      "======================================================================\n",
      "Aviso Plotly: Coluna 'Gini_VARMAX' n√£o encontrada ou vazia em df_historico.\n",
      "Aviso Plotly: Colunas 'Gini_VARMAX_Low' ou 'Gini_VARMAX_High' n√£o encontradas ou vazias em df_historico.\n",
      "\n",
      "Salvando Plotly em: /mnt/c/Users/daves/OneDrive/Pessoal/Acad√™mico/Doutorado/Codes/grafico_backcasting_interativo_k1lags_full.html\n",
      "‚úì SUCESSO! Gr√°fico Plotly salvo\n",
      "  ‚Üí Arquivo: grafico_backcasting_interativo_k1lags_full.html\n",
      "  ‚Üí Tamanho: 4758.4 KB\n",
      "  ‚Üí Caminho Windows: C:\\\\Users\\\\daves\\\\OneDrive\\\\Pessoal\\\\Acad√™mico\\\\Doutorado\\\\Codes\\\\grafico_backcasting_interativo_k1lags_full.html\n",
      "\n",
      "======================================================================\n",
      "GERANDO GR√ÅFICO EST√ÅTICO MATPLOTLIB (Atualizado)\n",
      "======================================================================\n",
      "Aviso Matplotlib: Coluna 'Gini_VARMAX' n√£o encontrada ou vazia em df_historico.\n",
      "Aviso Matplotlib: Colunas 'Gini_VARMAX_Low' ou 'Gini_VARMAX_High' n√£o encontradas ou vazias em df_historico.\n",
      "\n",
      "Salvando Matplotlib em: /mnt/c/Users/daves/OneDrive/Pessoal/Acad√™mico/Doutorado/Codes/grafico_backcasting_estatico_k1lags_full.jpg\n",
      "‚úì SUCESSO! Gr√°fico Matplotlib salvo\n",
      "  ‚Üí Arquivo: grafico_backcasting_estatico_k1lags_full.jpg\n",
      "  ‚Üí Tamanho: 473.3 KB\n",
      "  ‚Üí Caminho Windows: C:\\\\Users\\\\daves\\\\OneDrive\\\\Pessoal\\\\Acad√™mico\\\\Doutorado\\\\Codes\\\\grafico_backcasting_estatico_k1lags_full.jpg\n",
      "\n",
      "======================================================================\n",
      "RESUMO DOS ARQUIVOS GERADOS\n",
      "======================================================================\n",
      "Diret√≥rio: /mnt/c/Users/daves/OneDrive/Pessoal/Acad√™mico/Doutorado/Codes\n",
      "\n",
      "Arquivos:\n",
      "  1. grafico_backcasting_interativo_k1lags_full.html\n",
      "     Existe: True\n",
      "     Tamanho: 4758.4 KB\n",
      "\n",
      "  2. grafico_backcasting_estatico_k1lags_full.jpg\n",
      "     Existe: True\n",
      "     Tamanho: 473.3 KB\n",
      "\n",
      "  3. gini_regimes_plot.png\n",
      "     Existe: True\n",
      "     Tamanho: 93.2 KB\n",
      "\n",
      "  4. covariaveis_plot.png\n",
      "     Existe: True\n",
      "     Tamanho: 142.6 KB\n",
      "\n",
      "======================================================================\n",
      "‚úì VISUALIZA√á√ÉO CONCLU√çDA (com modelos adicionais)\n",
      "======================================================================\n",
      "\n",
      "‚úì DataFrame final com todas as previs√µes salvo em: /mnt/c/Users/daves/OneDrive/Pessoal/Acad√™mico/Doutorado/Codes/simulacao_resultados_k1lags_full.csv\n",
      "  ‚Üí Caminho Windows: C:\\\\Users\\\\daves\\\\OneDrive\\\\Pessoal\\\\Acad√™mico\\\\Doutorado\\\\Codes\\\\simulacao_resultados_k1lags_full.csv\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# 11. VISUALIZA√á√ÉO - VERS√ÉO WSL \n",
    "# ===========================\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONFIGURANDO DIRET√ìRIO DE SA√çDA (WSL)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Tenta definir output_dir, use o diret√≥rio atual como fallback seguro\n",
    "try:\n",
    "    # Define o diret√≥rio de sa√≠da desejado\n",
    "    output_dir_str = '/mnt/c/Users/daves/OneDrive/Pessoal/Acad√™mico/Doutorado/Codes'\n",
    "    output_dir = Path(output_dir_str)\n",
    "\n",
    "    # Cria o diret√≥rio se n√£o existir (necess√°rio para o teste de escrita)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Verifica se existe e √© grav√°vel\n",
    "    if output_dir.is_dir() and os.access(str(output_dir), os.W_OK):\n",
    "        print(f\"Diret√≥rio de sa√≠da (WSL): {output_dir}\")\n",
    "        print(f\"Existe: True\")\n",
    "        print(f\"‚úì Diret√≥rio √© grav√°vel\")\n",
    "        # Tenta criar e deletar um arquivo teste\n",
    "        test_file = output_dir / \"test_write.tmp\"\n",
    "        test_file.touch()\n",
    "        test_file.unlink()\n",
    "    else:\n",
    "        # Fallback se n√£o existir ou n√£o for grav√°vel\n",
    "        if not output_dir.is_dir():\n",
    "             print(f\"‚ö† Diret√≥rio n√£o existe: {output_dir}\")\n",
    "        else:\n",
    "             print(f\"‚ö† Sem permiss√£o de escrita no diret√≥rio: {output_dir}\")\n",
    "        output_dir = Path.cwd() # Diret√≥rio de trabalho atual\n",
    "        print(f\"‚Üí Usando diret√≥rio atual como fallback: {output_dir}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Erro ao configurar ou verificar diret√≥rio de sa√≠da: {e}\")\n",
    "    output_dir = Path.cwd() # Fallback seguro\n",
    "    print(f\"‚Üí Usando diret√≥rio atual como fallback: {output_dir}\")\n",
    "\n",
    "\n",
    "# --- Labels Atualizados (Garantindo consist√™ncia) ---\n",
    "# Use k_lags_selecionados que deve estar definido em blocos anteriores\n",
    "# Garante que k_lags_selecionados existe, sen√£o define um padr√£o\n",
    "if 'k_lags_selecionados' not in locals():\n",
    "     try:\n",
    "       # Tenta obter do DataFrame df se ele existir e tiver a coluna lag\n",
    "       lag_cols = [col for col in df.columns if 'Gini_Lag_' in col]\n",
    "       k_lags_selecionados = len(lag_cols) if lag_cols else 1\n",
    "       if k_lags_selecionados == 0: k_lags_selecionados = 1\n",
    "       print(f\"AVISO: k_lags_selecionados inferido como {k_lags_selecionados} a partir das colunas do DataFrame.\")\n",
    "     except NameError: # Se df tamb√©m n√£o existir\n",
    "       k_lags_selecionados = 1 # Define um padr√£o se n√£o existir\n",
    "       print(\"AVISO: k_lags_selecionados n√£o definido, usando padr√£o 1.\")\n",
    "\n",
    "\n",
    "ols_label = f'OLS (k={k_lags_selecionados} Lags)'\n",
    "markov_label = f'Markov (k={k_lags_selecionados} Lags)'\n",
    "gam_label = f'GAM (k={k_lags_selecionados} Lags)'\n",
    "ts_label = 'S√©rie Temporal (UCM)'\n",
    "bayes_label = f'Bayesiano (k={k_lags_selecionados} Lags)'\n",
    "quantum_base_label = f'Quantum (k={k_lags_selecionados} Lags)'\n",
    "# Labels para YDF (ajuste se usou TF-DF ou XGBoost/Sklearn)\n",
    "# Assume YDF baseado nos blocos anteriores\n",
    "gbt_label = f'YDF GBT (k={k_lags_selecionados} Lags)'\n",
    "rf_label = f'YDF RF (k={k_lags_selecionados} Lags)'\n",
    "varmax_label = f'VARMAX (k={k_lags_selecionados} Lags)'\n",
    "\n",
    "# --- Cores (Definido AQUI, antes de ser usado) ---\n",
    "cores = {\n",
    "    ols_label: '#FF6B6B', markov_label: '#F4A261', gam_label: '#4ECDC4',\n",
    "    ts_label: '#FFE66D', bayes_label: '#95E1D3', quantum_base_label: '#9D4EDD',\n",
    "    gbt_label: '#1E90FF', rf_label: '#32CD32', varmax_label: '#FF1493'\n",
    "}\n",
    "print(\"‚úì Dicion√°rio 'cores' definido.\")\n",
    "\n",
    "\n",
    "# ====================================================================\\\n",
    "# 11.a GR√ÅFICO INTERATIVO PLOTLY (Atualizado)\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GERANDO GR√ÅFICO INTERATIVO PLOTLY (Atualizado)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig_plotly = go.Figure()\n",
    "\n",
    "# --- Garante que os DataFrames df e df_moderno existem ---\n",
    "if 'df' not in locals() or 'df_moderno' not in locals():\n",
    "    print(\"ERRO: DataFrames 'df' ou 'df_moderno' n√£o encontrados. N√£o √© poss√≠vel gerar gr√°ficos.\")\n",
    "    # Define fig_plotly como None para pular o salvamento\n",
    "    fig_plotly = None\n",
    "else:\n",
    "    # Gini Verdadeiro e Observado\n",
    "    fig_plotly.add_trace(go.Scatter(\n",
    "        x=df['Ano'], y=df['Gini_Verdadeiro'], mode='lines', name='Gini Verdadeiro',\n",
    "        line=dict(color='black', width=2.5, dash='dash'), hoverinfo='name+x+y', legendgroup='Gini'\n",
    "    ))\n",
    "    # Garante que ano_inicio_pnad existe\n",
    "    if 'ano_inicio_pnad' not in locals(): ano_inicio_pnad = 1976 # Padr√£o\n",
    "    fig_plotly.add_trace(go.Scatter(\n",
    "        x=df_moderno['Ano'], y=df_moderno['Gini_Observado'], mode='markers', name=f'Observado ({ano_inicio_pnad}+)',\n",
    "        marker=dict(color='dimgray', size=8, opacity=0.7), hoverinfo='name+x+y', legendgroup='Gini'\n",
    "    ))\n",
    "    fig_plotly.add_vline(\n",
    "        x=ano_inicio_pnad, line_dash=\"dot\", line_color=\"gray\", line_width=2,\n",
    "        annotation_text=\"In√≠cio dados modernos\", annotation_position=\"top left\"\n",
    "    )\n",
    "\n",
    "    # Fun√ß√µes auxiliares\n",
    "    def add_model_trace(fig, df_hist, col_name, color, line_style, label, legend_group, show_legend=True):\n",
    "        if df_hist is not None and col_name in df_hist.columns and not df_hist[col_name].isnull().all():\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_hist['Ano'], y=df_hist[col_name], mode='lines', name=label,\n",
    "                line=dict(color=color, width=2.5, dash=line_style),\n",
    "                hoverinfo='name+x+y', legendgroup=legend_group, showlegend=show_legend\n",
    "            ))\n",
    "        else:\n",
    "             print(f\"Aviso Plotly: Coluna '{col_name}' n√£o encontrada ou vazia em df_historico.\")\n",
    "\n",
    "\n",
    "    def add_fill_trace(fig, df_hist, low_col, high_col, color, model_name, legend_group):\n",
    "        if df_hist is not None and low_col in df_hist.columns and high_col in df_hist.columns and \\\n",
    "           not df_hist[low_col].isnull().all() and not df_hist[high_col].isnull().all():\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_hist['Ano'], y=df_hist[high_col], mode='lines', line=dict(width=0),\n",
    "                showlegend=False, hoverinfo='skip', legendgroup=legend_group\n",
    "            ))\n",
    "            rgb = plotly.colors.hex_to_rgb(color)\n",
    "            rgba_color = f'rgba({rgb[0]}, {rgb[1]}, {rgb[2]}, 0.15)'\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_hist['Ano'], y=df_hist[low_col], mode='lines', line=dict(width=0),\n",
    "                fill='tonexty', fillcolor=rgba_color, name=f'{model_name} (Int. 95%)',\n",
    "                hoverinfo='name+x', legendgroup=legend_group\n",
    "            ))\n",
    "        else:\n",
    "             print(f\"Aviso Plotly: Colunas '{low_col}' ou '{high_col}' n√£o encontradas ou vazias em df_historico.\")\n",
    "\n",
    "    # --- Adicionar modelos (incluindo os novos) ---\n",
    "    if 'df_historico' in locals() and df_historico is not None:\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_OLS', cores[ols_label], 'solid', ols_label, 'OLS', True)\n",
    "\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_Markov', cores[markov_label], 'solid', markov_label, 'Markov', True)\n",
    "        add_fill_trace(fig_plotly, df_historico, 'Gini_Markov_Low', 'Gini_Markov_High', cores[markov_label], markov_label, 'Markov')\n",
    "\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_GAM', cores[gam_label], 'solid', gam_label, 'GAM', True)\n",
    "        add_fill_trace(fig_plotly, df_historico, 'Gini_GAM_Low', 'Gini_GAM_High', cores[gam_label], gam_label, 'GAM')\n",
    "\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_TimeSeries', cores[ts_label], 'solid', ts_label, 'TS', True)\n",
    "        add_fill_trace(fig_plotly, df_historico, 'Gini_TS_Low', 'Gini_TS_High', cores[ts_label], ts_label, 'TS')\n",
    "\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_Bayes_Hierarquico', cores[bayes_label], 'solid', bayes_label, 'Bayes', True)\n",
    "        add_fill_trace(fig_plotly, df_historico, 'Gini_Bayes_Low', 'Gini_Bayes_High', cores[bayes_label], bayes_label, 'Bayes')\n",
    "\n",
    "        if 'quantum_success' not in locals(): quantum_success = False # Define padr√£o\n",
    "        q_linestyle = 'dashdot' if quantum_success else 'dot'\n",
    "        q_label = f'{quantum_base_label} (QAOA)' if quantum_success else f'{quantum_base_label} (Fallback)'\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_Quantum', cores[quantum_base_label], q_linestyle, q_label, 'Quantum', True)\n",
    "\n",
    "        # YDF GBT e Random Forest (sem intervalos) - USA COLUNAS YDF\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_YDF_GBT', cores[gbt_label], 'dash', gbt_label, 'GBT', True)\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_YDF_RF', cores[rf_label], 'dash', rf_label, 'RF', True)\n",
    "\n",
    "        # VARMAX com intervalo\n",
    "        add_model_trace(fig_plotly, df_historico, 'Gini_VARMAX', cores[varmax_label], 'solid', varmax_label, 'VARMAX', True)\n",
    "        add_fill_trace(fig_plotly, df_historico, 'Gini_VARMAX_Low', 'Gini_VARMAX_High', cores[varmax_label], varmax_label, 'VARMAX')\n",
    "\n",
    "    else:\n",
    "        print(\"ERRO: DataFrame 'df_historico' n√£o encontrado. N√£o √© poss√≠vel adicionar tra√ßos dos modelos Plotly.\")\n",
    "        fig_plotly = None # Define fig_plotly como None para pular o salvamento\n",
    "\n",
    "    # Layout Plotly Atualizado (s√≥ executa se fig_plotly n√£o for None)\n",
    "    if fig_plotly:\n",
    "        fig_plotly.update_layout(\n",
    "            title=dict(\n",
    "                text=f'<b>An√°lise Backcasting Gini (1872-{ano_inicio_pnad-1}) com k={k_lags_selecionados} Lags (Incl. ML/VARMAX)</b>',\n",
    "                x=0.5, xanchor='center', font=dict(size=16, color='black'), pad=dict(b=20)\n",
    "            ),\n",
    "            hovermode='x unified',\n",
    "            legend=dict(\n",
    "                orientation=\"h\", yanchor=\"top\", y=-0.2, xanchor=\"center\", x=0.5, font=dict(size=9),\n",
    "                bgcolor=\"rgba(255,255,255,0.7)\", bordercolor=\"lightgray\", borderwidth=1\n",
    "            ),\n",
    "            margin=dict(l=40, r=40, t=80, b=150),\n",
    "            height=750,\n",
    "            template=\"plotly_white\",\n",
    "            xaxis=dict(range=[df['Ano'].min(), df['Ano'].max()], title='Ano'),\n",
    "            yaxis=dict(range=[0.3, 0.6], title='√çndice de Gini')\n",
    "        )\n",
    "\n",
    "# Salvar Plotly (s√≥ executa se fig_plotly n√£o for None)\n",
    "if fig_plotly:\n",
    "    output_filename_plotly = f\"grafico_backcasting_interativo_k{k_lags_selecionados}lags_full.html\"\n",
    "    output_path_plotly = output_dir / output_filename_plotly\n",
    "\n",
    "    print(f\"\\nSalvando Plotly em: {output_path_plotly}\")\n",
    "    try:\n",
    "        fig_plotly.write_html(str(output_path_plotly))\n",
    "        time.sleep(0.5)\n",
    "        if output_path_plotly.exists():\n",
    "            file_size = output_path_plotly.stat().st_size\n",
    "            print(f\"‚úì SUCESSO! Gr√°fico Plotly salvo\")\n",
    "            print(f\"  ‚Üí Arquivo: {output_path_plotly.name}\")\n",
    "            print(f\"  ‚Üí Tamanho: {file_size / 1024:.1f} KB\")\n",
    "            caminho_windows = str(output_path_plotly).replace('/mnt/c/', 'C:\\\\\\\\').replace('/', '\\\\\\\\')\n",
    "            print(f\"  ‚Üí Caminho Windows: {caminho_windows}\")\n",
    "        else:\n",
    "            print(f\"‚ö† AVISO: Arquivo Plotly n√£o encontrado ap√≥s salvamento!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó ERRO ao salvar Plotly: {e}\")\n",
    "else:\n",
    "    output_filename_plotly = \"plotly_nao_gerado.html\" # Define um nome padr√£o para o resumo\n",
    "    output_path_plotly = output_dir / output_filename_plotly # Define um caminho padr√£o\n",
    "    print(\"\\nAVISO: Gr√°fico Plotly n√£o foi gerado devido a erros anteriores.\")\n",
    "\n",
    "\n",
    "# ====================================================================\\\n",
    "# 11.b GR√ÅFICO EST√ÅTICO MATPLOTLIB (Atualizado)\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GERANDO GR√ÅFICO EST√ÅTICO MATPLOTLIB (Atualizado)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig_mpl = None # Inicializa fig_mpl\n",
    "\n",
    "# --- Garante que os DataFrames df e df_moderno existem ---\n",
    "if 'df' not in locals() or 'df_moderno' not in locals():\n",
    "    print(\"ERRO: DataFrames 'df' ou 'df_moderno' n√£o encontrados. N√£o √© poss√≠vel gerar gr√°ficos Matplotlib.\")\n",
    "else:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['figure.dpi'] = 100\n",
    "    fig_mpl, ax_mpl = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "    line_styles_mpl = {'solid': '-', 'dash': '--', 'dot': ':', 'dashdot': '-.'}\n",
    "\n",
    "    # Fun√ß√µes auxiliares\n",
    "    def add_model_trace_mpl(ax, df_hist, col_name, color, line_style_key, label):\n",
    "        if df_hist is not None and col_name in df_hist.columns and not df_hist[col_name].isnull().all():\n",
    "            ax.plot(\n",
    "                df_hist['Ano'], df_hist[col_name], color=color,\n",
    "                linestyle=line_styles_mpl.get(line_style_key, '-'),\n",
    "                linewidth=2.0, label=label, zorder=2\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Aviso Matplotlib: Coluna '{col_name}' n√£o encontrada ou vazia em df_historico.\")\n",
    "\n",
    "    def add_fill_trace_mpl(ax, df_hist, low_col, high_col, color, model_name):\n",
    "        if df_hist is not None and low_col in df_hist.columns and high_col in df_hist.columns and \\\n",
    "           not df_hist[low_col].isnull().all() and not df_hist[high_col].isnull().all():\n",
    "            ax.fill_between(\n",
    "                df_hist['Ano'], df_hist[low_col], df_hist[high_col], color=color, alpha=0.15,\n",
    "                label=f'{model_name} (Int. 95%)', zorder=1\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Aviso Matplotlib: Colunas '{low_col}' ou '{high_col}' n√£o encontradas ou vazias em df_historico.\")\n",
    "\n",
    "\n",
    "    # Plotar dados\n",
    "    ax_mpl.plot(df['Ano'], df['Gini_Verdadeiro'], color='black', linestyle='--', linewidth=2.0, label='Gini Verdadeiro', zorder=3)\n",
    "    ax_mpl.plot(df_moderno['Ano'], df_moderno['Gini_Observado'], marker='o', markersize=6, markerfacecolor='dimgray', markeredgecolor='dimgray', linestyle='None', label=f'Observado ({ano_inicio_pnad}+)', alpha=0.7, zorder=4)\n",
    "    ax_mpl.axvline(x=ano_inicio_pnad, color=\"gray\", linestyle=':', linewidth=2, zorder=2)\n",
    "    ax_mpl.annotate(\"In√≠cio dados modernos\", xy=(ano_inicio_pnad, 0.58), xytext=(ano_inicio_pnad + 2, 0.56), arrowprops=dict(facecolor='gray', shrink=0.05, width=1, headwidth=4), horizontalalignment='left', color='gray', zorder=3)\n",
    "\n",
    "    # Adicionar modelos (incluindo os novos)\n",
    "    if 'df_historico' in locals() and df_historico is not None:\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_OLS', cores[ols_label], 'solid', ols_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_Markov', cores[markov_label], 'solid', markov_label)\n",
    "        add_fill_trace_mpl(ax_mpl, df_historico, 'Gini_Markov_Low', 'Gini_Markov_High', cores[markov_label], markov_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_GAM', cores[gam_label], 'solid', gam_label)\n",
    "        add_fill_trace_mpl(ax_mpl, df_historico, 'Gini_GAM_Low', 'Gini_GAM_High', cores[gam_label], gam_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_TimeSeries', cores[ts_label], 'solid', ts_label)\n",
    "        add_fill_trace_mpl(ax_mpl, df_historico, 'Gini_TS_Low', 'Gini_TS_High', cores[ts_label], ts_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_Bayes_Hierarquico', cores[bayes_label], 'solid', bayes_label)\n",
    "        add_fill_trace_mpl(ax_mpl, df_historico, 'Gini_Bayes_Low', 'Gini_Bayes_High', cores[bayes_label], bayes_label)\n",
    "        # Quantum label\n",
    "        if 'quantum_success' not in locals(): quantum_success = False\n",
    "        q_linestyle = 'dashdot' if quantum_success else 'dot'\n",
    "        q_label = f'{quantum_base_label} (QAOA)' if quantum_success else f'{quantum_base_label} (Fallback)'\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_Quantum', cores[quantum_base_label], q_linestyle, q_label)\n",
    "\n",
    "        # YDF GBT e Random Forest - USA COLUNAS YDF\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_YDF_GBT', cores[gbt_label], 'dash', gbt_label)\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_YDF_RF', cores[rf_label], 'dash', rf_label)\n",
    "\n",
    "        add_model_trace_mpl(ax_mpl, df_historico, 'Gini_VARMAX', cores[varmax_label], 'solid', varmax_label)\n",
    "        add_fill_trace_mpl(ax_mpl, df_historico, 'Gini_VARMAX_Low', 'Gini_VARMAX_High', cores[varmax_label], varmax_label)\n",
    "\n",
    "    else:\n",
    "        print(\"ERRO: DataFrame 'df_historico' n√£o encontrado. N√£o √© poss√≠vel adicionar tra√ßos dos modelos Matplotlib.\")\n",
    "        fig_mpl = None # Define fig_mpl como None para pular o salvamento\n",
    "\n",
    "    # Layout Matplotlib (s√≥ executa se fig_mpl n√£o for None)\n",
    "    if fig_mpl:\n",
    "        ax_mpl.set_title(\n",
    "            f'An√°lise Backcasting Gini (1872-{ano_inicio_pnad-1}) com k={k_lags_selecionados} Lags (Incl. ML/VARMAX)',\n",
    "            fontsize=14, fontweight='bold', pad=20\n",
    "        )\n",
    "        ax_mpl.set_xlabel('Ano', fontsize=12)\n",
    "        ax_mpl.set_ylabel('√çndice de Gini', fontsize=12)\n",
    "        ax_mpl.set_xlim(df['Ano'].min(), df['Ano'].max())\n",
    "        ax_mpl.set_ylim(0.3, 0.6)\n",
    "        ax_mpl.xaxis.set_major_locator(mtick.MultipleLocator(20))\n",
    "        ax_mpl.yaxis.set_major_locator(mtick.MultipleLocator(0.05))\n",
    "        ax_mpl.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "        handles, labels = ax_mpl.get_legend_handles_labels()\n",
    "        if handles:\n",
    "            num_legend_items = len(handles)\n",
    "            ncol_legend = min(num_legend_items // 2 + num_legend_items % 2, 4)\n",
    "            leg_mpl = ax_mpl.legend(\n",
    "                loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "                ncol=ncol_legend, fontsize=8, frameon=True,\n",
    "                edgecolor='lightgray', facecolor='white'\n",
    "            )\n",
    "            fig_mpl.tight_layout()\n",
    "            plt.subplots_adjust(bottom=0.30 if num_legend_items > 8 else 0.25)\n",
    "        else:\n",
    "            fig_mpl.tight_layout()\n",
    "\n",
    "# Salvar Matplotlib (s√≥ executa se fig_mpl n√£o for None)\n",
    "if fig_mpl:\n",
    "    output_filename_mpl = f\"grafico_backcasting_estatico_k{k_lags_selecionados}lags_full.jpg\"\n",
    "    output_path_mpl = output_dir / output_filename_mpl\n",
    "\n",
    "    print(f\"\\nSalvando Matplotlib em: {output_path_mpl}\")\n",
    "    try:\n",
    "        fig_mpl.savefig(str(output_path_mpl), format='jpg', dpi=300, bbox_inches='tight')\n",
    "        time.sleep(0.5)\n",
    "        if output_path_mpl.exists():\n",
    "            file_size = output_path_mpl.stat().st_size\n",
    "            print(f\"‚úì SUCESSO! Gr√°fico Matplotlib salvo\")\n",
    "            print(f\"  ‚Üí Arquivo: {output_path_mpl.name}\")\n",
    "            print(f\"  ‚Üí Tamanho: {file_size / 1024:.1f} KB\")\n",
    "            caminho_windows = str(output_path_mpl).replace('/mnt/c/', 'C:\\\\\\\\').replace('/', '\\\\\\\\')\n",
    "            print(f\"  ‚Üí Caminho Windows: {caminho_windows}\")\n",
    "        else:\n",
    "            print(f\"‚ö† AVISO: Arquivo Matplotlib n√£o encontrado ap√≥s salvamento!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó ERRO ao salvar Matplotlib: {e}\")\n",
    "\n",
    "    # plt.show() # N√£o usar show\n",
    "    plt.close(fig_mpl) # Fecha a figura\n",
    "else:\n",
    "    output_filename_mpl = \"matplotlib_nao_gerado.jpg\" # Define um nome padr√£o para o resumo\n",
    "    output_path_mpl = output_dir / output_filename_mpl # Define um caminho padr√£o\n",
    "    print(\"\\nAVISO: Gr√°fico Matplotlib n√£o foi gerado devido a erros anteriores.\")\n",
    "\n",
    "\n",
    "# ====================================================================\\\n",
    "# RESUMO FINAL (Atualizado)\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESUMO DOS ARQUIVOS GERADOS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Diret√≥rio: {output_dir}\")\n",
    "print(f\"\\nArquivos:\")\n",
    "# Usa os nomes de arquivo definidos, mesmo que n√£o tenham sido criados\n",
    "print(f\"  1. {output_filename_plotly}\")\n",
    "print(f\"     Existe: {output_path_plotly.exists()}\")\n",
    "if output_path_plotly.exists(): print(f\"     Tamanho: {output_path_plotly.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "print(f\"\\n  2. {output_filename_mpl}\")\n",
    "print(f\"     Existe: {output_path_mpl.exists()}\")\n",
    "if output_path_mpl.exists(): print(f\"     Tamanho: {output_path_mpl.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# Verifica os arquivos de plot iniciais\n",
    "gini_regimes_path = Path('gini_regimes_plot.png')\n",
    "print(f\"\\n  3. {gini_regimes_path.name}\")\n",
    "print(f\"     Existe: {gini_regimes_path.exists()}\")\n",
    "if gini_regimes_path.exists(): print(f\"     Tamanho: {gini_regimes_path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "covariaveis_path = Path('covariaveis_plot.png')\n",
    "print(f\"\\n  4. {covariaveis_path.name}\")\n",
    "print(f\"     Existe: {covariaveis_path.exists()}\")\n",
    "if covariaveis_path.exists(): print(f\"     Tamanho: {covariaveis_path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úì VISUALIZA√á√ÉO CONCLU√çDA (com modelos adicionais)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save the final dataframe with all predictions to a CSV\n",
    "final_csv_path = output_dir / f\"simulacao_resultados_k{k_lags_selecionados}lags_full.csv\" # Updated filename\n",
    "try:\n",
    "    # Garante que df_historico existe antes de tentar o merge\n",
    "    if 'df_historico' in locals() and df_historico is not None:\n",
    "        # Seleciona apenas as colunas que realmente existem em df_historico\n",
    "        cols_to_merge = ['Ano'] + [col for col in [\n",
    "            'Gini_OLS', 'Gini_Markov', 'Gini_Markov_Low', 'Gini_Markov_High',\n",
    "            'Gini_GAM', 'Gini_GAM_Low', 'Gini_GAM_High', 'Gini_TimeSeries',\n",
    "            'Gini_TS_Low', 'Gini_TS_High', 'Gini_Bayes_Hierarquico',\n",
    "            'Gini_Bayes_Low', 'Gini_Bayes_High', 'Gini_Quantum',\n",
    "            # AJUSTE AQUI BASEADO NO BLOCO 7 - Usando YDF\n",
    "            'Gini_YDF_GBT', 'Gini_YDF_RF',\n",
    "            'Gini_VARMAX', 'Gini_VARMAX_Low', 'Gini_VARMAX_High'\n",
    "            ] if col in df_historico.columns]\n",
    "        df_hist_subset = df_historico[cols_to_merge].copy()\n",
    "        df_combined_output = pd.merge(df.copy(), df_hist_subset, on='Ano', how='left') # Usa c√≥pia de df\n",
    "\n",
    "        # Merge modern dataframe info if needed e se df_moderno existir\n",
    "        if 'df_moderno' in locals() and df_moderno is not None and 'Regime_Inferido' in df_moderno.columns:\n",
    "             cols_moderno = ['Ano'] + [col for col in ['Regime_Inferido', 'Prob_Regime_0', 'Prob_Regime_1'] if col in df_moderno.columns]\n",
    "             df_mod_subset = df_moderno[cols_moderno].copy()\n",
    "             # Assegura que n√£o h√° colunas duplicadas (exceto 'Ano') antes do merge\n",
    "             cols_mod_to_merge = [c for c in df_mod_subset.columns if c not in df_combined_output.columns or c == 'Ano']\n",
    "             df_combined_output = pd.merge(df_combined_output, df_mod_subset[cols_mod_to_merge], on='Ano', how='left')\n",
    "\n",
    "        # Salva o DataFrame combinado\n",
    "        df_combined_output.to_csv(str(final_csv_path), index=False, decimal=',', sep=';')\n",
    "        print(f\"\\n‚úì DataFrame final com todas as previs√µes salvo em: {final_csv_path}\")\n",
    "        caminho_windows_csv = str(final_csv_path).replace('/mnt/c/', 'C:\\\\\\\\').replace('/', '\\\\\\\\')\n",
    "        print(f\"  ‚Üí Caminho Windows: {caminho_windows_csv}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö† DataFrame 'df_historico' n√£o encontrado. N√£o foi poss√≠vel salvar o CSV combinado.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö† Erro ao salvar DataFrame final em CSV: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34038727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
